{"title":"DockerSwarm搭建完整的微服务项目","uid":"27852f8dc79cc34a496b7be5ae32dae9","slug":"golang/DockerSwarm搭建完整的微服务项目","date":"2020-10-20T06:59:52.000Z","updated":"2021-12-11T02:10:04.778Z","comments":true,"path":"api/articles/golang/DockerSwarm搭建完整的微服务项目.json","keywords":"golang rust python docker k8s","cover":null,"content":"<p>这是一个容器化快速发展的时代，相信不少朋友都已经体会到了容器的便利性，自从我第一眼看到容器这个东西，就对其深深的爱上了。也确定了我以后的职业发展方向。这也是我喜欢Golang的原因</p>\n<span id=\"more\"></span>\n<p>最近接到一个说大不大说下不小的项目，因为K8S有点太重了，我们人员资源有限，所以这一次我打算用docker自带的集群工具swarm去进行搭建。</p>\n<p>简单描述一下项目的架构，图就不放了涉及到商业机密哈哈哈</p>\n<p>整个项目是近年来比较流行的微服务架构的形式，（PS,人少千万别搞，头发疯狂掉，我这边是不懂技术的leader非要搞这个。醉了，其实单体应用一样可以满足需求），不过好处也是有的，各个service的代码会变得少且清爽。</p>\n<p>技术选型</p>\n<ol>\n<li>开发语言：Golang</li>\n<li>开发框架：Gin(web框架) go-micro(一个我用起来比较舒服的微服务框架)</li>\n<li>OTHER：<ul>\n<li>go-fastdfs : 存储静态文件</li>\n<li>MySQL</li>\n<li>Redis</li>\n<li>ETCD</li>\n<li>ElasticSearch</li>\n<li>logstash</li>\n<li>kafka</li>\n<li>elastalert (哈哈看到这几个东西你是不是觉得你知道咱们是干什么的啦？没错，但是也错，因为这只是整个项目中的一块功能)</li>\n<li>docker swarm</li>\n</ul>\n</li>\n</ol>\n<p>我们准备了五台机器来搭建环境都是32核+48G往上的配置。</p>\n<p>代码是分为了 负责用户交互的 API项目。以及若干不同的后端service, 所有的service通过rpc受API控制与调度。</p>\n<ol>\n<li>初始化docker swarm环境。</li>\n</ol>\n<ul>\n<li>首先选择你要作为主管理节点的机器执行 <code>docker swarm init</code>,执行完毕会生成类似如下信息,其中<code>docker swarm join --token ...</code> 就是你要在其他机器上执行的命令，以让其他节点加入集群。同时我们可以看到swarm集群是默认通过2377端口进行通讯的，注意你的防火墙哦。  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">Swarm initialized: current node (kszmpm48vw7kzrl3r1erqnhww) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n  docker swarm join --token SWMTKN-1-3fjzlta4vpoj1eq2mo9eqzvxa96lt46hpdfyd6o4pgwtdxnrzo-cbdve6xq1dcah532llqn2jgxr 192.168.65.3:2377\n\nTo add a manager to this swarm, run &#39;docker swarm join-token manager&#39; and follow the instructions.</code></pre></li>\n<li>在其他节点加入完毕后，在master上执行<code>docker node ls</code>查看是否所有节点都加入进来。</li>\n<li>另外还可以对每个节点 <code>docker node update --label-add xxx=xxx  [node_name]</code>打上一些标签，方便部署规划</li>\n</ul>\n<ol start=\"2\">\n<li><p>在开始部署项目之前我们需要解决一个小问题<br>  我们知道docker跨主机网络是可以共享的，那么数据卷是不是可以呢，其实是可以的，只不过官方自己未实现而已，这里就需要一些第三方的插件了，我们这里选用的是 convoy ,这是一个基于nfs的跨主机容器存储插件，安装方式这里就不赘述了。</p>\n</li>\n<li><p>开始部署。<br>  docker swarm也是支持使用<code>docker-compose.yaml</code>文件去进行部署的，这样比命令行好的原因是方便管理。也更加直观。所以这里我们基本上一个中间件，或者一个服务一个yaml文件</p>\n</li>\n<li><p>MySQL: 由于我这里暂时数据量还没上来，而且还在开发阶段所以只部署了单节点<br><pre class=\"line-numbers language-yaml\" data-language=\"yaml\"><code class=\"language-yaml\">version: &quot;3.8&quot;\nservices:\n  mysql:\n    image: mysql:5.7\n    command: [ &quot;mysqld&quot;,&quot;--character-set-server&#x3D;utf8mb4&quot;,&quot;--collation-server&#x3D;utf8mb4_unicode_ci&quot; ]\n    ports:\n      - 8306:3306\n    environment:\n      - MYSQL_ROOT_PASSWORD&#x3D;mysql\n    volumes:\n      - mysql-data:&#x2F;var&#x2F;lib&#x2F;mysql\n    networks:\n      - project-network\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.role&#x3D;&#x3D;manager&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\nvolumes:    # 使用convoy创建的数据卷\n  mysql-data:\n    name: mysql-data\n    external: true\n\nnetworks:\n  project-network: # 外部创建用于 项目共享的网络 后面不再赘述\n    name: project-network\n    external: true</code></pre></p>\n</li>\n<li><p>redis: redis的集群哨兵模式在docker中只能以host模式去运行（这是要注意的，如果你要搭集群的话）<br><pre class=\"line-numbers language-yaml\" data-language=\"yaml\"><code class=\"language-yaml\">version: &quot;3.8&quot;\n  services:\n    redis:\n      image: project-redis:latest # 这里使用的不是官方镜像，因为我们需要修改一些配置，所以需要自己build\n      networks:\n        - project-network\n      deploy:\n        replicas: 1\n        placement:\n          constraints:\n            - &quot;node.labels.name&#x3D;&#x3D;worker2&quot; # 标签\n        restart_policy:\n          condition: on-failure\n          delay: 5s\n          max_attempts: 3\n          window: 10s\n\n  networks:\n    project-network:\n      name: project-network\n      external: true</code></pre></p>\n</li>\n<li><p>fastdfs<br><pre class=\"line-numbers language-yaml\" data-language=\"yaml\"><code class=\"language-yaml\">version: &quot;3.8&quot;\nservices:\n  fast_dfs:\n    image: sjqzhang&#x2F;go-fastdfs:latest\n    networks:\n      - project-network\n    environment:\n      GO_FASTDFS_DIR: &#x2F;data\n    volumes:\n      - dfs:&#x2F;data\n    deploy:\n      replicas: 1  # 这个也是可以搭建集群的官方有教程可以操作一下\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;worker3&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\nnetworks:\n  project-network:\n    name: project-network\n    external: true\n\nvolumes:\n  dfs:\n    name: fast-dfs\n    external: true</code></pre></p>\n</li>\n<li><p>ETCD集群<br><pre class=\"line-numbers language-yaml\" data-language=\"yaml\"><code class=\"language-yaml\">version: &quot;3.8&quot;\nservices:\n  etcd:\n    image: quay.io&#x2F;coreos&#x2F;etcd:latest\n    environment:\n      - ETCDCTL_API&#x3D;3\n    networks:\n      - project-network\n    command:\n      &#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcd\n      -name etcd\n      -data-dir &#x2F;etcd-data\n      -initial-advertise-peer-urls http:&#x2F;&#x2F;etcd:2380\n      -advertise-client-urls http:&#x2F;&#x2F;etcd:2379\n      -listen-client-urls http:&#x2F;&#x2F;0.0.0.0:2379\n      -listen-peer-urls http:&#x2F;&#x2F;0.0.0.0:2380\n      -initial-cluster-token etcd-cluster\n      -initial-cluster-state new\n      -initial-cluster &quot;etcd&#x3D;http:&#x2F;&#x2F;etcd:2380,etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380&quot;\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.role&#x3D;&#x3D;manager&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  etcd1:\n    image: quay.io&#x2F;coreos&#x2F;etcd:latest\n    environment:\n      - ETCDCTL_API&#x3D;3\n    networks:\n      - project-network\n    command:\n      &#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcd\n      -name etcd1\n      -data-dir &#x2F;etcd-data\n      -initial-advertise-peer-urls http:&#x2F;&#x2F;etcd1:2380\n      -advertise-client-urls http:&#x2F;&#x2F;etcd1:2379\n      -listen-client-urls http:&#x2F;&#x2F;0.0.0.0:2379\n      -listen-peer-urls http:&#x2F;&#x2F;0.0.0.0:2380\n      -initial-cluster-token etcd-cluster\n      -initial-cluster-state new\n      -initial-cluster &quot;etcd&#x3D;http:&#x2F;&#x2F;etcd:2380,etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380&quot;\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;worker2&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  etcd2:\n    image: quay.io&#x2F;coreos&#x2F;etcd:latest\n    environment:\n      - ETCDCTL_API&#x3D;3\n    networks:\n      - project-network\n    command:\n      &#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcd\n      -name etcd2\n      -data-dir &#x2F;etcd-data\n      -initial-advertise-peer-urls http:&#x2F;&#x2F;etcd2:2380\n      -advertise-client-urls http:&#x2F;&#x2F;etcd2:2379\n      -listen-client-urls http:&#x2F;&#x2F;0.0.0.0:2379\n      -listen-peer-urls http:&#x2F;&#x2F;0.0.0.0:2380\n      -initial-cluster-token etcd-cluster\n      -initial-cluster-state new\n      -initial-cluster &quot;etcd&#x3D;http:&#x2F;&#x2F;etcd:2380,etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380&quot;\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;worker3&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\nnetworks:\n  project-network:\n    name: project-network\n    external: true</code></pre></p>\n</li>\n<li><p>ES集群<br><pre class=\"line-numbers language-yaml\" data-language=\"yaml\"><code class=\"language-yaml\">version: &quot;3.8&quot;\nservices:\n  es1:\n    image: elasticsearch:7.8.1\n    networks:\n      - project-network\n    volumes:\n      - &#x2F;opt&#x2F;es_docker&#x2F;certs&#x2F;elastic-certificates.p12:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config&#x2F;elastic-certificates.p12\n      - &#x2F;opt&#x2F;es_data:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data\n    environment:\n      - node.name&#x3D;es1\n      - node.master&#x3D;true\n      - node.data&#x3D;true\n      - cluster.name&#x3D;noahsec\n      - node.max_local_storage_nodes&#x3D;9\n      - discovery.zen.ping.unicast.hosts&#x3D;es_es1,es_es2,es_es3\n      - discovery.zen.minimum_master_nodes&#x3D;1\n      - cluster.initial_master_nodes&#x3D;es1\n      - http.cors.enabled&#x3D;true\n      - http.cors.allow-origin&#x3D;&quot;*&quot;\n      - xpack.license.self_generated.type&#x3D;basic\n      - xpack.security.enabled&#x3D;true\n      - xpack.security.transport.ssl.enabled&#x3D;true\n      - xpack.security.transport.ssl.verification_mode&#x3D;certificate\n      - xpack.security.transport.ssl.keystore.path&#x3D;elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path&#x3D;elastic-certificates.p12\n      - xpack.monitoring.enabled&#x3D;true\n      - &quot;ES_JAVA_OPTS&#x3D;-Xms32g -Xmx32g&quot;\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;es&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  es2:\n    image: elasticsearch:7.8.1\n    networks:\n      - project-network\n    volumes:\n      - &#x2F;opt&#x2F;es_docker&#x2F;certs&#x2F;elastic-certificates.p12:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config&#x2F;elastic-certificates.p12\n      - &#x2F;opt&#x2F;es_data:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data\n    environment:\n      - node.name&#x3D;es2\n      - node.master&#x3D;true\n      - node.data&#x3D;true\n      - cluster.name&#x3D;noahsec\n      - node.max_local_storage_nodes&#x3D;9\n      - discovery.zen.ping.unicast.hosts&#x3D;es_es1,es_es2,es_es3\n      - discovery.zen.minimum_master_nodes&#x3D;1\n      - cluster.initial_master_nodes&#x3D;es1\n      - http.cors.enabled&#x3D;true\n      - http.cors.allow-origin&#x3D;&quot;*&quot;\n      - xpack.license.self_generated.type&#x3D;basic\n      - xpack.security.enabled&#x3D;true\n      - xpack.security.transport.ssl.enabled&#x3D;true\n      - xpack.security.transport.ssl.verification_mode&#x3D;certificate\n      - xpack.security.transport.ssl.keystore.path&#x3D;elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path&#x3D;elastic-certificates.p12\n      - xpack.monitoring.enabled&#x3D;true\n      - &quot;ES_JAVA_OPTS&#x3D;-Xms32g -Xmx32g&quot;\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;es&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n  es3:\n    image: elasticsearch:7.8.1\n    networks:\n      - project-network\n    volumes:\n      - &#x2F;opt&#x2F;es_docker&#x2F;certs&#x2F;elastic-certificates.p12:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config&#x2F;elastic-certificates.p12\n      - &#x2F;opt&#x2F;es_data:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data\n    environment:\n      - node.name&#x3D;es3\n      - node.master&#x3D;true\n      - node.data&#x3D;true\n      - cluster.name&#x3D;noahsec\n      - node.max_local_storage_nodes&#x3D;9\n      - discovery.zen.ping.unicast.hosts&#x3D;es_es1,es_es2,es_es3\n      - discovery.zen.minimum_master_nodes&#x3D;1\n      - cluster.initial_master_nodes&#x3D;es1\n      - http.cors.enabled&#x3D;true\n      - http.cors.allow-origin&#x3D;&quot;*&quot;\n      - xpack.license.self_generated.type&#x3D;basic\n      - xpack.security.enabled&#x3D;true\n      - xpack.security.transport.ssl.enabled&#x3D;true\n      - xpack.security.transport.ssl.verification_mode&#x3D;certificate\n      - xpack.security.transport.ssl.keystore.path&#x3D;elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path&#x3D;elastic-certificates.p12\n      - xpack.monitoring.enabled&#x3D;true\n      - &quot;ES_JAVA_OPTS&#x3D;-Xms32g -Xmx32g&quot;\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;es&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  kibana:\n    image: kibana:7.8.1\n    networks:\n      - project-network\n    ports:\n      - 5601:5601\n    environment:\n      ELASTICSEARCH_HOSTS: http:&#x2F;&#x2F;es1:9200\n      ELASTICSEARCH_USERNAME: kibana\n      ELASTICSEARCH_PASSWORD: Zx3TuFXNKgTEv1IVZvFt\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;es&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  nginx:  # 这里用ngix是和我们公司的特殊环境有关，需要从外部访问。你可以不用设置\n    image: nginx\n    networks:\n      - project-network\n    ports:\n      - 9200:9200\n    command: |\n      &#x2F;bin&#x2F;bash -c &quot;echo &#39;\n      server &#123;\n        listen 9200;\n        add_header X-Frame-Options &quot;SAMEORIGIN&quot;;\n        location &#x2F; &#123;\n          client_max_body_size 200m;\n          proxy_pass http:&#x2F;&#x2F;es_es1:9200;\n          proxy_http_version 1.1;\n          proxy_set_header Connection keep-alive;\n          proxy_set_header Upgrade $$http_upgrade;\n          proxy_set_header Host $$host;\n          proxy_set_header X-Real-IP $$remote_addr;\n          proxy_cache_bypass $$http_upgrade;\n      &#125;\n      &#125;&#39; | tee &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf &amp;&amp; nginx -g &#39;daemon off;&#39;&quot;\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;esalert&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\nvolumes:\n  es-data:\n    name: es-data\n    external: true\n\nnetworks:\n  project-network:\n    name: project-network\n    external: true\n    external: true</code></pre><br>  项目代码部分如何部署就不做展示了，都是同理的。</p>\n</li>\n<li><p>结语<br>  此篇博客其实没什么干货，只是稍微水一下不过我相信聪明的同学即使是在水文中也能获取到一点点知识哈哈。<br>  关于微服务，其实本项目还有很多东西没有做，比如服务注册，服务发现，配置中心等等（目前项目中所有的配置都是使用一个环境变量配置文件去读取），这些都是人手不足无法去做的地方。<br>  所以还是那句话，不要因为什么流行，就去搞什么，还是得调研，实际符合自己的架构才是好的架构。</p>\n</li>\n</ol>\n","text":"这是一个容器化快速发展的时代，相信不少朋友都已经体会到了容器的便利性，自从我第一眼看到容器这个东西，就对其深深的爱上了。也确定了我以后的职业发展方向。这也是我喜欢Golang的原因 最近接到一个说大不大说下不小的项目，因为K8S有点太重了，我们人员资源有限，所以这一次我打算用do...","link":"","photos":[],"count_time":{"symbolsCount":"13k","symbolsTime":"12 mins."},"categories":[{"name":"docker","slug":"docker","count":2,"path":"api/categories/docker.json"}],"tags":[{"name":"docker","slug":"docker","count":2,"path":"api/tags/docker.json"},{"name":"swarm","slug":"swarm","count":1,"path":"api/tags/swarm.json"},{"name":"架构","slug":"架构","count":1,"path":"api/tags/架构.json"},{"name":"微服务","slug":"微服务","count":1,"path":"api/tags/微服务.json"}],"toc":"","author":{"name":"Aurora","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"hexo添加评论系统","uid":"e58f8fe0572c85b85b5c4eee696e5d39","slug":"config/hexo添加评论系统","date":"2020-10-21T01:54:15.000Z","updated":"2021-12-11T02:10:04.777Z","comments":true,"path":"api/articles/config/hexo添加评论系统.json","keywords":"golang rust python docker k8s","cover":[],"text":" hexo支持很多评论系统，由于我的blog是部署在github page 上，所以，索性我就直接用gitalk用做评论系统 配置方法 首先先在github中创建一个用于存储评论的公有仓库，注意（博客可以部署在私有仓库，评论必须public） 注册Github APP https...","link":"","photos":[],"count_time":{"symbolsCount":457,"symbolsTime":"1 mins."},"categories":[{"name":"hexo","slug":"hexo","count":2,"path":"api/categories/hexo.json"}],"tags":[{"name":"hexo","slug":"hexo","count":2,"path":"api/tags/hexo.json"}],"author":{"name":"Aurora","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"用简单的话讲明白MySQL索引","uid":"5a2cdee73626da8985a23805f627ad4f","slug":"mysql/用简单的话讲明白索引","date":"2020-10-20T01:57:21.000Z","updated":"2021-12-11T02:10:04.780Z","comments":true,"path":"api/articles/mysql/用简单的话讲明白索引.json","keywords":"golang rust python docker k8s","cover":[],"text":"索引的作用顾名思义，索引其实就是字面意思，和我们以前查字典的索引是一样的意思，能够帮助我们快速的查找到相关数据，这就是索引，哈希表的键，人的名字，工号，身份证号，这些都是索引 BTree(B-Tree) B树和B-树其实是一个意思。它长这个样子 它是一颗多路平衡查找树，我们描述一...","link":"","photos":[],"count_time":{"symbolsCount":"2.6k","symbolsTime":"2 mins."},"categories":[{"name":"MySQL","slug":"MySQL","count":4,"path":"api/categories/MySQL.json"}],"tags":[{"name":"mysql","slug":"mysql","count":4,"path":"api/tags/mysql.json"},{"name":"数据库索引","slug":"数据库索引","count":1,"path":"api/tags/数据库索引.json"}],"author":{"name":"Aurora","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}