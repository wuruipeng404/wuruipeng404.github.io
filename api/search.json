[{"id":"235660ba99baa3b7d4208214f0acb547","title":"封装易用的 Golang Odm","content":"&amp;#160;&amp;#160;&amp;#160;&amp;#160;在golang中目前需要对mongodb进行操作会接触到如下两个库\nmongo-go-driver mongodb官方出的驱动mgo\nmgo 很久没有维护了. 所以现在大家基本上都在使用官方的driver,但是官方的driver用下来,有一些痛点.所以我决定封装一下.使其用起来像gorm那样更方便一点\n\n\n痛点\ndriver对象每次使用都需要手动指定collection名称 而不能通过已经定义好的结构体进行映射\n虽然可以通过结构体的 tag bson 进行标注, 但是这个标注,在有些方法中是不能通过结构体自行判断filter字段的, 只能通过bson.M 这个结构去传递\n查询后的结果也没有一个便捷的方法去进行接收,就像 json.Unmarshal() 那样\n\nmongoos代码取名 mongoose, 这个是因为最近刚好在用nodejs的 mongoose 也就直接拿过来用了.实现的方式主要还是反射, 详情看源码吧.\n一些例子\npackage main\n\nimport (\n\t&quot;context&quot;\n\t&quot;log&quot;\n\t&quot;github.com&#x2F;wuruipeng404&#x2F;mongoose&quot;\n\t&quot;go.mongodb.org&#x2F;mongo-driver&#x2F;bson&quot;\n)\n\nvar odm *mongoose.Mongo\n\n&#x2F;&#x2F; get mongo client\nfunc init() &#123;\n\n\tvar err error\n\n\tif odm, err &#x3D; mongoose.Open(&amp;mongoose.Options&#123;\n\t\tUser:       &quot;user&quot;,\n\t\tPassword:   &quot;password&quot;,\n\t\tHost:       &quot;localhost&quot;,\n\t\tPort:       27017,\n\t\tDBName:     &quot;your-db&quot;,\n\t\tDriverOpts: nil, &#x2F;&#x2F; and you can add driver client options\n\t&#125;); err !&#x3D; nil &#123;\n\t\tlog.Fatalf(&quot;connect mongoose failed:%s&quot;, err)\n\t&#125;\n&#125;\n\n&#x2F;&#x2F; define your schema\ntype YourSchema struct &#123;\n\tmongoose.Document &#96;bson:&quot;,inline&quot;&#96;\n\tFieldA            string     &#96;bson:&quot;field_a,omitempty&quot;&#96;\n\tFieldB            int        &#96;bson:&quot;field_b,omitempty&quot;&#96;\n\tSon               *SubSchema &#96;bson:&quot;son,omitempty&quot;&#96;\n\t*SubSchema        &#96;bson:&quot;,inline&quot;&#96; &#x2F;&#x2F; inline field\n&#125;\n\ntype SubSchema struct &#123;\n\tFieldC string &#96;bson:&quot;field_c,omitempty&quot;&#96;\n\tFieldD string &#96;bson:&quot;field_d,omitempty&quot;&#96;\n&#125;\n\n&#x2F;&#x2F; CollectionName impl mongoose.IDocument interface\nfunc (*YourSchema) CollectionName() string &#123;\n\treturn &quot;your_collection&quot;\n&#125;\n\nfunc Create() &#123;\n\t&#x2F;&#x2F; will auto add create time for now , and also you can set your time \n\t&#x2F;&#x2F; and all create method will auto find collection name\n\todm.InsertOne(&amp;YourSchema&#123;\n\t\tFieldA: &quot;test&quot;,\n\t\tFieldB: 3,\n\t\tSubSchema: &amp;SubSchema&#123;\n\t\t\tFieldC: &quot;111&quot;,\n\t\t\tFieldD: &quot;222&quot;,\n\t\t&#125;,\n\t&#125;)\n\n\t&#x2F;&#x2F; if your want to use driver method\n\todm.DriverCollection(&quot;your collection&quot;).InsertOne(bson.M&#123;&#125;)\n&#125;\n\nfunc HaveFilterMethod() &#123;\n\t&#x2F;&#x2F; update find delete\n\t&#x2F;&#x2F; id support string (primitive.ObjectID.hex()) and ObjectID\n\tvar result YourSchema\n\todm.FindByID(id, &amp;result)\n\n\t&#x2F;&#x2F; filter support bson and IDocument\n\t&#x2F;&#x2F; This is equivalent\n\tvar result2 []YourSchema\n\todm.Find(YourSchema&#123;FieldA: &quot;zhangsan&quot;&#125;, &amp;result2)\n\todm.Find(bson.M&#123;&quot;field_a&quot;: &quot;zhangsan&quot;&#125;, &amp;result2)\n\t&#x2F;&#x2F; this is sugar\n\todm.Find(mongoose.Eq(&quot;field_a&quot;, &quot;zhangsan&quot;), &amp;result2)\n&#125;\n\n\n&#x2F;&#x2F; release client\nfunc Close() &#123;\n\todm.Release(context.TODO())\n&#125;\n\ntodo: 目前只实现了一些常用功能. 还有一些其他的方法需要被实现.","slug":"golang/odm","date":"2022-03-12T04:12:37.000Z","categories_index":"go,mongo","tags_index":"go,mongodb,odm","author_index":"Rumple"},{"id":"24fa801b1de3778c9ca42278460e2c33","title":"k8s之heketi(四)","content":"前言  在上一篇中，我们搭建了GlusterFS分布式存储集群。其实搭建好之后就可以创建PV以及PVC进行使用了。但是K8S更进一步的提供一个高级抽象StorageClass, 他主要的作用是对用户设置的PVC申请屏 蔽后端存储的细节，一方面减少了用户对于存储资源细节的关注，另一方面减轻了管理员手工管理PV的工作，由系统自动完成PV的创建和绑定，实现了动态的资源供应。\n\nHeketi  heketi是一个提供RESTful API管理gfs卷的框架，能够在kubernetes、openshift、openstack等云平台上实现动态的存储资源供应，支持gfs多集群管理，便于管理员对gfs进行操作，在kubernetes集群中，pod将存储的请求发送至heketi，然后heketi控制gfs集群创建对应的存储卷。heketi动态在集群内选择bricks构建指定的volumes，以确保副本会分散到集群不同的故障域内。heketi还支持任意数量的glusterfs集群，以保证接入的云服务器不局限于单个glusterfs集群。\n  显而易见 如果我们要使用gfs驱动的StroageClass，就需要通过Heketi了。\n安装部署\n我们继续在K8S当中进行部署 heketi 服务,创建heketi.yaml\n  apiVersion: v1 # 分配账户\nkind: ServiceAccount\nmetadata:\n  name: heketi-service-account\n\n---\n\nkind: Role  # 分配权限\napiVersion: rbac.authorization.k8s.io&#x2F;v1\nmetadata:\n  name: heketi-role\nrules:\n  - apiGroups: [ &quot;&quot; ]\n    resources: [ &quot;pods&quot; ]\n    verbs: [ get,list,watch,create ]\n\n---\n\nkind: RoleBinding # 绑定权限\napiVersion: rbac.authorization.k8s.io&#x2F;v1\nmetadata:\n  name: heketi-rb\nsubjects:\n  - kind: ServiceAccount\n    name: heketi-service-account\nroleRef:\n  kind: Role\n  name: heketi-role\n  apiGroup: rbac.authorization.k8s.io\n\n---\nkind: Deployment\napiVersion: apps&#x2F;v1\nmetadata:\n  name: deploy-heketi\n  labels:\n    glusterfs: heketi-deployment\nspec:\n  selector:\n    matchLabels:\n      name: heketi-deploy\n  replicas: 1\n  template:\n    metadata:\n      name: heketi-deploy\n      labels:\n        name: heketi-deploy\n    spec:\n      nodeSelector:\n        heketi: &quot;yes&quot;\n      serviceAccountName: heketi-service-account\n      containers:\n        - name: heketi\n          image: heketi&#x2F;heketi:latest\n          ports:\n            - containerPort: 8080\n          env:\n            - name: HEKETI_CLI_SERVER\n              value: http:&#x2F;&#x2F;localhost:8080\n          volumeMounts:\n            - mountPath: &quot;&#x2F;var&#x2F;lib&#x2F;heketi&quot;\n              name: db\n          readinessProbe:\n            timeoutSeconds: 3\n            initialDelaySeconds: 3\n            httpGet:\n              port: 8080\n              path: &quot;&#x2F;hello&quot;\n          livenessProbe:\n            timeoutSeconds: 3\n            initialDelaySeconds: 30\n            httpGet:\n              port: 8080\n              path: &quot;&#x2F;hello&quot;\n      volumes:\n        - name: db\n          hostPath:\n            path: &quot;&#x2F;heketi-data&quot;\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: heketi-svc\n  labels:\n    glusterfs: heketi-service\nspec:\n  selector:\n    name: heketi-deploy\n  ports:\n    - port: 8080\n      name: heketi\n      targetPort: 8080\n\n执行 kubectl apply -f heketi.yaml\n\n创建 GFS 集群\n\n首先编写topology.json文件拷贝并进入到 heketi pod 当中&#123;\n  &quot;clusters&quot;: [\n    &#123;\n      &quot;nodes&quot;: [\n        &#123;\n          &quot;node&quot;: &#123;\n            &quot;hostnames&quot;: &#123;\n              &quot;manage&quot;: [\n                &quot;k8s-master&quot;\n              ],\n              &quot;storage&quot;: [\n                &quot;192.168.0.1&quot;\n              ]\n            &#125;,\n            &quot;zone&quot;: 1\n          &#125;,\n          &quot;devices&quot;: [\n            &quot;&#x2F;gluster-data&quot;\n          ]\n        &#125;,\n        &#123;\n          &quot;node&quot;: &#123;\n            &quot;hostnames&quot;: &#123;\n              &quot;manage&quot;: [\n                &quot;k8s-node-1&quot;\n              ],\n              &quot;storage&quot;: [\n                &quot;192.168.0.2&quot;\n              ]\n            &#125;,\n            &quot;zone&quot;: 1\n          &#125;,\n          &quot;devices&quot;: [\n            &quot;&#x2F;gluster-data&quot;\n          ]\n        &#125;,\n        &#123;\n          &quot;node&quot;: &#123;\n            &quot;hostnames&quot;: &#123;\n              &quot;manage&quot;: [\n                &quot;k8s-node-2&quot;\n              ],\n              &quot;storage&quot;: [\n                &quot;192.168.0.3&quot;\n              ]\n            &#125;,\n            &quot;zone&quot;: 1\n          &#125;,\n          &quot;devices&quot;: [\n            &quot;&#x2F;gluster-data&quot;\n          ]\n        &#125;\n      ]\n    &#125;\n  ]\n&#125;\n执行 heketi-cli --user admin --secret &#39;My Secret&#39; topology load --json=topology.json\n查看集群状态 heketi-cli --user admin --secret &#39;My Secret&#39; topology info\n\n\n创建 StorageClass\n  kind: Secret\napiVersion: v1\nmetadata:\n  name: heketi-secret\n  namespace: default\ndata:\n  key: xxxx   # echo -n &quot;your secret&quot; | base64\ntype: kubernetes.io&#x2F;glusterfs\n---\napiVersion: storage.k8s.io&#x2F;v1\nkind: StorageClass\nmetadata:\n  name: heketi-storage-class\nprovisioner: kubernetes.io&#x2F;glusterfs # 必须\nparameters:\n  resturl: &quot;http:&#x2F;&#x2F;ClusterIP:Port&quot;\n  restuser: &quot;admin&quot;\n  secretNamespace: &quot;default&quot;\n  secretName: &quot;heketi-secret&quot; \n  gidMin: &quot;40000&quot;\n  gidMax: &quot;50000&quot;\n  volumetype: &quot;replica:3&quot;\nPVC申请\n  kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: pvc-test\nspec:\n  storageClassName: heketi-storage-class\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi\n\n","slug":"k8s/4.k8s之Heketi","date":"2021-01-06T06:07:06.000Z","categories_index":"k8s","tags_index":"k8s,heketi,GlusterFS","author_index":"Rumple"},{"id":"60ad9b5a7955245986176acd6be5e193","title":"k8s之共享存储(GlusterFS)(三)","content":"K8S共享存储介绍\nK8S 对于有状态的容器应用 或者 需要数据持久化的数据应用，不仅需要将容器内的目录挂载到宿主机的目录或者emptyDir临时存储卷，而且需要更加可靠的存储来保存应用产生的重要数据，以便容器应用在重建之后仍然可以使用之前的数据。\n为了方便使用和管理，K8S实现了三种抽象资源，PersistentVolume（PV）和 PersistentVolumeClaim（PVC）以及 StorageClass,关于三者的概念解释，可以参考上一篇K8S基础概念理解。\n抽象的资源对象对应的其实是实际的存储服务，K8S支持非常多的存储服务，而本地最常用的 是NFS，CephFS 以及GlusterFS\n\nGlusterFS简介  GlusterFS 是一个可扩展，分布式文件系统，集成来自多台服务器上的磁盘存储资源到单一全局命名空间，提供共享文件存储。  特性：\n\n可以扩展到几PB容量\n支持处理数千个客户端\n兼容POSIX接口\n使用通用硬件，普通服务器即可构建\n能够使用支持扩展属性的文件系统，例如ext4，XFS\n支持工业标准的协议，例如NFS，SMB\n提供很多高级功能，例如副本，配额，跨地域复制，快照以及bitrot检测\n支持根据不同工作负载进行调优\n\n环境搭建\n首先K8S集群要先搭建好\nGlusterFS有两种安装方式，1 直接安装在K8S集群中（需要一些硬性条件），2 传统物理部署。这里由于我本地资源有限所以选择第二种。\n准备三台虚拟机，系统为centos7.x\n192.168.10.21\n192.168.10.22\n192.168.10.23\n\n\n安装，分别在每台机器执行如下命令\n安装源 yum -y install centos-release-gluster\n安装glusterfs组件 yum install -y glusterfs glusterfs-server glusterfs-fuse glusterfs-rdma glusterfs-geo-replication glusterfs-devel\n启动服务 systemctl enable --now glusterd\n\n\n集群配置\n修改每一台机器的hosts文件\n192.168.10.21127.0.0.1     gfs1\n192.168.10.22 gfs2\n192.168.10.23 gfs3\n192.168.10.22192.168.10.21 gfs1\n127.0.0.1     gfs2\n192.168.10.23 gfs3\n以此类推\n\n\n添加节点，假设我们在gfs1节点操作 gluster peer probe gfs2\ngluster peer probe gfs3\ngluster peer status\n\n\nvolume&gt; glusterfs volume 有几种模式1. DHT默认模式 \n也叫分布卷，将文件已hash算法随机分布到 一台服务器节点中存储。\n命令格式：gluster volume create test-volume server1:/exp1 server2:/exp2\nAFR复制模式\n\n\n创建volume 时带 replica x 数量: 将文件复制到 replica x 个节点中。\n命令格式：gluster volume create test-volume replica 2 transport tcp server1:/exp1 server2:/exp2\nStriped条带模式\n\n\n创建volume 时带 stripe x 数量： 将文件切割成数据块，分别存储到 stripe x 个节点中 ( 类似raid 0 )。\n命令格式：gluster volume create test-volume stripe 2 transport tcp server1:/exp1 server2:/exp2\n分布式条带模式（组合型）\n\n\n最少需要4台服务器才能创建。 创建volume 时 stripe 2 server &#x3D; 4 个节点： 是DHT 与 Striped 的组合型。\n命令格式：gluster volume create test-volume stripe 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4\n分布式复制模式（组合型）\n\n\n最少需要4台服务器才能创建。 创建volume 时 replica 2 server &#x3D; 4 个节点：是DHT 与 AFR 的组合型。\n命令格式：gluster volume create test-volume replica 2 transport tcp server1:/exp1 server2:/exp2　server3:/exp3 server4:/exp4 \n条带复制卷模式（组合型）\n\n\n最少需要4台服务器才能创建。 创建volume 时 stripe 2 replica 2 server &#x3D; 4 个节点： 是 Striped 与 AFR 的组合型。\n命令格式：gluster volume create test-volume stripe 2 replica 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4\n三种混合模式\n\n\n至少需要8台 服务器才能创建。 stripe 2 replica 2 , 每4个节点 组成一个 组。\n命令格式：gluster volume create test-volume stripe 2 replica 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4 server5:/exp5 server6:/exp6 server7:/exp7 server8:/exp8\n\n\n创建volume进行测试gluster volume create k8s-volume gfs1:&#x2F;app&#x2F;tv gfs2:&#x2F;app&#x2F;tv gfs3:&#x2F;app&#x2F;tv\n\n# 查看volume状态\ngluster volume info\n\n# 启动volume\ngluster volume start k8s-volume\nGlusterFS性能调整选项# 开启 指定 volume 的配额\ngluster volume quota k8s-volume enable\n\n# 限制 指定 volume 的配额\ngluster volume quota k8s-volume limit-usage &#x2F; 1TB\n\n# 设置 cache 大小, 默认32MB\ngluster volume set k8s-volume performance.cache-size 4GB\n\n# 设置 io 线程, 太大会导致进程崩溃\ngluster volume set k8s-volume performance.io-thread-count 16\n\n# 设置 网络检测时间, 默认42s\ngluster volume set k8s-volume network.ping-timeout 10\n\n# 设置 写缓冲区的大小, 默认1M\ngluster volume set k8s-volume performance.write-behind-window-size 1024MB\n搭建私有镜像仓库，使用volume1. 首先要创建gluster相关服务kind: Endpoints\napiVersion: v1\nmetadata:\n  name: glusterfs-cluster\nsubsets:\n  - addresses:\n      - ip: 192.168.10.21\n    ports:\n      - port: 24007\n  - addresses:\n      - ip: 192.168.10.22\n    ports:\n      - port: 24007\n  - addresses:\n      - ip: 192.168.10.23\n    ports:\n      - port: 24007\n\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: glusterfs-cluster\nspec:\n  ports:\n    - port: 340072. 正式使用apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: registry-pv\n  labels:\n    name: registry-pv\nspec:\n  capacity:\n    storage: 20Gi\n  accessModes:\n    - ReadWriteMany\n  persistentVolumeReclaimPolicy: Retain  # 回收策略  :: 保留,回收,删除\n\n  glusterfs:\n    endpoints: glusterfs-cluster\n    path: k8s_registry_volume\n    readOnly: false\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: registry-pvc\n\nspec:\n  accessModes:\n    - ReadWriteMany # 多节点挂载 这里的节点指的是 Node\n  resources:\n    requests:\n      storage: 20Gi\n  selector:\n    matchLabels:\n      name: registry-pv\n---\nkind: Deployment\napiVersion: apps&#x2F;v1\nmetadata:\n  name: registry-deploy\n  labels:\n    name: registry-deploy\nspec:\n  selector:\n    matchLabels:\n      name: registry\n  template:\n    metadata:\n      labels:\n        name: registry\n    spec:\n      containers:\n        - name: registry\n          image: registry:latest\n          imagePullPolicy: IfNotPresent\n          ports:\n            - containerPort: 5000\n          volumeMounts:\n            - mountPath: &quot;&#x2F;var&#x2F;lib&#x2F;registry&quot;\n              name: registry-data\n      volumes:\n        - name: registry-data\n          persistentVolumeClaim:\n            claimName: registry-pvc\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: registry\n  labels:\n    name: registry\nspec:\n  type: NodePort\n  ports:\n    - port: 5000\n      nodePort: 30003\n  selector:\n    name: registry  # pod labels\nDone!\n\n","slug":"k8s/3.k8s之共享存储","date":"2020-12-25T05:26:26.000Z","categories_index":"k8s","tags_index":"k8s,GlusterFS","author_index":"Rumple"},{"id":"3ded30373967d6211e6c798b6bf7e484","title":"k8s之基础概念理解(二)","content":"本篇主要来解释一下k8s繁多的概念  我觉得吧第一遍不用一定要全部理解，先大致过一下，以后会慢慢熟悉  K8S中的概念按我的理解把他分为这样两类：  架构类：所谓架构类，就是指K8S自身部署，调度，的一些组件和概念  服务类：就是针对我们自己的服务调度，部署，控制，所用到的概念\n\n架构类  首先，我们先看一张K8S的架构图。另外我们知道K8S是一个集群所以一定是有Master(管理节点)和Node(工作节点)  \n  这里我提取如下概念归类为架构部分\n\nMaster：k8s集群的大脑,负责管理和控制整个K8S集群。\nAPI-Server: 提供了HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程。\nScheduler: 负责资源调度（Pod 调度）的进程，相当于公交公司的“调度室”。\nControllerManager：Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的“大总管”。\nETCD： 一个强一致性的KV存储数据库，用来存放集群状态和配置，以及资源对象。\nkubedns：主要用来做服务发现，能够通过服务名称去访问服务\n\n\nNode： 集群中的其他节点称为Node,可以是物理机,也可以是虚拟机\nkubelet: 负责Pod对应的容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能。\nkube-proxy: 实现Kubernetes Service的通信与负载均衡机制的重要组件。\ndocker engine: Docker引擎，负责本机的容器创建和管理工作。(注意在K8S 1.20版本即将弃用)\n\n\nkubectl： k8s客户端\nkubeadm： 安装K8S集群的一个工具\n\n服务类Pod\n\n\n\n\n\n\n\n\nk8s最小的资源调度单元,每个pod都包含一个叫做跟容器的Pause容器,以及若干其他服务容器,服务容器共享Pause容器的资源,比如IP,Volume等. \n   一些特征:\n\n每个Pod都有一个唯一IP,所有不同主机上的Pod是可以直接进行通信的  \nPod中的一个容器挂了,k8s会重启Pod中所有的容器\n如果Pod所在Node宕机,那么Pod中所有的服务会被调度到别的Node上去运行\n\nLabel\n\n\n\n\n\n\n\n\nlabel就是一对键值对,可以附加到任何资源对象上,资源对象上也可以附加任意数量的label.主要用于区分分类管理  Label Selector 的一些filter语法\n\nname &#x3D;\nname !&#x3D;\nname in ()\nname not in ()\n\nReplication Controller(RC)\n\n\n\n\n\n\n\n\n定义了一个期望的场景，即声明某种Pod的副本数量在任意时刻都符合某个预期值\n   所以其定义包括如下部分\n\nPod期待的副本数量\n用于筛选目标Pod的Label Selector\n当Pod副本数量小于预期时,用于创建Pod的模板(Template)\n\nReplica Set\n\n\n\n\n\n\n\n\nRS是下一代的RC,功能比RC更强,RC的label selector只支持等式,而RS支持基于集合\n   特性:\n\n在大多数情况下，我们通过定义一个RC实现Pod的创建及副本数量的自动控制。\n在RC里包括完整的Pod定义模板。\nRC通过Label Selector机制实现对Pod副本的自动控制。\n通过改变RC里的Pod副本数量，可以实现Pod的扩容或缩容。\n通过改变RC里Pod模板中的镜像版本，可以实现Pod的滚动升级。\n\nDeployment\n\n\n\n\n\n\n\n\ndeployment是对于RC的进一步的升级,内部使用依旧是RC,其中最大的一个升级是可以随时知道当前pod的部署进度\n   一些典型场景:\n\n创建一个Deployment对象来生成对应的Replica Set并完成Pod副本的创建。\n检查Deployment的状态来看部署动作是否完成（Pod副本数量 是否达到预期的值）。\n更新Deployment以创建新的Pod（比如镜像升级）。\n如果当前Deployment不稳定，则回滚到一个早先的Deployment版本。\n暂停Deployment以便于一次性修改多个PodTemplateSpec的配置项，之后再恢复Deployment，进行新的发布。\n扩展Deployment以应对高负载。\n查看Deployment的状态，以此作为发布是否成功的指标。 \n清理不再需要的旧版本ReplicaSets。\n\nHorizontal Pod Autoscaler(HPA)\n\n\n\n\n\n\n\n\n横向自动扩缩容\n   衡量指标:\n\nCPUUtilizationPercentage: 目标Pod所有副本的cpu利用率的平均值\n应用程序自定义的度量指标，比如服务在每秒内的相应请求数（TPS或QPS）\n\nStatefulSet\n\n\n\n\n\n\n\n\n专门用来部署有状态的服务,比如一些中间件MySQL,Redis,Mongo集群等.\n   特性:\n\nStatefulSet里的每个Pod都有稳定、唯一的网络标识，可以用来发现集群内的其他成员。假设StatefulSet的名称为kafka，那么第1个Pod叫kafka-0，第2个叫kafka-1，以此类推。\nStatefulSet控制的Pod副本的启停顺序是受控的，操作第n个Pod时，前n-1个Pod已经是运行且准备好的状态。\nStatefulSet里的Pod采用稳定的持久化存储卷，通过PV或PVC来实现，删除Pod时默认不会删除与StatefulSet相关的存储卷（为了保证数据的安全）。\n\nDaemonSet\n\n\n\n\n\n\n\n\n当一种pod在每个Node必须部署且只能部署一个副部时,这就是DaemonSet\nService\n\n\n\n\n\n\n\n\nService就是微服务架构当中的微服务\n\nClusterIP: Service 独有,在整个生命周期内不变\nPodIP: \nNodeIP: 外部需要访问必须通过 Node IP通常会搭载一个外部LB,比如HAProxy\n\nJob &amp;&amp; CronJob\n\n\n\n\n\n\n\n\n同样是Pod控制器,但其中的任务只允许一次,运行完毕 就销毁了,而CronJob顾名思义 轮训的任务.\nVolume\n\n\n\n\n\n\n\n\nPod中能被多个容器所共享的目录\n   类型:\n\nemptyDir: 在pod分配到Node时创建,初始为空,无需指定宿主机上的路径,当pod被移除,也会被永久删除.\n主要作用:\n\n临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留。\n长时间任务的中间过程CheckPoint的临时保存目录。\n一个容器需要从另一个容器中获取数据的目录（多容器共享目录）。\n\n\nhostPath: 永久保存在宿主机上\n\nnfs: \n\niscsi：使用iSCSI存储设备上的目录挂载到Pod中。\n\nflocker：使用Flocker管理存储卷。\n\nglusterfs：使用开源GlusterFS网络文件系统的目录挂载到Pod中。\n\nrbd：使用Ceph块设备共享存储（Rados Block Device）挂载到Pod中。\n\ngitRepo：通过挂载一个空目录，并从Git库clone一个git repository以供Pod使用。\n\nsecret：一个Secret Volume用于为Pod提供加密的信息，你可以将定义在Kubernetes中的Secret直接挂载为文件让Pod访问。Secret Volume是通过TMFS（内存文件系统）实现的，这种类型的Volume总是不会被持久化的。\n\n\nPersistent Volume\n\n\n\n\n\n\n\n\nPV是一种独立的资源,是网络存储对应的一块存储,与Volume类似但有以下区别\n\nPV只能是网络存储，不属于任何Node，但可以在每个Node上访问。\nPV并不是被定义在Pod上的，而是独立于Pod之外定义的。 \nPV目前支持的类型包括：gcePersistentDisk、 AWSElasticBlockStore、AzureFile、AzureDisk、FC（Fibre Channel）、 Flocker、NFS、iSCSI、RBD（Rados Block Device）、CephFS、 Cinder、GlusterFS、VsphereVolume、Quobyte Volumes、VMware Photon、Portworx Volumes、ScaleIO Volumes和HostPath（仅供单机测试）。\n\nPersistent Volume Claim\n\n\n\n\n\n\n\n\nPVC则是用户对存储资源的一个“申请”。就像Pod“消费”Node的资源一样，PVC能够“消费”PV资源。PVC可以申请特定的存储空间和访问模式。\nStorageClass\n\n\n\n\n\n\n\n\n使用PVC“申请”到一定的存储空间仍然不能满足应用对存储设备的 各种需求。通常应用程序都会对存储设备的特性和性能有不同的要求， 包括读写速度、并发性能、数据冗余等更高的要求，Kubernetes从1.4版本开始引入了一个新的资源对象StorageClass，用于标记存储资源的特性和性能\nNamespaces\n\n\n\n\n\n\n\n\n用于多租户的资源隔离\nAnnotation\n\n\n\n\n\n\n\n\n注解:与Label类似,但是是用户自定义的,而Label是资源的元数据\nConfigMap\n\n\n\n\n\n\n\n\n解决了 docker 修改运行时配置必须挂载文件, 或者写入环境变量的问题.\n   典型用法:\n\n生成为容器内的环境变量。\n设置容器启动命令的启动参数（需设置为环境变量）。\n以Volume的形式挂载为容器内部的文件或目录。\n\nIngress\n\n\n\n\n\n\n\n\n可以理解为对外提供服务的负载均衡器或者叫代理，常见的有haproxy,nginx\nSecret\n\n\n\n\n\n\n\n\n对象类型用来保存敏感信息，例如密码、OAuth 令牌和 SSH 密钥。 将这些信息放在 secret 中比放在 Pod 的定义或者容器镜像中来说更加安全和灵活\n","slug":"k8s/2.k8s之基础概念理解","date":"2020-12-07T06:12:09.000Z","categories_index":"k8s","tags_index":"k8s","author_index":"Rumple"},{"id":"0fd644d7a8607c81bbe89c11e736a98e","title":"记一次磁盘满后引发的血案","content":"概要\n微服务项目， 部署于docker swarm集群\ndocker swarm集群 是一台物理服务器 + 物理服务器自身虚拟出来的 四个节点，也就是总共五个节点所组成。\n我们的中间件有 ELK, MySQL, Redis, RabbitMQ, DFS, ETCD，+上 大量的服务集群\n由于一些原因，我们的 master 一开始在一台虚拟机节点，nfs 也是，这也是导致这次问题的主要原因，虚拟节点磁盘太小了只有100G\n好在项目目前处于迭代开发，半上线试用的状态，影响到不是很大，但还是挺烦人的。\n\n\n详情  我们的共享数据卷是用 convoy 这个插件去进行管理的，但是一开始由于一些原因 server 部署在了 虚拟节点。 我们的服务日志，中间件的数据目录，全都是挂载在nfs当中。\n  所以，周末得时候，Duang的一声，zabbix 告警了，磁盘不足。但是由于我们公司环境特殊，没有申请过vpn还不太好登，所以就等到了周一过来解决。\n\n遇到这个问题的时候，想法就很简单啊，把历史日志删掉不就好了，再修改一下程序，不要备份所有的历史日志了。然而现实总是没那么简单，到公司查看的时候，docker daemon 直接挂了，convoy 创建的共享数据卷 也是直接消失了。\n查看了其他节点，都很正常，就是master挂了。\n检查其他节点的磁盘状况，df -h duang的一声 卡住了。 我严重怀疑就是nfs搞的鬼\nyum -y install strace\nstrace df -h debug, 果然是卡在了， &#x2F;mnt&#x2F;nfs 我们的共享卷\n那好办 我们先 umount -f /mnt/nfs, 然而告诉我们 device is busy\n有占用，fuser -m /mnt/nfs 查看一下pid kill掉，然鹅我这一步也是卡，不过没关系，因为我当然知道当前机器哪些服务在占用啦。\n重新部署项目，把集群 leader 以及 convoy server 都迁移到 物理机节点，过段时间再迁移到k8s吧。swarm有些地方还是挺难用的\n\n一些幸运的地方\n我们的数据都挂载出来了，所以数据完全没有丢失\n项目部署都是通过yaml编写配置文件 使用docker stack deploy -c xx.yaml ,所以部署也是问题不大，无非就是修改一些节点label的问题。\n\n","slug":"work/记一次磁盘满后引发的血案","date":"2020-12-07T05:37:12.000Z","categories_index":"work-record","tags_index":"工作记录","author_index":"Rumple"},{"id":"3ecf53fd0f043e7fd47d014c92e0e74b","title":"k8s之搭建环境(一)","content":"flag:从今天开始，我将更新K8S系列博文，从环境搭建，到K8S概念的详解，到在k8s上部署完整项目，乃至有可能对K8S的二次开发。未来可期\n\n\nMAC1. 安装docker-desktop，这个没什么好说的  docker\n2. 配置镜像仓库源进行加速  可以选择的源有很多\n\ndocker官方 https://registry.docker-cn.com\n网易 http://hub-mirror.c.163.com\n中科大 http://docker.mirrors.ustc.edu.cn\n\n  \n3. 拉取K8S镜像  众所周知，由于GFW，在不作特殊处理的情况下，K8S的镜像是拉不下来的，这里我们借用此项目来拉镜像k8s-for-docker-desktop\n\ngit clone https://github.com/AliyunContainerService/k8s-for-docker-desktop.git\n进入项目目录执行 ./load_images.sh (注意确认好自己的版本)\n开启K8S如果长时间没有成功开启，可以运行如下命令查看日志pred&#x3D;&#39;process matches &quot;.*(ocker|vpnkit).*&quot;\n || (process in &#123;&quot;taskgated-helper&quot;, &quot;launchservicesd&quot;, &quot;kernel&quot;&#125; &amp;&amp; eventMessage contains[c] &quot;docker&quot;)&#39;\n &#x2F;usr&#x2F;bin&#x2F;log stream --style syslog --level&#x3D;debug --color&#x3D;always --predicate &quot;$pred&quot;\n验证集群状态# 注意如果你配置了终端代理 这里可能会有问题 可以取消，或者在命令前加入 http_proxy&#x3D;&quot;&quot; https_proxy&#x3D;&quot;&quot;\nkubectl cluster-info\n默认master是不调度pod的，使用如下命令将master加入调度节点kubectl taint node k8s-master node-role.kubernetes.io&#x2F;master-\n# 恢复\nkubectl taint node k8s-master node-role.kubernetes.io&#x2F;master&#x3D;&quot;&quot;\n\n4. 配置Daskboard  K8S-DaskBoard\n\n安装 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml\n开启访问 kubectl proxy\n通过 http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 连接访问dashboard\n这里会有两种认证方式进行选择，1是token，2是配置文件.\n配置访问令牌TOKEN&#x3D;$(kubectl -n kube-system describe secret default| awk &#39;$1&#x3D;&#x3D;&quot;token:&quot;&#123;print $2&#125;&#39;)\nkubectl config set-credentials docker-for-desktop --token&#x3D;&quot;$&#123;TOKEN&#125;&quot;\necho $TOKEN\n将获得的token 填入认证框即可\n\n\n\nWindows (TODO)Linux  这里我们采用Centos7\n\n检查内核版本 uname -r 需要在3.10以上 (Master&amp;&amp;Node)\n关闭防火墙 systemctl disable firewalld &amp;&amp; systemctl stop firewalld (Master&amp;&amp;Node)\n配置系统参数(Master&amp;&amp;Node)yum -y install bridge-utils \nmodprobe bridge &amp;&amp; modprobe br_netfilter\n\ncat &lt;&lt;EOF &gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf\nnet.bridge.bridge-nf-call-ip6tables &#x3D; 1\nnet.bridge.bridge-nf-call-iptables &#x3D; 1\nEOF\nsysctl --system\n\n# 禁用 selinux\nsetenforce 0 \nsed -i &#39;s&#x2F;^SELINUX&#x3D;enforcing$\\|^SELINUX&#x3D;disabled$&#x2F;SELINUX&#x3D;permissive&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config\n\n# 关闭swap 取消自动挂载\nswapoff -a &amp;&amp; sed -i &quot;&#x2F;swap&#x2F;s&#x2F;^&#x2F;#&#x2F;&quot; &#x2F;etc&#x2F;fstab\n安装kubeadm(Master&amp;&amp;Node)cat &gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;kubebrnetes.repo &lt;&lt; EOF\n[kubernetes]\nname&#x3D;Kubernetes Respository\nbaseurl&#x3D;http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-x86_64&#x2F;\nenabled&#x3D;1\ngpgcheck&#x3D;0\nEOF\n\nyum clean all &amp;&amp; yum makecache faster\nyum -y install kubelet kubeadm kubectl --disableexcludes&#x3D;kubernetes\n\nsystemctl enable --now kubelet\n修改默认配置文件初始化集群\nMaster\nkubeadm config print init-defaults &gt; init-master.yaml\n修改配置文件中的 advertiseAddress 为你Master的ip地址, 修改imageRepository镜像仓库地址，我这里用的docker.io/gotok8s,如果你需要用到网络插件比如flannel，还需要修改podSubnet为其分配一个网段，注意不要跟宿主机冲突\n初始化，依次执行kubeadm config images pull --config=init-master.yaml &amp;&amp; kubeadm init --config=init-master.yaml\n\n\nNode\nkubeadm config print join-defaults &gt; init-node.yaml\n修改配置文件中apiServerEndpoint为你master的api服务地址，以及修改Token配置。\n\n\n\n\n安装网络插件flannel,在Master直接执行如下命令即可（注意修改文件中的网段分配地址）  kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;coreos&#x2F;flannel&#x2F;master&#x2F;Documentation&#x2F;kube-flannel.yml\n共享存储（这个我会单独开一篇进行讲解） \n说明\n加入集群节点的token有可能会失效（比如你过了一段时间新加一台机器），导致加入节点失败，这时候在master上执行kubeadm token create生成新的token加入即可\n\n\n\n","slug":"k8s/1.k8s之搭建环境","date":"2020-11-27T05:18:17.000Z","categories_index":"k8s","tags_index":"k8s","author_index":"Rumple"},{"id":"771a458cad4b66e91f1476adf7a25646","title":"关于Golang高并发高效率代码的一些实践","content":"Go的并发  Go语言是原生支持并发的，它和传统基于OS线程和进程的实现不同，Go语言的并发是基于用户态的并发，这种并发方式就变得非常轻量，能够轻松运行几万甚至是几十万的并发逻辑。因此使用Go开发的服务端应用采用的就是“协程模型”，每一个请求由独立的协程处理完成、\n\n并发模型  Go的并发属于CSP并发模型的一种实现，CSP并发模型的核心概念是：“不要通过共享内存来通信，而应该通过通信来共享内存”。这在Go语言中的实现就是Goroutine和Channel。\n\ngoroutine 是 go 的协程对象，用于创建协程并发执行任务的基本单元\nchannel 是一个并发安全的FIFO队列，用于协程之间的通信。\n\n\nGMP模型：Go的线程调度模型\n\nG (Goroutine)\nM (Machine): 对应系统内核线程\nP (Processor): 它包含了运行goroutine的资源，如果线程想运行goroutine，必须先获取P，P中还包含了可运行的G队列\n\n在Go中，线程(M)是运行(G)的实体，调度器处理器(P)的功能是把可运行的(G)分配到工作线程(M)上。调度：\n\nGlobalQueue: 全局队列，存放等待运行的G\nP’s LocalQuene: P的本地队列 同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建G时，G优先加入到P的本地队列，如果队列满了，则会把本地队列中一半的G移动到全局队列。\nP List: 所有的P都在程序启动时创建，并保存在数组中，默认和系统的逻辑cpu个数相同，可通过runtime.GOMAXPROCS(n)设置。\nM: 线程想执行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列拿一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。 go语言本身会设置M的最大数量默认为10000，但一般内核很难支持到这么多。可以通过debug.SetMaxThreads(n) 进行设置.\n\n虽然P和M总是在一起协作执行，但他们的数量却没有什么绝对性的关系，一个M阻塞了，P就会去创建另一个M或者切换另一个M。\n\n\n并发控制  go的并发特性是如此的简单易用，实际过程中，当然会大量用到，尤其涉及到网络I&#x2F;O的过程，比如RPC的调用，数据库，邮件等等。\n\n假设在一个API接口调用中，关联了3个RPC服务的调用，接口需要等待3个服务的返回结果。为了避免长时间等待，会用到超时的概念，在请求超时后，避免资源泄露，进行相关处理。\n在go中有两个模块与上述功能息息相关，写并发程序必会用到的\nContextpackage main\n\nimport (\n  &quot;context&quot;\n  &quot;fmt&quot;\n  &quot;time&quot;\n)\n\nfunc work(ctx context.Context) &#123;\n\n  for &#123;\n    select &#123;\n    case &lt;-ctx.Done(): &#x2F;&#x2F; context超时取消函数被触发结束任务\n      fmt.Println(&quot;任务被取消&quot;)\n      return\n    default:\n      time.Sleep(time.Second * 1)\n      fmt.Println(&quot;i am working&quot;)\n    &#125;\n  &#125;\n\n&#125;\n\nfunc main() &#123;\n  ctx, cancel :&#x3D; context.WithTimeout(context.Background(), 4*time.Second)\n\n  go work(ctx)\n  for i :&#x3D; 0; i &lt; 10; i++ &#123;\n    time.Sleep(2 * time.Second)\n  &#125;\n&#125;\nWaitGrouppackage main\n\nimport &quot;sync&quot;\n\nfunc work(wg *sync.WaitGroup) &#123;\n  defer wg.Done()\n&#125;\n\nfunc main() &#123;\n  wg :&#x3D; sync.WaitGroup&#123;&#125;\n  for i :&#x3D; 0; i &lt;&#x3D; 10; i++ &#123;\n    wg.Add(1)\n    go work(&amp;wg)\n  &#125;\n  wg.Wait()\n&#125;\n\n\n\n超时控制  合理的超时控制，对于构建大规模的可靠的微服务架构显得非常重要，不合理的设置将会导致整个调用链上的服务雪崩。  比如 我们有一个被很多上游服务依赖的服务 \bA, 由于一些原因，导致A的响应总是很慢，导致所有的上级服务都会阻塞在A的调用上，导致请求阻塞在A上无法释放，进而影响所有上级服务链。\n\n在go中server处理 就是每一个请求都会分配一个goroutine去进行handle，如果服务响应慢，阻塞，在高并发情况，下很容易造成段时间内的大量goroutine堆积，每个goroutine因为逻辑的不同占用不同大小的内存，很快服务就会吞噬掉内存。\n协程暴涨和内存使用激增会加剧 Go 调度器和运行时 GC 的负担，进而再次影响服务的处理能力，这种恶性循环会导致整个服务不可用。\n解决办法有蛮多种，不过不同的办法，适应的情况不同\n协程池，控制整体最大可运行的协程数量，从而进一步限制了内存的使用占用\n限流排队策略，比如令牌桶算法。 \nMoney(你懂的)\n在微服务中，有一个叫做熔断机制的东西，其实就是并发超时控制\n在一次完整的网络连接调用中，总共有三个部分会涉及到耗时，有耗时那就有可能超时，1.建立连接的时候，2.读取数据超时，3.写入数据超时。而go都提供了与之对应的控制函数     conn.SetReadDeadline(),conn.SetWriteDeadline() \n而当你使用成熟的微服务框架，熔断机制，可能只是其中的一个组件。\n\n\n\n\n\n性能  想要获得最好的程序性能，对程序进行性能分析，是必不可少的 比如：\n\nCPU使用分析\n协程调用栈\nGC日志\nTrace分析工具  好在这些功能 Go 自身都已经完整的提供了，\npprof\nGODEBUG=gctrace=1 go run main.go 2&gt; log_file \ngo tool trace\n\n\n\n一些写出高性能Go代码的点\n注重锁的使用，尽量做到锁变量而不要锁过程\n可以使用 CAS，则使用 CAS 操作\n针对热点代码要做针对性优化\n不要忽略 GC 的影响，尤其是高性能低延迟的服务\n合理的对象复用可以取得非常好的优化效果\n尽量避免反射，在高性能服务中杜绝反射的使用\n有些情况下可以尝试调优“GOGC”参数\n新版本稳定的前提下，尽量升级新的 Go 版本，因为旧版本永远不会变得更好\n优化业务逻辑，有时候很多逻辑仔细想想是有很大优化空间的。\n\n","slug":"golang/关于Golang高并发高效率代码的一些实践","date":"2020-11-18T09:49:19.000Z","categories_index":"go","tags_index":"go,高并发","author_index":"Rumple"},{"id":"517d2648b07f96d72267ed192f3c0c92","title":"查看日志相关的命令","content":"作为一名开发，查询过滤日志去debug 应该是基本功中的基本功了。今天详细介绍一下这些命令\n\n\n1. head  head 与 tail 是一对命令，从字面意思也可以看出其作用  head 是用来查看头部的内容，tail 用来查看尾部的内容  参数：    - -q 隐藏文件名    - -v 显示文件名    - -c &lt;字节&gt; 显示字节数    - -n &lt;行数&gt; 显示行数\n2. tail  这个相较与 head 就用的比较多了  参数：\n\n-f 循环读取\n-q 不显示处理信息\n-v 显示详细的处理信息\n-c&lt;数目&gt; 显示的字节数no\n-n&lt;行数&gt; 显示文件的尾部 n 行内容\n--pid=PID与-f合用,表示在进程ID,PID死掉之后结束\n-q, --quiet, --silent 从不输出给出文件名的首部\n-s, --sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒\n\n3. grep  grep用来过滤输出  参数：\n\n-a,--text 不忽略二进制的数据。\n-A&lt;显示行数&gt;,--after-context=&lt;显示行数&gt; 显示匹配值之后的n行内容\n-b,--byte-offset 标示出该行第一个字符的编号。\n-B&lt;显示行数&gt;,--before-context=&lt;显示行数&gt; 显示匹配值之前的n行内容\n-c,--count 计算符合样式的列数。\n-C&lt;显示行数&gt;,--context=&lt;显示行数&gt;或-&lt;显示行数&gt; 除了显示符合样式的那一行之外，并显示该行之前后的内容。\n-d &lt;动作&gt;,--directories=&lt;动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。\n-e&lt;范本样式&gt;,--regexp=&lt;范本样式&gt; 指定字符串做为查找文件内容的样式。\n-E,--extended-regexp 将样式为延伸的正则表达式来使用。\n-f&lt;规则文件&gt;,--file=&lt;规则文件&gt; 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。\n-F,--fixed-regexp 将样式视为固定字符串的列表。\n-G,--basic-regexp 将样式视为普通的表示法来使用。\n-h,--no-filename 在显示符合样式的那一行之前，不标示该行所属的文件名称。\n-H,--with-filename 在显示符合样式的那一行之前，表示该行所属的文件名称。\n-i,--ignore-case 忽略字符大小写的差别。\n-l,--file-with-matches 列出文件内容符合指定的样式的文件名称。\n-L,--files-without-match 列出文件内容不符合指定的样式的文件名称。\n-n,--line-number 在显示符合样式的那一行之前，标示出该行的列数编号。\n-o,--only-matching 只显示匹配PATTERN 部分。\n-q,--quiet或--silent 不显示任何信息。\n-r,--recursive 此参数的效果和指定”-d recurse”参数相同。\n-s,--no-messages 不显示错误信息。\n-v,--revert-match 显示不包含匹配文本的所有行。\n-V,--version 显示版本信息。\n-w,--word-regexp 只显示全字符合的列。\n-x,--line-regexp 只显示全列符合的列。\n-y 此参数的效果和指定”-i”参数相同。\n-m 匹配多少次\n\n4.Example\n持续输出最新的 50 行日志  tail -f -n 20 file.log \n持续输出最新 50 行日志中匹配 关键字ss的行  tail -f -n 50 file.log | grep &quot;ss&quot;\n持续输出最新 50 行日志中匹配 关键字ss的行 只匹配3次  tail -f -n 50 file.log | grep -m 3 &quot;ss&quot;\n持续输出最新 50 行日志中匹配 关键字ss的行 只匹配3次,并显示匹配项前后3行的内容  tail -f -n 50 file.log | grep -3 -m 3 &quot;ss&quot;\n\n","slug":"guide/查看日志相关的命令","date":"2020-11-18T07:38:28.000Z","categories_index":"操作指南","tags_index":"head,grep,tail","author_index":"Rumple"},{"id":"94d8fb994bc3cd6f390288bebd2dcdbe","title":"MySQL之MVCC","content":"什么是MVCC？  英文全称为Multi-Version Concurrency Control,即多版本并发控制。但说到低其实本质上就是乐观锁（逻辑锁）的一种实现。适用于读提交以及默认的可重复读 的隔离级别。\n原理  MVCC的实现，通过保存数据在某个时间点的快照来实现的。这意味着一个事务无论运行多长时间，在同一个事务里能够看到数据一致的视图。根据事务开始的时间不同，同时也意味着在同一个时刻不同事务看到的相同表里的数据可能是不同的。\n\n每行数据都存在一个版本，每次数据更新时都会更新该版本。\n修改时Copy出当前版本随意修改，各个事务之间无干扰。\n保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback）\nInnoDB的MVCC实现策略  在每一行数据中额外保存两个隐藏的列：当前行创建时的版本号和删除时的版本号（可能为空，其实还有一列称为回滚指针，用于事务回滚，不在本文范畴）。这里的版本号并不是实际的时间值，而是系统版本号。每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询每行记录的版本号进行比较。  每个事务又有自己的版本号，这样事务内执行CRUD操作时，就通过版本号的比较来达到数据版本控制的目。\n\n通过示例来看看是如何工作的\n假如我们有这样一张表\n  create table users (id int primary key not null auto_increment, name varchar(255) not null default &quot;&#x2F;&quot;);\n插入数据（insert）: 记录的版本号既是当前事务的版本号\n  insert into users values(1,&quot;rumple&quot;);\n  假设事务id为1，那么插入后的数据行为\n\n\n\nid\nname\ncreate version\ndelete version\n\n\n\n1\nrumple\n1\n\n\n\n\n更新\n\n先标记旧的那一行记录为已删除，并且版本号是事务版本号\n插入一行新的记录  比如：事务id为2更新name字段   update users set name&#x3D;&quot;lily&quot; where id&#x3D;1;\n\n\n\nid\nname\ncreate version\ndelete version\n\n\n\n1\nrumple\n1\n2\n\n\n1\nlily\n2\n\n\n\n\n\n\n删除：把事务版本号当做删除版本号\n  delete from users where id&#x3D;1;\n\n\n\nid\nname\ncreate version\ndelete version\n\n\n\n1\nlily\n2\n3\n\n\n\n查询：从上面的操作可以看出来，符合如下两个条件才能被查询出来\n\n删除版本号未指定或者大于当前事务版本号，用白话讲就是查询事务开启后需要确保读取的行没有被删除（事务id&#x3D;2的查询 依旧可查询到事务id&#x3D;3所删除的数据）\n创建版本号小于等于当前事务版本号，也就是说（事务id&#x3D;2的 只能读取到 create version &lt;&#x3D;2 的已提交数据）\n\n\n\n","slug":"mysql/MySQL之MVCC","date":"2020-11-11T09:46:56.000Z","categories_index":"MySQL","tags_index":"mysql","author_index":"Rumple"},{"id":"9675eb8263b3ddc03bf1d31763c2e083","title":"python调用rust与go生成的库文件","content":"Python,Rust,Go 我最喜欢的三门语言。  今天来搞一下 分别用rust&amp;&amp;go生成.so文件供python调用，顺便简单测试一下他们之间的性能差距\n版本\nPython: 3.8.6\nGo: 1.15.3\nRust: 1.49.0-nightly (25f6938da 2020-11-09)\n\n\n1. Rust\n编写python能用的库文件，我们需要用到pyo3这个项目（其实不用也可以，但是会比较吃藕，pyo3可以直接包装成python的数据类型,以及python的module。而且pyo3的功能不止如此）\n安装 rust版本分为 stable, beta 和 nightly 版本，pyo3目前需要使用nightly版本，所以我们先安装 nightly rustup install nightly\n# 如果已经安装过则升级\nrustup update nightly\n\n# 切换\nrustup default nightly\n修改.cargo配置文件 vim ~&#x2F;.cargo&#x2F;config\n 填入如下内容 [target.x86_64-apple-darwin]\nrustflags &#x3D; [\n  &quot;-C&quot;, &quot;link-arg&#x3D;-undefined&quot;,\n  &quot;-C&quot;, &quot;link-arg&#x3D;dynamic_lookup&quot;,\n]\n\n\n创建项目  cargo new r2py\n\n\n创建好后目录下会有一个Cargo.toml文件，内容如下  [package]\nname &#x3D; &quot;r2py&quot;\nversion &#x3D; &quot;0.1.0&quot;\nauthors &#x3D; [&quot;rumple&quot;]\nedition &#x3D; &quot;2018&quot;\n\n[dependencies]\n\n# 以下为手动添加依赖与配置部分\n[lib]\nname &#x3D; &quot;r2py&quot;\ncrate-type &#x3D; [&quot;cdylib&quot;]\n\n[dependencies.pyo3]\nversion &#x3D; &quot;*&quot;\nfeatures &#x3D; [&quot;extension-module&quot;]\n\n\n编写库文件   在src下创建lib.rs文件,我们来创建一个计算函数  use pyo3::prelude::*;\nuse pyo3::wrap_pyfunction;\n\n\n#[pyfunction]\nfn add(num: u64) -&gt; PyResult&lt;u64&gt; &#123;\n    let mut sum &#x3D; 0;\n\n    for i in 0..&#x3D;num &#123;\n        sum +&#x3D; i;\n    &#125;\n    Ok(sum)\n&#125;\n\n#[pymodule]\nfn r2p(_py: Python, m: &amp;PyModule) -&gt; PyResult&lt;()&gt; &#123;\n    m.add_wrapped(wrap_pyfunction!(add))?;\n    Ok(())\n&#125;\n编译：cargo build --release编译后会在src同级目录生成 target/release/libr2py.dylib,你也可以直接指定cargo配置文件中的crate-type去直接生成so文件，不过这里是一样的。\n把文件拷贝到我们的python测试目录待用。  cp target&#x2F;release&#x2F;libr2py.dylib  $&#123;yourdirectory&#125;&#x2F;r2py.so\n\n2. Go\n编写 libadd.go\n  package main\n\nimport &quot;C&quot;\n\n&#x2F;&#x2F;export add\nfunc add(num uint64) uint64 &#123;\n\n  var (\n    i, sum uint64   \n  )\n\n  for i &lt; num &#123;\n    i++\n    sum +&#x3D; i\n &#125;\n  return sum\n&#125;\n\nfunc main()  &#123;\n  \n&#125;\n\n编译\n  go build -buildmode&#x3D;c-shared -o libadd.so libadd.go\n\n3. 编写Python测试脚本  import time\nimport r2py # pyo3的好处。可以直接当做module导入\n\nfrom ctypes import cdll, c_ulonglong\n\ngo_lib &#x3D; cdll.LoadLibrary(&quot;.&#x2F;src&#x2F;libadd.so&quot;)\n# 处理数据类型 不然会溢出\ngo_add &#x3D; go_lib.add\ngo_add.restype &#x3D; c_ulonglong\n\n\nNUM_CONST &#x3D; 1000000000\n\n\ndef time_decorator(func):\n    def wrap():\n        start &#x3D; time.process_time()\n        a &#x3D; func()\n        end &#x3D; time.process_time()\n        print(f&quot;cost:&#123;end - start&#125; seconds&quot;)\n        return a\n\n    return wrap\n\n\n@time_decorator\ndef py_test():\n    s &#x3D; 0\n    for i in range(NUM_CONST + 1):\n        s +&#x3D; i\n    return s\n\n\n@time_decorator\ndef rust_test():\n    return r2py.add(NUM_CONST)\n\n\n@time_decorator\ndef go_test():\n    return go_add(NUM_CONST)\n\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    print(&quot;&#x3D;&quot; * 50)\n    print(f&quot;python 结果:&#123;py_test()&#125;&quot;)\n\n    print(&quot;&#x3D;&quot; * 50)\n    print(f&quot;rust 结果:&#123;rust_test()&#125;&quot;)\n\n    print(&quot;&#x3D;&quot; * 50)\n    print(f&quot;go 结果:&#123;go_test()&#125;&quot;)\n\n4.结果\n结果显而易见啦，不过这里让我惊奇的是 go 竟然比 rust 还要快一点，golang 牛逼。当然啦这里只是一个很简单的计算场景，孰强孰弱还需要更多不同场景的探索,而且他们所适用的方向可能也不太一样。但rust毕竟是号称新时代的底层语言，我觉得潜力还是很大的。\n","slug":"rust/python-rust-go","date":"2020-11-11T03:09:44.000Z","categories_index":"rust","tags_index":"go,python,rust","author_index":"Rumple"},{"id":"357905e1891b1f51272b4c207482f185","title":"github-ssh协议配置代理","content":"最近git连github经常抽风 使用 git config --global http.proxy的方式也没用的状态下，就想搞一下ssh协议走代理开搞\n配置 .ssh/config\n  Host github.com \nProxyCommand ~&#x2F;.ssh&#x2F;ssh-https-tunnel %h %p \nPort 443\nHostname ssh.github.com\n下载 ssh-https-tunnel\n  wget http:&#x2F;&#x2F;zwitterion.org&#x2F;software&#x2F;ssh-https-tunnel&#x2F;ssh-https-tunnel\n\n给脚本加上执行权限\n  chmod +x ~&#x2F;.ssh&#x2F;ssh-https-tunnel\n\n配置代理地址\n  vim ~&#x2F;.ssh&#x2F;ssh-https-tunnel\n# 将下面两项改为你自己的保存即可\nmy $proxy &#x3D; &quot;&quot;;\nmy $proxy_port &#x3D; ;\n\n","slug":"guide/github-ssh协议配置代理","date":"2020-11-10T07:10:01.000Z","categories_index":"操作指南","tags_index":"git","author_index":"Rumple"},{"id":"63b43d983c23e0729b58ec6fc65ef6d7","title":"详解MySQL的事务机制","content":"1. 什么是事务  事务就是一组原子性的sql查询，或者说一个独立的工作单元。即事务内的sql语句，要么全部执行成功，要么全部执行失败；\n2. ACID  我们都知道事务的四大特性\n\n原子性(atomicity)：一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，基于Redo&#x2F;Undo机制。\n一致性(consistency)：数据库总是从一个一致性状态转移到另一个一致性状态。\n隔离性(isolation)：通常来说，一个事务所做的修改在最终提交前，对其他事务都是不可见的。\n持久性(Durability)：一旦事务提交，则其所做的修改就会永久保存到数据库中；此时即使数据库崩溃，数据也不会丢失。\n\n3. 事务的隔离级别\n读未提交（READ-UNCOMMITTED）事务中的修改，即使没有提交，对其他事务也是可见的。读取未提交的数据称之为脏读，这个级别一般挺少使用\n读提交（READ-COMMITTED）这个级别是大多数数据库系统的默认隔离级别（但MySQL不是）。一个事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的。这个级别也叫作不可重复读（nonrepeatable read），因为两次执行同样的查询，可能会得到不一样的结果。\n可重复度（REPEATABLE—READ）MySQL的默认级别，在一个事务内的多次读取结果是一样的，在此级别下可以避免脏读，不可重复读等查询问题\n串行化（SERIALIZABLE）最高的隔离级别，强制事务读写串行执行，除了不会造成数据不一致的问题，没有其他优点\n\n4. 常见问题\n脏读（Dirty Reads）:一个事务正在访问并修改数据库中的数据但是没有提交，但是另外一个事务可能读取到这些已作出修改但未提交的数据。这样可能导致的结果就是所有的操作都有可能回滚，比如第一个事务对数据做出的修改可能违背了数据表的某些约束，破坏了完整性，但是恰巧第二个事务却读取到了这些不正确的数据造成它自身操作也发生失败回滚。 \n不可重复读取（Non-Repeatable Reads）：A 事务两次读取同一数据，B事务也读取这同一数据，但是 A 事务在第二次读取前B事务已经更新了这一数据。所以对于A事务来说，它第一次和第二次读取到的这一数据可能就不一致了。 \n幻读（Phantom Reads）:与不可重复读有点类似，都是两次读取，不同的是 A 事务第一次操作的比如说是全表的数据，此时 B 事务并不是只修改某一具体数据而是插入了一条新数据，而后 A 事务第二次读取这全表的时候就发现比上一次多了一条数据，发生幻觉了。 \n更新丢失（Lost Update）:更新丢失是指并发下两次更新同时进行，后一次更新覆盖了前一次更新的情况，更新丢失是数据没有保证一致性导致的。\n\n5. 问题剖析\n脏读和不可重复读在 可重复读的隔离机制下都可以直接避免\n幻读\n要说明的一点，幻读指的是新插入的行，原本存在的行 更新 结果 不算。\n影响：\n会造成一个事务中先产生的锁，无法锁住后加入的满足条件的行。\n产生数据一致性问题，在一个事务中，先对符合条件的目标行做变更，而在事务提交前有新的符合目标条件的行加入。这样通过binlog恢复的数据是会将所有符合条件的目标行都进行变更的。\n\n\n原因：\n行锁只能锁住行，即使把所有的行记录都上锁，也阻止不了新插入的记录。\n\n\n解决办法：\n将两行记录间的空隙加上锁，阻止新记录的插入；这个锁称为间隙锁。\n间隙锁与间隙锁之间没有冲突关系。跟间隙锁存在冲突关系的，是往这个间隙中插入一个记录这个操作。\n\n\n注意：\n由于 间隙锁 之间 是不互斥的，所以有可能会产生死锁问题。\n\n\n\n\n更新丢失\n解决办法：\n悲观锁：获取行的时候使用 select xxxx for update 主动加锁\n乐观锁：使用类似MVVC一样的处理办法加上版本控制 从逻辑上去加锁。\n\n\n\n\n死锁\n产生原因：\n两个事务都持有对方需要的锁，并且在等待对方释放，并且双方都不会释放自己的锁。\n\n\n解决办法：\n相互等待，直到时间超时（设置死锁超时时间innodb_lock_wait_timeout）\n发起死锁检测，主动回滚一条事务，让其他事务继续执行（innodb_deadlock_detect&#x3D;on）\n\n\n\n\n\n","slug":"mysql/详解MySQL的事务机制","date":"2020-11-10T05:56:05.000Z","categories_index":"MySQL","tags_index":"mysql,事务机制","author_index":"Rumple"},{"id":"44f9b4429be4a923b3d82ea9a6628937","title":"数据结构之链表","content":"1. 什么是链表  链表是由一组不必相连（可以连续也可以不连续）的内存结构节点，按特定的顺序链接在一起的抽象数据类型\n\n2. 链表的分类  链表常用的有三类，单链表 双向链表 循环链表, 循环链表又分为单项与双向  \n3. 用Python来实现单向循环链表,其他的大同小异  一般会抽象如下方法\n\nadd(item) 向链表添加数据项\nremove(item) 删除链表中的数据项\nexist(item) 数据是否存在于链表\nempty() 链表是否为空\nsize() 返回链表数据个数\n\n# 链表的一个节点\nclass Node(object):\n    def __init__(self, data&#x3D;None):\n        self.__data &#x3D; data\n        self.__next &#x3D; None\n\n    def get_data(self):\n        return self.__data\n\n    def set_data(self, data):\n        self.__data &#x3D; data\n\n    def get_next(self):\n        return self.__next\n\n    def set_next(self, node):\n        self.__next &#x3D; node\n\n\n# 单向循环链表\nclass LinkList(object):\n    def __init__(self):\n        self.head: Node &#x3D; Node()\n        # 初始化时,下一个节点的指针指向head\n        self.head.set_next(self.head)\n\n    # 添加节点\n    def add(self, item):\n        node &#x3D; Node(item)\n        # 将新节点的指针指向 head\n        node.set_next(self.head.get_next())\n        # 将head指针指向 新创建的node\n        self.head.set_next(node)\n\n    # 移除节点\n    def remove(self, item):\n        prev &#x3D; self.head\n        while prev.get_next() !&#x3D; self.head:\n            cur &#x3D; prev.get_next()\n\n            if cur.get_data() &#x3D;&#x3D; item:\n                prev.set_next(cur.get_next())\n\n            prev &#x3D; prev.get_next()\n\n    def exist(self, item) -&gt; bool:\n        cur &#x3D; self.head.get_next()\n        while cur !&#x3D; self.head:\n            if cur.get_data() &#x3D;&#x3D; item:\n                return True\n            cur &#x3D; cur.get_next()\n        return False\n\n    def empty(self):\n        return self.head.get_next() &#x3D;&#x3D; self.head\n\n    def size(self):\n        count &#x3D; 0\n        cur &#x3D; self.head.get_next()\n        while cur !&#x3D; self.head:\n            count +&#x3D; 1\n            cur &#x3D; cur.get_next()\n        return count\n\n\nif __name__ &#x3D;&#x3D; &quot;__main__&quot;:\n    s &#x3D; LinkList()\n    print(f&quot;s.empty() &#x3D;&#x3D; &#123;s.empty()&#125;, s.size() &#x3D;&#x3D; &#123;s.size()&#125;&quot;)\n\n    s.add(100)\n    s.add(99)\n    print(f&quot;s.empty() &#x3D;&#x3D; &#123;s.empty()&#125;, s.size() &#x3D;&#x3D; &#123;s.size()&#125;&quot;)\n\n    print(f&quot;100 &#123;&#39;&#39; if s.exist(100) else &#39;not&#39;&#125; in s&quot;)\n    print(f&quot;98 &#123;&#39;&#39; if s.exist(98) else &#39;not&#39;&#125; in s&quot;)\n    print(f&quot;s.empty() &#x3D;&#x3D; &#123;s.empty()&#125;, s.size() &#x3D;&#x3D; &#123;s.size()&#125;&quot;)\n\n    s.remove(99)\n    print(f&quot;s.empty() &#x3D;&#x3D; &#123;s.empty()&#125;, s.size() &#x3D;&#x3D; &#123;s.size()&#125;&quot;)","slug":"ds/数据结构之链表","date":"2020-10-30T05:14:02.000Z","categories_index":"数据结构","tags_index":"数据结构,链表","author_index":"Rumple"},{"id":"80648934d5c19eeef307e3bc1f9a947e","title":"数据结构之线性与非线性","content":"数据结构是计算机存储组织数据的方式，常见的数据结构分类如下图：\n\n\n线性结构\n什么是线性结构？  数据结构中线性结构指的是数据元素之间存在着 一对一 的线性关系的数据结构。线性结构是一个有序数据元素的集合。\n线性结构的特点- 线性结构有唯一的首元素（第一个元素）- 线性结构有唯一的尾元素（最后一个元素）- 除首元素外，所有的元素都有唯一的 前驱- 除尾元素外，所有的元素都有唯一的 后继- 数据元素之间存在 一对一 的关系，即除了第一个和最后一个数据元素之外，其它数据元素都是首尾相接的。\n例：数组 [a1,a2,a3.....an], a1为第一个元素，an为最后一个元素，此集合即为一个线性结构的集合。\n常见的线性结构\n线性表\n栈\n队列\n双队列\n循环队列\n一位数组\n字符串（简称串）线性表中包括顺序表、链表等，其中，栈和队列只是属于逻辑上的概念，实际中不存在，仅仅是一种思想，一种理念；线性表则是在内存中数据的一种组织、存储的方式。\n\n\n\n非线性结构\n什么是非线性结构  非线性结构中各个数据元素不再保持在一个线性序列中，数据元素之间是一对多，或者是多对一的关系。根据关系的不同，可分为层次结构 树 和群结构 图。\n特点  相对应于线性结构，非线性结构的逻辑特征是一个结点元素可能对应多个直接前驱和多个后继。\n常见的非线性结构\nn维数组（n&gt;&#x3D;2）\n树\n图\n广义表\n\n\n\n","slug":"ds/数据结构之线性与非线性","date":"2020-10-30T02:35:58.000Z","categories_index":"数据结构","tags_index":"数据结构","author_index":"Rumple"},{"id":"c9eed3f9b00e09f8e1c1149f26ce6969","title":"MySQL8的新特性","content":"MySQL的版本一下子跳跃这么大，用手指想就有很多新的东西了。下面我们就来详细了解一下。\n\n\n1. 秒级加列\n分别在5.7与8.0中有一张 test 表，数据为3000w行   # mysql8.0.22\nmysql&gt; alter table test add str varchar(200) not null default &#39;mysql8.0 新加字段&#39;;\nQuery OK, 0 rows affected (0.13 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\n# mysql5.7.30\nmysql&gt;  alter table test add str varchar(200) not null default &#39;mysql5.7 新加字段&#39;;\nQuery OK, 0 rows affected (6 min 8.36 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n可以看到 8.0 只需要 0.13 秒，而 5.7 需要 6分多钟！\n以前表加列操作需要重建表（消耗大量的IO资源和时间），8.0加列没有这个步骤。\n\n\n\n2. 性能提升      # mysql5.7.30\nmysql&gt; select count(*) from test;\n+----------+\n| count(*) |\n+----------+\n| 29991137 |\n+----------+\n1 row in set (3 min 12.24 sec)\n\n# mysql8.0.22\nmysql&gt; select count(*) from test;\n+----------+\n| count(*) |\n+----------+\n| 30000000 |\n+----------+\n1 row in set (45.70 sec)    可以看到三千万的数据量，8.0版本只需要45.70秒，而5.7版本需要3分12.24秒    分别在只更新和只读场景下，8.0相比5.7在高并发时性能提升近1倍；求表总数据量8.0响应时间也将近提升5倍。\n3. 文档数据库\nMySQL Document Store，NoSQL + SQL &#x3D; MySQL\n多文档事务，ACID特性\n支持更新JSON中部分字段  \n\n4. SQL增强\n公用表表达式（CTE）  关于CTE的详细介绍看这里 https://developer.aliyun.com/article/719994\n不可见索引（Invisible Indexes）将索引置为不可见时，SQL执行时查询优化器会忽略该索引；这样有助于我们了解该索引对查询语句的影响有多大。-- 将索引置为不可见\nalter table test alter index  index_name invisible;\n-- 置为可见\n......................................... visible;\n降序索引（Descending Indexes）在5.7的时候只支持升序索引，就算显式指定为降序，创建的还是升序。具体例子 降序索引详解\n函数索引（Functional Indexes）在之前的版本中我们知道，凡是涉及到计算以及函数的都无法使用索引。 那么现在这已经是过去式了  select * from test where year(date_) &#x3D; 2020;\n而且函数索引可以和普通索引组合为联合索引，就像普通索引与普通索引组合那样，相同的方法\n\n5. 默认字符集utf8mb4  mysql root@localhost:(none)&gt; show variables like &#39;%character%&#39;;\n+--------------------------+--------------------------------+\n| Variable_name            | Value                          |\n+--------------------------+--------------------------------+\n| character_set_client     | utf8                           |\n| character_set_connection | utf8                           |\n| character_set_database   | utf8mb4                        |\n| character_set_filesystem | binary                         |\n| character_set_results    | utf8                           |\n| character_set_server     | utf8mb4                        |\n| character_set_system     | utf8                           |\n| character_sets_dir       | &#x2F;usr&#x2F;share&#x2F;mysql-8.0&#x2F;charsets&#x2F; |\n+--------------------------+--------------------------------+\n8 rows in set\nTime: 0.028s\n\n可以更好的存储emojis\n可变长度编码字符的性能提升  \n\n6. 一致性查询改进\nSKIP LOCKED需要加锁的记录若被其它线程占有锁，则跳过，而不是等待\n  select * from test where age&#x3D;12 for update skip locked;\nEmpty set (0.00 sec)\n\nNOWAIT需要加锁的记录如果有锁，则会报错\n  select * from test where age&#x3D;12 for update nowait;\nERROR 3572 (HY000): Statement aborted because lock(s) could not be acquired immediately and NOWAIT is set.\n  这两个特性某种意义上替代了redis的作用。\n\n\n7. 资源组\n线程赋给不同的资源组\n资源组和不同的内存、IO、CPU(现仅支持)进行关联  \n\n8. 新的数据字典\n基于innodb的库表元数据信息\n增强了MySQL crash-safe能力\n原子DDL（ Atomic DDLs ）    以前版本MySQL数据字典存放在多个地方，一机器多实例时存在大量文件描述符性能消耗。\n\n  8.0版本都存放在事务性InnoDB表，MySQL异常挂掉后也不会再出现表损坏情况；DDL操作失败也不会再留下占空间的临时文件\n9. MGR 增强\n金融级别99.999%官方高可用方案\nMGR是业务多活(应用多活+数据库多活)的终极方案\n多个MySQL组成一个group，数据写group\n线上10套多主8.0 MGR集群    MGR的增强大大提升了在网络异常(机房级故障)下的健壮、稳定性\n\n10. 安全性增强  # SQL角色\nSQL Roles      \n# 原子ACL语句\nAtomic ACL Statements       \n# 动态特权\nDynamic Privileges          \n# 防止暴力攻击\nProtection Against Brute Force Attacks     \n# REDO &amp; UNDO Logs加密\nREDO &amp; UNDO Logs Encryption        \n# 缓存Sa2认证插件\nCaching sha2 authentication plugin     \n# 密码轮询策略\nPassword Rotation Policy        \n\n11. 复制增强  # binlog中额外的Metadata\nAdditional Metadata in the binary log      \n\n# 高效的json复制 \nEfficient JSON Replication \n\n# 监控复制延迟细到毫秒\nMonitor Replication Lag with Microsecond Precision \n\n# 组复制更多的P_S\nMore P_S Instrumentation for Group Replication \n\n# 默认启动了binlog\nEnable binary log by default   \n\n# 基于Writeset-based Dependency Tracking的并行应用\nImproving the Parallel Applier with Writeset-based Dependency Tracking \n\n# 组复制白名单中支持主机名\nHostname support in Group Replication Whitelist    \n\n12. 实例克隆\n以前都是要备份恢复，再加入主从复制\n现在可以在原目标实例上直接安装克隆插件 授权进行克隆\n\n13. 全局变量持久化  以前我们在客户端执行MySQL配置，都是暂时性的，MySQL重启后就会失效。想永久设置只能修改配置文件。8.0版本直接通过SQL命令，就可以直接永久配置。\n\nset persist会在设置当前全局变量的前提下，将其保存到 mysqld-auto.cnf 文件中，这个命令需要有这个权限：system_variables_admin，才能执行\nset persist_only只会将其保存到 mysqld-auto.cnf 文件中，而不会设置当前全局变量，这对只读全局变量有用，这个命令需要有这个权限：persist_ro_variables_admin，才能执行\n\n14. 其他\n优化器直方图\n自增主键持久化\n移除Query Cache\nGIS增强\n备份锁\ngroup by 不再隐式排序\nredo_log优化、多线程并发写log buffer\n\n","slug":"mysql/MySQL8的新特性","date":"2020-10-29T07:36:48.000Z","categories_index":"MySQL","tags_index":"mysql","author_index":"Rumple"},{"id":"e31f27ca5c997bccd8e8b4c8d00251b5","title":"讲明白倒排索引","content":"要搞明白倒排索引我们就要先搞明白什么是正排索引\n\n对于搜索引擎来讲，正排索引是文档id到文档内容以及单词的关联关系，也就是说通过id获取到文档的内容，如果拿关系型数据库来解释就是下面这条SQL\nselect * from human where id &#x3D; 3;\n\n\n倒排索引 是通过单词 找到文档id 这一过程，然后再使用正排索引 通过id找到文档内容返回给搜索用户。\n\n在倒排索引中有这么几个概念\n\n单词（Term）: 一段文本经过分词器分词后就会得到一系列的单词\n单词词典（Term Dictionary）: 记录所有的文档分词后的结果，顾名思义就是维护 单词（Term）\n单词索引(Term Index) : 为了更快找出单词，给单词简历索引\n倒排列表（Posting List）: 记录了单词对应文档的集合，由倒排项（Posting）组成\n倒排项（Posting）: 倒排项主要包含以下信息\n文档ID ：用于获取原始文档信息\n单词频率（TF，Term Frequency）: 记录该单词在文档中出现的次数\n位置（Position）: 记录单词在文档中的分词位置，用于词语搜索\n偏移量（Offset）: 记录单词在文档的开始和结束位置，用于高亮显示\n\n\n\n\n\n这里用一张图\n用通俗的话来描述整个流程就是\n我们拿着 单词词典 通过 单词索引 找到 单词，找到 单词 就可以找到对应的 文档列表，然后通过文档列表中的数据进行一系列的计算，做一个优先级排序，或者叫评分排序，评分越高则在最前面，最后将所有结果返回。\n","slug":"es/讲明白倒排索引","date":"2020-10-28T09:24:17.000Z","categories_index":"es","tags_index":"倒排索引","author_index":"Rumple"},{"id":"bd281a987a5c824ac404d854e69b882e","title":"关于RabbitMQ消息队列的可靠性传输","content":"在使用消息队列的过程中如何保证消息的可靠性呢？这个问题其实包含了几方面的小问题。\n\n数据丢失问题\n数据幂等性的问题\n重复消费的问题\n\n\n我们知道在使用消息队列的时候是必然有三个角色的，生产者，消费者，以及MQ本身。那么数据丢失无非就以下几种情况\n\n生产者传输给MQ 这个过程丢失数据，导致MQ未获取到消息\nMQ收到消息，但是自身宕机，把消息给弄丢了。\nMQ将消息传输给消费者，消费者接收到消息，但是还没处理 挂掉了。导致消息丢失。\n\n解决办法：\n\n第一种情况有两种解决办法\n\n是在生产者开启MQ的事务机制，整个流程和数据库事务差不多，但是这种方法完全不推荐。首先事务机制会大幅降低MQ的吞吐量和性能。其次，我们用MQ本来就是追求一个异步的消息传输过程，当开启事务时，所有的一系列流程就变成了同步阻塞。\n在生产者开启confirm模式(推荐)，开启confirm模式之后 每一条消息mq都会返回给你一个ack信息，用来通知你消息是发送成功还是失败。而且这整个过程是异步的。下面用go的代码做一下示例： package main\n\nimport (\n  &quot;fmt&quot;\n  &quot;github.com&#x2F;streadway&#x2F;amqp&quot;\n  &quot;log&quot;\n)\n\nfunc main() &#123;\n  var (\n    err  error\n    conn *amqp.Connection\n    ch   *amqp.Channel\n    q    amqp.Queue\n  )\n  if conn, err &#x3D; amqp.Dial(&quot;amqp:&#x2F;&#x2F;guest:guest@localhost:5672&#x2F;&quot;); err !&#x3D; nil &#123;\n    log.Fatalf(&quot;连接MQ失败:%s&quot;, err.Error())\n  &#125;\n\n  defer func() &#123;\n    _ &#x3D; conn.Close()\n  &#125;()\n\n  &#x2F;&#x2F; 打开一个channel\n  if ch, err &#x3D; conn.Channel(); err !&#x3D; nil &#123;\n    log.Fatalf(&quot;获取channel失败:%s&quot;, err.Error())\n  &#125;\n\n  defer func() &#123;\n    _ &#x3D; ch.Close()\n  &#125;()\n\n  &#x2F;&#x2F; 声名队列\n  if q, err &#x3D; ch.QueueDeclare(\n    &quot;hallo&quot;,\n    false,\n    false,\n    false,\n    false,\n    nil,\n  ); err !&#x3D; nil &#123;\n    log.Fatalf(&quot;声明队列失败:%s&quot;, err.Error())\n  &#125;\n\n  confirm :&#x3D; ch.NotifyPublish(make(chan amqp.Confirmation))\n  if err &#x3D; ch.Confirm(false); err !&#x3D; nil &#123;\n    log.Fatalf(&quot;开启confirm模式失败:%s&quot;, err.Error())\n  &#125;\n\n  go func() &#123;\n    for i :&#x3D; 0; i &lt;&#x3D; 10; i++ &#123;\n      if err &#x3D; ch.Publish(\n        &quot;&quot;,\n        q.Name,\n        false,\n        false,\n        amqp.Publishing&#123;\n          ContentType: &quot;text&#x2F;plain&quot;,\n          Body:        []byte(fmt.Sprintf(&quot;%d&quot;, i)),\n        &#125;,\n      ); err !&#x3D; nil &#123;\n        log.Printf(&quot;推送消息失败:%s&quot;, err.Error())\n        continue\n      &#125;\n    &#125;\n  &#125;()\n\n  for i :&#x3D; 0; i &lt;&#x3D; 10; i++ &#123;\n\n    ack :&#x3D; &lt;-confirm\n    if ack.Ack &#123;\n      &#x2F;&#x2F; 消息发送成功\n    &#125; else &#123;\n      &#x2F;&#x2F; 消息发送失败\n      &#x2F;&#x2F; 写你想要的逻辑\n    &#125;\n    log.Println(ack.DeliveryTag)\n  &#125;\n&#125;\n\n\n第二种情况，MQ消息丢失\n\n这个时候就需要开启MQ的数据持久化模式了。\n持久化包括三个部分： &#x2F;&#x2F; 1. exchange 的持久化 \n&#x2F;&#x2F; 声明exchange 时将 durable设置为True\nch.ExchangeDeclare(\n  &quot;logs&quot;, &#x2F;&#x2F; name\n  amqp.ExchangeFanout, &#x2F;&#x2F; kind \n  true, &#x2F;&#x2F; durable\n  false, &#x2F;&#x2F; autoDelete\n  false, &#x2F;&#x2F; internal  是否为内置交换机\n  false, &#x2F;&#x2F; noWait\n  nil,   &#x2F;&#x2F; args\n)\n\n&#x2F;&#x2F; 2. queue 持久化\n&#x2F;&#x2F; 同样的在声明时 将 durable设置为True\nch.QueueDeclare(\n  &quot;hallo&quot;, &#x2F;&#x2F; name 队列名称\n  true,  &#x2F;&#x2F; durable 是否持久化\n  false, &#x2F;&#x2F; autoDelete \n  false, &#x2F;&#x2F; exclusive 排他性\n  false, &#x2F;&#x2F; noWait \n  nil, &#x2F;&#x2F; args\n)\n\n&#x2F;&#x2F; 3. message 持久化\n&#x2F;&#x2F; 发送消息时将 delivery_mode 设置为2\nch.Publish(\n  &quot;logs&quot;, &#x2F;&#x2F; exchange\n  &quot;&quot;,     &#x2F;&#x2F; routing key\n  false,  &#x2F;&#x2F; mandatory 无法路由的消息是否返回处理\n  false,  &#x2F;&#x2F; immediate 是否对路由到无消费者队列的消息进行返回处理\n  amqp.Publishing&#123;\n    ContentType: &quot;text&#x2F;plain&quot;,\n    Body:        []byte(&quot;hallo world&quot;),\n    DeliveryMode: 2,\n  &#125;,\n)\n\n注意：\nexchange 和 queue 如果一个为持久化一个不为持久化，那么他们之间就不能进行绑定\n如果都为持久化，那么绑定也是持久化的\n设定持久化之后是不允许修改的，唯一途径是删除重建。\n即使你做了持久化，也还是不能完全的保证 数据不丢失，比如MQ在持久化之前挂掉了，那当时内存的数据就真的丢失了，只是这种情况的概率非常小。\n这一部分还可以引申出 rabbitmq 搭建高可用集群这一话题，这里就不详细讲了。简单描述一下，rmq的集群模式分为两种，一种是普通模式，比如有两个节点，那么queue只需要存在于其中一个节点即可，每个节点的数据是不同的。第二种是镜像模式，节点与节点之间会主动同步数据，这种优点和缺点都是显而易见的。反正根据自己的实际情况来选择。当然了有钱直接阿里云他不香吗。\n\n\n\n\n第三种情况就需要启用我们的ack机制了，就是当我们消费处理完毕的时候，去给mq返回一个ack确认信息。\nif msgs, err &#x3D; ch.Consume(\n  q.Name, &#x2F;&#x2F; name\n  &quot;&quot;,     &#x2F;&#x2F; consumer\n  false,   &#x2F;&#x2F; 是否自动ack\n  false,   &#x2F;&#x2F; exclusive 排他\n  false,   &#x2F;&#x2F; noLocal\n  false,   &#x2F;&#x2F; noWait\n  nil,     &#x2F;&#x2F; args\n); err !&#x3D; nil &#123;\n  log.Fatalf(&quot;获取消费队列失败:%s&quot;, err.Error())\n&#125;\n\nfor d :&#x3D; range msgs &#123;\n  &#x2F;&#x2F; 处理消息逻辑\n  if err &#x3D; d.Ack(false); err !&#x3D; nil &#123;\n    log.Printf(&quot;确认消息失败:%s&quot;, err.Error())\n  &#125;\n  log.Printf(&quot;收到消息:%s&quot;, d.Body)\n&#125;\n\n","slug":"mq/关于RabbitMQ消息队列的可靠性传输","date":"2020-10-28T05:21:20.000Z","categories_index":"消息队列","tags_index":"rabbitmq","author_index":"Rumple"},{"id":"6861080263609c8f32ead8d0fe52b3fb","title":"理解设计模式之访问者模式","content":"访问者模式主要是为了解决 稳定数据结构与变化的数据操作 耦合的问题。可以给一系列对象透明的添加功能，并且把相关代码封装到一个类中。对象只要预留访问者接口Accept则后期为对象添加功能的时候就不需要改动对象。\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 定义访问者接口\ntype IVisitor interface &#123;\n\tVisit(IElement)\n&#125;\n\n&#x2F;&#x2F; 定义生产环境访问者\ntype VisitorProduct struct &#123;\n\tname string\n&#125;\n\nfunc (c *VisitorProduct) Visit(ce IElement) &#123;\n\tfmt.Printf(&quot;%s 访问:%s&quot;, c.name, ce.Name())\n&#125;\n\n&#x2F;&#x2F; 定义测试环境访问者\ntype VisitorTesting struct &#123;\n\tname string\n&#125;\n\nfunc (c *VisitorTesting) Visit(ce IElement) &#123;\n\tfmt.Printf(&quot;%s 访问:%s&quot;, c.name, ce.Name())\n&#125;\n\n&#x2F;&#x2F; 元素接口\ntype IElement interface &#123;\n\tAccept(IVisitor)\n\tName() string\n&#125;\n\ntype ElementProduct struct &#123;\n\tname string\n&#125;\n\nfunc (c *ElementProduct) Accept(visitor IVisitor) &#123;\n\tvisitor.Visit(c)\n&#125;\n\nfunc (c *ElementProduct) Name() string &#123;\n\treturn c.name\n&#125;\n\ntype ElementTesting struct &#123;\n\tname string\n&#125;\n\nfunc (c *ElementTesting) Accept(visitor IVisitor) &#123;\n\tvisitor.Visit(c)\n&#125;\n\nfunc (c *ElementTesting) Name() string &#123;\n\treturn c.name\n&#125;\n\nfunc main() &#123;\n\tep :&#x3D; &amp;ElementProduct&#123;name: &quot;生产环境数据&quot;&#125;\n\tvp :&#x3D; &amp;VisitorProduct&#123;name: &quot;rumple&quot;&#125;\n\tep.Accept(vp)\n&#125;\n","slug":"golang/dp/理解设计模式之访问者模式","date":"2020-10-27T08:17:55.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"4d590d0702a24ddaf8b311434285f6b8","title":"理解设计模式之责任链模式","content":"责任链模式：分离不同职责 动态的组合相关责任链责任链上的处理者负责处理请求。客户端只需要发送即可这里举一个 通俗易懂的例子，叫家人帮我买手机！\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 定义一个购买手机的需求\ntype Require struct &#123;\n\tphone string\n\tprice int\n&#125;\n\n&#x2F;&#x2F; 定义处理请求的接口\ntype Handler interface &#123;\n\tProcessRequire(require *Require)\n&#125;\n\n&#x2F;&#x2F; 定义一系列可以帮我买手机的家人们\n&#x2F;&#x2F; 当前的处理者处理不了请求,就要传给下一位,因此每位处理者需要保存下一位处理者的指针\ntype (\n\tFather struct &#123;\n\t\tnext Handler\n\t&#125;\n\n\tMother struct &#123;\n\t\tnext Handler\n\t&#125;\n\n\tGrandFather struct &#123;\n\t\tnext Handler\n\t&#125;\n\n\tGrandMother struct &#123;\n\t&#125;\n)\n\nfunc (h *Father) ProcessRequire(require *Require) &#123;\n\n\tif require &#x3D;&#x3D; nil &#123;\n\t\treturn\n\t&#125;\n\n\tif require.price &lt;&#x3D; 500 &#123;\n\t\tfmt.Println(&quot;爸爸帮你买了!&quot;)\n\t&#125; else &#123;\n\t\th.next.ProcessRequire(require)\n\t\tfmt.Println(&quot;爸爸买不起交给妈妈&quot;)\n\t&#125;\n&#125;\n\n&#x2F;&#x2F; 略\n","slug":"golang/dp/理解设计模式之责任链模式","date":"2020-10-27T07:56:07.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"f06ad8235feac5c0bb5f9c61b04ab4af","title":"理解设计模式之解释器模式","content":"解释器模式定义一套语言文法，并设计该语言解释器，使用户能使用特定文法控制解释器行为。解释器模式的意义在于，它分离多种复杂功能的实现，每个功能只需关注自身的解释。对于调用者不用关心内部的解释器的工作，只需要用简单的方式组合命令就可以。\n\npackage main\n\nimport &quot;fmt&quot;\n\ntype Node interface &#123;\n\tInterpret() int\n&#125;\n\ntype ValueNode struct &#123;\n\tval int\n&#125;\n\nfunc (n *ValueNode) Interpret() int &#123;\n\treturn n.val\n&#125;\n\ntype AddNode struct &#123;\n\tleft  Node\n\tright Node\n&#125;\n\nfunc (n *AddNode) Interpret() int &#123;\n\treturn n.left.Interpret() + n.right.Interpret()\n&#125;\n\ntype SubNode struct &#123;\n\tleft  Node\n\tright Node\n&#125;\n\nfunc (n *SubNode) Interpret() int &#123;\n\treturn n.left.Interpret() - n.right.Interpret()\n&#125;\n\nfunc main() &#123;\n\tv :&#x3D; &amp;ValueNode&#123;val: 11&#125;\n\tb :&#x3D; &amp;ValueNode&#123;val: 12&#125;\n\n\tsub :&#x3D; &amp;SubNode&#123;v, b&#125;\n\tfmt.Println(sub.Interpret())\n&#125;","slug":"golang/dp/理解设计模式之解释器模式","date":"2020-10-27T07:28:27.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"31a528ce1cc912e617e7cd21630fdad9","title":"理解设计模式之备忘录模式","content":"备忘录，字面意思，一般会用来保存程序快照。或者 将内部程序的状态暴露给 外部，而不展示具体细节\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 定义备忘录接口\ntype Memo interface &#123;\n\tSave() Memo\n&#125;\n\n&#x2F;&#x2F; 游戏对象\ntype Game struct &#123;\n\thp, mp int\n&#125;\n\nfunc (g *Game) Play(mpDelta, hpDelta int) &#123;\n\tg.mp +&#x3D; mpDelta\n\tg.hp +&#x3D; hpDelta\n&#125;\n\n&#x2F;&#x2F; 保存快照\nfunc (g *Game) Save() Memo &#123;\n\treturn &amp;Game&#123;\n\t\thp: g.hp,\n\t\tmp: g.mp,\n\t&#125;\n&#125;\n\nfunc (g *Game) Load(m Memo) &#123;\n\tgm :&#x3D; m.(*Game)\n\tg.mp &#x3D; gm.mp\n\tg.hp &#x3D; gm.hp\n&#125;\n\nfunc (g *Game) Status() &#123;\n\tfmt.Printf(&quot;Current HP:%d, MP:%d\\n&quot;, g.hp, g.mp)\n&#125;\n\nfunc main()  &#123;\n\t&#x2F;&#x2F; pass\n&#125;","slug":"golang/dp/理解设计模式之备忘录模式","date":"2020-10-27T07:08:52.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"57343b3b347c194726d5fcd7c1e57903","title":"理解设计模式之状态模式","content":"状态模式没啥好说的，就是用来分离行为与状态的。直接看例子\n\n\npackage main\n\nimport &quot;fmt&quot;\n\ntype Week interface &#123;\n\tToday()\n\tNext(*DayContext)\n&#125;\n\ntype DayContext struct &#123;\n\ttoday Week\n&#125;\n\nfunc NewDayContext() *DayContext &#123;\n\treturn &amp;DayContext&#123;\n\t\ttoday: &amp;Sunday&#123;&#125;,\n\t&#125;\n&#125;\n\nfunc (d *DayContext) Today() &#123;\n\td.today.Today()\n&#125;\n\nfunc (d *DayContext) Next() &#123;\n\td.today.Next(d)\n&#125;\n\ntype Sunday struct&#123;&#125;\n\nfunc (*Sunday) Today() &#123;\n\tfmt.Printf(&quot;Sunday\\n&quot;)\n&#125;\n\nfunc (*Sunday) Next(ctx *DayContext) &#123;\n\tctx.today &#x3D; &amp;Monday&#123;&#125;\n&#125;\n\ntype Monday struct&#123;&#125;\n\nfunc (*Monday) Today() &#123;\n\tfmt.Printf(&quot;Monday\\n&quot;)\n&#125;\n\nfunc (*Monday) Next(ctx *DayContext) &#123;\n\tctx.today &#x3D; &amp;Tuesday&#123;&#125;\n&#125;\n\ntype Tuesday struct&#123;&#125;\n\nfunc (*Tuesday) Today() &#123;\n\tfmt.Printf(&quot;Tuesday\\n&quot;)\n&#125;\n\nfunc (*Tuesday) Next(ctx *DayContext) &#123;\n\tctx.today &#x3D; &amp;Wednesday&#123;&#125;\n&#125;\n\ntype Wednesday struct&#123;&#125;\n\nfunc (*Wednesday) Today() &#123;\n\tfmt.Printf(&quot;Wednesday\\n&quot;)\n&#125;\n\nfunc (*Wednesday) Next(ctx *DayContext) &#123;\n\tctx.today &#x3D; &amp;Thursday&#123;&#125;\n&#125;\n\ntype Thursday struct&#123;&#125;\n\nfunc (*Thursday) Today() &#123;\n\tfmt.Printf(&quot;Thursday\\n&quot;)\n&#125;\n\nfunc (*Thursday) Next(ctx *DayContext) &#123;\n\tctx.today &#x3D; &amp;Friday&#123;&#125;\n&#125;\n\ntype Friday struct&#123;&#125;\n\nfunc (*Friday) Today() &#123;\n\tfmt.Printf(&quot;Friday\\n&quot;)\n&#125;\n\nfunc (*Friday) Next(ctx *DayContext) &#123;\n\tctx.today &#x3D; &amp;Saturday&#123;&#125;\n&#125;\n\ntype Saturday struct&#123;&#125;\n\nfunc (*Saturday) Today() &#123;\n\tfmt.Printf(&quot;Saturday\\n&quot;)\n&#125;\n\nfunc (*Saturday) Next(ctx *DayContext) &#123;\n\tctx.today &#x3D; &amp;Sunday&#123;&#125;\n&#125;\n\nfunc main() &#123;\n\ttd :&#x3D; NewDayContext()\n\ttd.Next()\n\ttd.Today()\n&#125;\n","slug":"golang/dp/理解设计模式之状态模式","date":"2020-10-27T06:58:29.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"8edf5cc3c2cccf16484400f87c198799","title":"理解设计模式之策略模式","content":"策略模式一般是用来封装一系列的算法，让这些算法可以在运行时互换。复合开闭原则\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 定义付款对象\ntype Payment struct &#123;\n\tcontext  *PaymentContext &#x2F;&#x2F; 上下文\n\tstrategy PaymentStrategy &#x2F;&#x2F; 策略\n&#125;\n\nfunc (p *Payment) Pay() &#123;\n\tp.strategy.Pay(p.context)\n&#125;\n\n&#x2F;&#x2F; 付款上下文\ntype PaymentContext struct &#123;\n\tName   string\n\tCardID string\n\tMoney  int\n&#125;\n\nfunc NewPayment(name, cardID string, money int, strategy PaymentStrategy) *Payment &#123;\n\treturn &amp;Payment&#123;\n\t\tcontext: &amp;PaymentContext&#123;\n\t\t\tName:   name,\n\t\t\tCardID: cardID,\n\t\t\tMoney:  money,\n\t\t&#125;,\n\t\tstrategy: strategy,\n\t&#125;\n&#125;\n\n&#x2F;&#x2F; 付款策略 接口(算法接口)\ntype PaymentStrategy interface &#123;\n\tPay(*PaymentContext)\n&#125;\n\ntype Cash struct&#123;&#125;\n\nfunc (*Cash) Pay(ctx *PaymentContext) &#123;\n\tfmt.Printf(&quot;Pay $%d to %s by cash&quot;, ctx.Money, ctx.Name)\n&#125;\n\ntype Wechat struct&#123;&#125;\n\nfunc (*Wechat) Pay(ctx *PaymentContext) &#123;\n\tfmt.Printf(&quot;Pay $%d to %s by wechat account %s&quot;, ctx.Money, ctx.Name, ctx.CardID)\n&#125;\n\nfunc main() &#123;\n\tstrategy :&#x3D; &amp;Cash&#123;&#125;\n\tNewPayment(&quot;rumple&quot;, &quot;12938282&quot;, 100, strategy).Pay()\n&#125;","slug":"golang/dp/理解设计模式之策略模式","date":"2020-10-27T06:51:40.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"047033f0c1450db28daf35058b5fd01e","title":"理解设计模式之模板方法模式","content":"模版方法模式使用继承机制，把通用步骤和通用方法放到父类中，把具体实现延迟到子类中实现。使得实现符合开闭原则。注意匿名组合虽然像继承，但还是有不一样的地方的。比如，因为父类需要调用子类方法，所以子类需要匿名组合父类的同时，父类需要持有子类的引用\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 定义父类接口\ntype Downloader interface &#123;\n\tDownload(uri string)\n&#125;\n\n&#x2F;&#x2F; 定义模板类(父类)\ntype template struct &#123;\n\timpl &#x2F;&#x2F; 持有子类引用\n\turi  string\n&#125;\n\n&#x2F;&#x2F; 定义子类接口\ntype impl interface &#123;\n\tdownload()\n\tsave()\n&#125;\n\nfunc newTemplate(impl impl) *template &#123;\n\treturn &amp;template&#123;\n\t\timpl: impl,\n\t&#125;\n&#125;\n\nfunc (t *template) Download(uri string) &#123;\n\tt.uri &#x3D; uri\n\tfmt.Print(&quot;prepare downloading\\n&quot;)\n\tt.impl.download()\n\tt.impl.save()\n\tfmt.Print(&quot;finish downloading\\n&quot;)\n&#125;\n\n&#x2F;&#x2F; 默认的保存实现\nfunc (t *template) save() &#123;\n\tfmt.Print(&quot;default save\\n&quot;)\n&#125;\n\n&#x2F;&#x2F; http下载器\ntype HTTPDownloader struct &#123;\n\t*template\n&#125;\n\nfunc NewHTTPDownloader() Downloader &#123;\n\tdownloader :&#x3D; &amp;HTTPDownloader&#123;&#125;\n\ttemplate :&#x3D; newTemplate(downloader)\n\tdownloader.template &#x3D; template\n\treturn downloader\n&#125;\n\nfunc (d *HTTPDownloader) download() &#123;\n\tfmt.Printf(&quot;download %s via http\\n&quot;, d.uri)\n&#125;\n\nfunc (*HTTPDownloader) save() &#123;\n\tfmt.Printf(&quot;http save\\n&quot;)\n&#125;\n\ntype FTPDownloader struct &#123;\n\t*template\n&#125;\n\nfunc NewFTPDownloader() Downloader &#123;\n\tdownloader :&#x3D; &amp;FTPDownloader&#123;&#125;\n\ttemplate :&#x3D; newTemplate(downloader)\n\tdownloader.template &#x3D; template\n\treturn downloader\n&#125;\n\nfunc (d *FTPDownloader) download() &#123;\n\tfmt.Printf(&quot;download %s via ftp\\n&quot;, d.uri)\n&#125;\n\nfunc main() &#123;\n\tNewHTTPDownloader().Download(&quot;xxxxxxx&quot;)\n&#125;","slug":"golang/dp/理解设计模式之模板方法模式","date":"2020-10-27T02:23:35.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"293d39b9d616d2268ed47b9219110ea6","title":"理解设计模式之迭代器模式","content":"迭代器模式，一样的一个字面意思，封装你的对象 对外提供一个迭代器，可以不断迭代你的对象，这样外部无需了解对象的具体实现细节，通过迭代器就可以不断访问下一个元素\n\npackage main\n\nimport &quot;container&#x2F;list&quot;\n\n&#x2F;&#x2F; 定义一个容器接口 拥有迭代方法 返回迭代器\ntype Container interface &#123;\n\tIterator() Iterator\n\tAdd(interface&#123;&#125;)\n&#125;\n\n&#x2F;&#x2F; 定义容器类\ntype MyList struct &#123;\n\tlist *list.List\n&#125;\n\nfunc (l *MyList) Iterator() Iterator &#123;\n\treturn &amp;ListIterator&#123;l.list.Front(), l.list.Back()&#125;\n&#125;\n\nfunc (l *MyList) Add(value interface&#123;&#125;) &#123;\n\tl.list.PushBack(value)\n&#125;\n\nfunc NewList() Container &#123;\n\treturn &amp;MyList&#123;list: list.New()&#125;\n&#125;\n\n&#x2F;&#x2F; 定义迭代器接口\ntype Iterator interface &#123;\n\tHasNext() bool\n\tNext() interface&#123;&#125;\n&#125;\n\n&#x2F;&#x2F; 定义迭代器类\ntype ListIterator struct &#123;\n\tcur *list.Element\n\tend *list.Element\n&#125;\n\nfunc (l *ListIterator) HasNext() bool &#123;\n\treturn l.cur !&#x3D; l.end\n&#125;\n\nfunc (l *ListIterator) Next() interface&#123;&#125; &#123;\n\tvalue :&#x3D; l.cur.Next().Value\n\tl.cur &#x3D; l.cur.Next()\n\treturn value\n&#125;\n\nfunc main() &#123;\n\tli :&#x3D; NewList()\n\n\tfor i :&#x3D; 0; i &lt;&#x3D; 10; i++ &#123;\n\t\tli.Add(i)\n\t&#125;\n\n\titer :&#x3D; li.Iterator()\n\titer.HasNext()\n&#125;","slug":"golang/dp/理解设计模式之迭代器模式","date":"2020-10-27T01:35:19.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"2f495e9970023abb3de380eead14299f","title":"理解设计模式之命令模式","content":"命令模式本质是把某个对象的方法调用封装到对象中，方便传递、存储、调用。\n示例中把主板单中的启动(start)方法和重启(reboot)方法封装为命令对象，再传递到主机(box)对象中。于两个按钮进行绑定：\n第一个机箱(box1)设置按钮1(buttion1) 为开机按钮2(buttion2)为重启。第二个机箱(box2)设置按钮2(buttion2) 为开机按钮1(buttion1)为重启。从而得到配置灵活性。\n除了配置灵活外，使用命令模式还可以用作：\n\n批处理\n任务队列\nundo, redo等把具体命令封装到对象中使用的场合\n\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 定义命令接口\ntype ICommand interface &#123;\n\tExecute()\n&#125;\n\n&#x2F;&#x2F; 定义开机命令类\ntype StartCommand struct &#123;\n\tmb *MotherBoard\n&#125;\n\n&#x2F;&#x2F; 构造方法\nfunc NewStartCommand(mb *MotherBoard) *StartCommand &#123;\n\treturn &amp;StartCommand&#123;\n\t\tmb: mb,\n\t&#125;\n&#125;\n\nfunc (c *StartCommand) Execute() &#123;\n\tc.mb.Start()\n&#125;\n\n&#x2F;&#x2F; 定义重启命令类\ntype RebootCommand struct &#123;\n\tmb *MotherBoard\n&#125;\n\nfunc NewRebootCommand(mb *MotherBoard) *RebootCommand &#123;\n\treturn &amp;RebootCommand&#123;\n\t\tmb: mb,\n\t&#125;\n&#125;\n\nfunc (c *RebootCommand) Execute() &#123;\n\tc.mb.Reboot()\n&#125;\n\n&#x2F;&#x2F; 定义主板\ntype MotherBoard struct&#123;&#125;\n\nfunc (*MotherBoard) Start() &#123;\n\tfmt.Println(&quot;system starting&quot;)\n&#125;\n\nfunc (*MotherBoard) Reboot() &#123;\n\tfmt.Println(&quot;system rebooting&quot;)\n&#125;\n\n&#x2F;&#x2F; 定义机箱\ntype Box struct &#123;\n\tbutton1 ICommand\n\tbutton2 ICommand\n&#125;\n\nfunc NewBox(button1, button2 ICommand) *Box &#123;\n\treturn &amp;Box&#123;\n\t\tbutton1: button1,\n\t\tbutton2: button2,\n\t&#125;\n&#125;\n\nfunc (b *Box) PressButton1() &#123;\n\tb.button1.Execute()\n&#125;\n\nfunc (b *Box) PressButton2() &#123;\n\tb.button2.Execute()\n&#125;\n\nfunc main() &#123;\n\tmb :&#x3D; &amp;MotherBoard&#123;&#125;\n\tstart :&#x3D; NewStartCommand(mb)\n\treboot :&#x3D; NewRebootCommand(mb)\n\n\tbox :&#x3D; NewBox(start, reboot)\n\tbox.PressButton1()\n\tbox.PressButton2()\n&#125;","slug":"golang/dp/理解设计模式之命令模式","date":"2020-10-26T10:05:50.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"53fbeba8ed5d161cf25f38b1905c9c66","title":"理解设计模式之观察者模式","content":"观察者模式比较好理解，就是字面意思，其实和发布订阅差不多。举一个学生订阅课程的例子\n\npackage main\n\n&#x2F;&#x2F; 定义课程接口\ntype ISubject interface &#123;\n\tAttach(IObserver) &#x2F;&#x2F; 添加观察者方法\n\tNotify()          &#x2F;&#x2F; 通知接口\n\tUpdateTime(time string)\n&#125;\n\n&#x2F;&#x2F; 定义课程类\ntype Subject struct &#123;\n\tobservers []IObserver\n\tname      string &#x2F;&#x2F; 课程名称\n\ttime      string &#x2F;&#x2F; 上课时间\n&#125;\n\nfunc NewSubject(name string) ISubject &#123;\n\treturn &amp;Subject&#123;\n\t\tobservers: make([]IObserver, 0),\n\t\tname:      name,\n\t&#125;\n&#125;\n\n&#x2F;&#x2F; 添加观察者\nfunc (s *Subject) Attach(o IObserver) &#123;\n\ts.observers &#x3D; append(s.observers, o)\n&#125;\n\n&#x2F;&#x2F; 通知观察者进行改变\nfunc (s *Subject) Notify() &#123;\n\tfor _, o :&#x3D; range s.observers &#123;\n\t\to.Update(s)\n\t&#125;\n&#125;\n\nfunc (s *Subject) UpdateTime(time string) &#123;\n\ts.time &#x3D; time\n&#125;\n\n&#x2F;&#x2F; 定义观察者类\ntype IObserver interface &#123;\n\tUpdate(subject ISubject)\n&#125;\n\ntype Student struct &#123;\n\tname string\n\tsub  ISubject\n&#125;\n\nfunc (s *Student) Update(subject ISubject) &#123;\n\ts.sub &#x3D; subject\n&#125;\n\nfunc main() &#123;\n\tsbj :&#x3D; NewSubject(&quot;线性代数&quot;)\n\tlily :&#x3D; &amp;Student&#123;name: &quot;lily&quot;&#125;\n\n\tsbj.Attach(lily)\n\tsbj.UpdateTime(&quot;12点半&quot;)\n\t&#x2F;&#x2F; ...\n&#125;","slug":"golang/dp/理解设计模式之观察者模式","date":"2020-10-26T09:55:25.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"2f29c37507db5ca2a228334b44c7a06a","title":"理解设计模式之中介者模式","content":"中介者模式是用来封装对象与对象之间的交互，使依赖变简单，使复杂交互简单化，封装在中介者中，显而易见的缺点就是，由于逻辑封装在中介者中，所以中介者以后会越来越复杂\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 定义中介者类\ntype Mediator struct &#123;\n\tmarket IDepartment &#x2F;&#x2F; 市场部门\n\ttec    IDepartment &#x2F;&#x2F; 技术部门\n&#125;\n\nfunc NewMediator() *Mediator &#123;\n\treturn &amp;Mediator&#123;&#125;\n&#125;\n\nfunc (m *Mediator) SetMarket(market IDepartment) &#123;\n\tm.market &#x3D; market\n&#125;\n\nfunc (m *Mediator) SetTec(tec IDepartment) &#123;\n\tm.tec &#x3D; tec\n&#125;\n\nfunc (m *Mediator) ForwardMessage(department IDepartment, message string) &#123;\n\tswitch department.(type) &#123;\n\tcase *Technical: &#x2F;&#x2F; 技术部门的消息转发给市场部\n\t\tm.market.GetMess(message)\n\tcase *Market: &#x2F;&#x2F; 相同\n\t\tm.tec.GetMess(message)\n\t&#125;\n&#125;\n\n&#x2F;&#x2F; 定义部门接口\ntype IDepartment interface &#123;\n\tSendMess(message string)\n\tGetMess(message string)\n&#125;\n\n&#x2F;&#x2F; 定义技术部\ntype Technical struct &#123;\n\tmediator *Mediator\n&#125;\n\nfunc (t *Technical) SendMess(message string) &#123;\n\tt.mediator.ForwardMessage(t, message)\n&#125;\n\nfunc (t *Technical) GetMess(message string) &#123;\n\tfmt.Printf(&quot;技术部收到消息: %s\\n&quot;, message)\n&#125;\n\n&#x2F;&#x2F; 定义市场部\ntype Market struct &#123;\n\tmediator *Mediator\n&#125;\n\nfunc (m *Market) SendMess(message string) &#123;\n\tm.mediator.ForwardMessage(m, message)\n&#125;\n\nfunc (m *Market) GetMess(message string) &#123;\n\tfmt.Printf(&quot;市场部部收到消息: %s\\n&quot;, message)\n&#125;\n\nfunc main() &#123;\n\tm :&#x3D; NewMediator()\n\n\tmarket :&#x3D; &amp;Market&#123;mediator: m&#125;\n\ttec :&#x3D; &amp;Technical&#123;mediator: m&#125;\n\n\tm.SetTec(tec)\n\tm.SetMarket(market)\n\n\tmarket.SendMess(&quot;hallo world&quot;)\n&#125;","slug":"golang/dp/理解设计模式之中介者模式","date":"2020-10-26T09:39:55.000Z","categories_index":"设计模式","tags_index":"行为型设计模式","author_index":"Rumple"},{"id":"4e7dab327a16c4ff4445f675a754b4bd","title":"理解设计模式之桥接模式","content":"桥接模式分离抽象部分和实现部分。使得两部分可以独立扩展。\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 抽象消息接口  定义具体的消息类型\ntype AbsMessage interface &#123;\n\tSendMessage(text, to string)\n&#125;\n\n&#x2F;&#x2F; 真正发消息的接口 发送消息的方式\ntype Message interface &#123;\n\tSend(text, to string)\n&#125;\n\n&#x2F;&#x2F; -------------------------------------\ntype EmailMessage struct&#123;&#125;\n\nfunc (*EmailMessage) Send(text, to string) &#123;\n\tfmt.Printf(&quot;send %s to %s email&quot;, text, to)\n&#125;\n\ntype WechatMessage struct&#123;&#125;\n\nfunc (*WechatMessage) Send(text, to string) &#123;\n\tfmt.Printf(&quot;send %s to %s wechat&quot;, text, to)\n&#125;\n\n&#x2F;&#x2F; 公共消息\ntype CommonMessage struct &#123;\n\tmethod Message\n&#125;\n\nfunc NewCommonMessage(method Message) AbsMessage &#123;\n\treturn &amp;CommonMessage&#123;\n\t\tmethod: method,\n\t&#125;\n&#125;\n\nfunc (m *CommonMessage) SendMessage(text, to string) &#123;\n\tm.method.Send(fmt.Sprintf(&quot;[Common] %s&quot;, text), to)\n&#125;\n\n&#x2F;&#x2F; 紧急消息\ntype UrgencyMessage struct &#123;\n\tmethod Message\n&#125;\n\nfunc NewUrgencyMessage(method Message) AbsMessage &#123;\n\treturn &amp;UrgencyMessage&#123;\n\t\tmethod: method,\n\t&#125;\n&#125;\n\nfunc (m *UrgencyMessage) SendMessage(text, to string) &#123;\n\tm.method.Send(fmt.Sprintf(&quot;[Urgency] %s&quot;, text), to)\n&#125;\n\nfunc main() &#123;\n\tNewCommonMessage(&amp;EmailMessage&#123;&#125;).SendMessage(&quot;Hallo world&quot;, &quot;zhangsan&quot;)\n&#125;\n","slug":"golang/dp/理解设计模式之桥接模式","date":"2020-10-26T06:54:02.000Z","categories_index":"设计模式","tags_index":"结构型设计模式","author_index":"Rumple"},{"id":"f0bac87a6e91ff11c8f0bc84046165ce","title":"理解设计模式之装饰器模式","content":"熟悉python的朋友对装饰器肯定不陌生，他的定义就是在不改变原有定义的情况下，动态的添加功能。这里的装饰器模式其实也是一个意思\n\n\n首先来看一个最简单的,在go中函数是一等公民，所以是可以当成参数传递的，那么这就简单了。\nfunc pprint() &#123;\n\tfmt.Println(&quot;1234&quot;)\n&#125;\n\nfunc pprintDecorator(a func()) &#123;\n\tfmt.Println(&quot;decorator&quot;)\n\ta()\n\tfmt.Println(&quot;after&quot;)\n&#125;\n\nfunc main() &#123;\n\tpprintDecorator(pprint)\n&#125;\n\n\n再来看一个标准的\npackage main\n\nimport (\n\t&quot;fmt&quot;\n\t&quot;log&quot;\n)\n\n&#x2F;&#x2F; 定义一个API, API中只有一个方法就是计算获取结果\ntype API interface &#123;\n\tCalc() int\n&#125;\n\ntype Object struct&#123;&#125;\n\nfunc (*Object) Calc() int &#123;\n\treturn 0\n&#125;\n\n&#x2F;&#x2F; 乘 装饰器\ntype MulDecorator struct &#123;\n\tAPI\n\tnum int\n&#125;\n\nfunc WarpMulDecorator(c API, num int) API &#123;\n\treturn &amp;MulDecorator&#123;\n\t\tAPI: c,\n\t\tnum: num,\n\t&#125;\n&#125;\n\nfunc (d *MulDecorator) Calc() int &#123;\n\treturn d.API.Calc() * d.num\n&#125;\n\n&#x2F;&#x2F; 加 装饰器\ntype AddDecorator struct &#123;\n\tAPI\n\tnum int\n&#125;\n\nfunc WarpAddDecorator(c API, num int) API &#123;\n\treturn &amp;AddDecorator&#123;\n\t\tAPI: c,\n\t\tnum: num,\n\t&#125;\n&#125;\n\nfunc (d *AddDecorator) Calc() int &#123;\n\treturn d.API.Calc() + d.num\n&#125;\n\nfunc main() &#123;\n\tobj :&#x3D; &amp;Object&#123;&#125;\n\td :&#x3D; WarpAddDecorator(obj, 100)\n\tlog.Println(d.Calc())\n&#125;\n\n","slug":"golang/dp/理解设计模式之装饰器模式","date":"2020-10-26T06:38:34.000Z","categories_index":"设计模式","tags_index":"结构型设计模式","author_index":"Rumple"},{"id":"0e88d00be424e9da6d7f13b5a9de850e","title":"理解设计模式之享元模式","content":"享元模式是指：从对象中剥离出不发生改变且多个实例都需要的重复数据（当然这个数据也可以是对象），独立出一个享元，从而减少对象的创建，节省内存\n\n\npackage main\n\nimport &quot;fmt&quot;\n\ntype ImageFactory struct &#123;\n\tmaps map[string]*Image\n&#125;\n\nfunc NewImageFactory() *ImageFactory &#123;\n\treturn &amp;ImageFactory&#123;maps: make(map[string]*Image)&#125;\n&#125;\n\n&#x2F;&#x2F; 获取共享数据\nfunc (f *ImageFactory) Get(filename string) *Image &#123;\n\tvar image &#x3D; f.maps[filename]\n\tif image &#x3D;&#x3D; nil &#123;\n\t\t&#x2F;&#x2F; 当没有这个数据的时候,才进行新建\n\t\timage &#x3D; NewImage(filename)\n\t\tf.maps[filename] &#x3D; image\n\t&#125;\n\treturn image\n&#125;\n\n&#x2F;&#x2F; 共享数据对象\ntype Image struct &#123;\n\tdata string\n&#125;\n\n&#x2F;&#x2F; 新建共享数据对象\nfunc NewImage(filename string) *Image &#123;\n\treturn &amp;Image&#123;\n\t\tdata: fmt.Sprintf(&quot;image data %s&quot;, filename),\n\t&#125;\n&#125;\n\n&#x2F;&#x2F; 返回对象数据\nfunc (i *Image) Data() string &#123;\n\treturn i.data\n&#125;\n\ntype ImageViewer struct &#123;\n\t*Image\n&#125;\n\nfunc NewImageViewer(filename string, imageFactory *ImageFactory) *ImageViewer &#123;\n\treturn &amp;ImageViewer&#123;\n\t\tImage: imageFactory.Get(filename),\n\t&#125;\n&#125;\n\nfunc (i *ImageViewer) Display() &#123;\n\tfmt.Printf(&quot;Display: %s\\n&quot;, i.Data())\n&#125;\n\nfunc main() &#123;\n\tnif :&#x3D; NewImageFactory()\n\tiv :&#x3D; NewImageViewer(&quot;beauty&quot;, nif)\n\tiv.Display()\n&#125;","slug":"golang/dp/理解设计模式之享元模式","date":"2020-10-26T06:22:51.000Z","categories_index":"设计模式","tags_index":"结构型设计模式","author_index":"Rumple"},{"id":"ae24c711008000da26e897d1dea4a2e7","title":"理解设计模式之组合模式","content":"组合模式可以统一对象以及对象集，之后可以使用相同接口去访问这些对象和对象集组合模式常用于树状结构，用于统一叶子节点和树节点的访问，并且可以用于应用某一操作到所有子节点。\n这里咱们就直接创建一个树。\n\npackage main\n\nimport (\n\t&quot;log&quot;\n)\n\n&#x2F;&#x2F; 定义基础对象接口 树 组件的基本属性\ntype TreeComponent interface &#123;\n\tParent() TreeComponent   &#x2F;&#x2F; 获取父节点\n\tSetParent(TreeComponent) &#x2F;&#x2F; 设置父节点\n\tName() string            &#x2F;&#x2F; 名称\n\tSetName(string)          &#x2F;&#x2F; 设置名称\n\tAddChild(TreeComponent)  &#x2F;&#x2F; 添加子节点\n\tCount() int              &#x2F;&#x2F; 查看当前节点的子节点数量\n&#125;\n\nfunc NewTreeComponent(kind int, name string) TreeComponent &#123;\n\n\tvar c TreeComponent\n\tlog.Print(&quot;创建节点&quot;)\n\tif kind &#x3D;&#x3D; 0 &#123;\n\t\tc &#x3D; NewLeaf(name)\n\t&#125; else &#123;\n\t\tc &#x3D; NewNonLeaf(name)\n\t&#125;\n\treturn c\n&#125;\n\n&#x2F;&#x2F; ----------叶子节点-----------\ntype Leaf struct &#123;\n\tname   string\n\tparent TreeComponent\n&#125;\n\n&#x2F;&#x2F; 构造函数\nfunc NewLeaf(name string) *Leaf &#123;\n\treturn &amp;Leaf&#123;name: name&#125;\n&#125;\n\nfunc (l *Leaf) Parent() TreeComponent &#123;\n\treturn l.parent\n&#125;\n\nfunc (l *Leaf) SetParent(component TreeComponent) &#123;\n\tl.parent &#x3D; component\n&#125;\n\nfunc (l *Leaf) Name() string &#123;\n\treturn l.name\n&#125;\n\nfunc (l *Leaf) SetName(name string) &#123;\n\tl.name &#x3D; name\n&#125;\n\n&#x2F;&#x2F; 叶子节点不能添加子节点 所以这里什么都不做\nfunc (l *Leaf) AddChild(component TreeComponent) &#123;\n\n&#125;\n\nfunc (l *Leaf) Count() int &#123;\n\treturn 1\n&#125;\n\n&#x2F;&#x2F; ----- 非叶子节点------\ntype NonLeaf struct &#123;\n\tname     string\n\tparent   TreeComponent\n\tchildren []TreeComponent\n&#125;\n\nfunc NewNonLeaf(name string) *NonLeaf &#123;\n\treturn &amp;NonLeaf&#123;\n\t\tchildren: make([]TreeComponent, 0),\n\t\tname:     name,\n\t&#125;\n&#125;\n\nfunc (n *NonLeaf) Parent() TreeComponent &#123;\n\treturn n.parent\n&#125;\n\nfunc (n *NonLeaf) SetParent(component TreeComponent) &#123;\n\tn.parent &#x3D; component\n&#125;\n\nfunc (n *NonLeaf) Name() string &#123;\n\treturn n.name\n&#125;\n\nfunc (n *NonLeaf) SetName(name string) &#123;\n\tn.name &#x3D; name\n&#125;\n\nfunc (n *NonLeaf) AddChild(component TreeComponent) &#123;\n\tlog.Println(&quot;添加子节点&quot;, component.Name())\n\tcomponent.SetParent(n)\n\tn.children &#x3D; append(n.children, component)\n&#125;\n\nfunc (n *NonLeaf) Count() int &#123;\n\tlog.Println(&quot;获取所有子节点数量&quot;)\n\n\tvar count &#x3D; 1 &#x2F;&#x2F; 注意: 把自己算进去,所以这里是1\n\tfor _, x :&#x3D; range n.children &#123;\n\t\tcount +&#x3D; x.Count()\n\t&#125;\n\treturn count\n&#125;\n\nfunc main() &#123;\n\n\t&#x2F;&#x2F; 创建根节点\n\trootNode :&#x3D; NewTreeComponent(1, &quot;root&quot;)\n\n\t&#x2F;&#x2F; 循环十次 每次 给root节点添加一个 叶子节点 和 非叶子节点, 非叶子节点也添加一个 叶子节点\n\tfor i :&#x3D; 0; i &lt;&#x3D; 10; i++ &#123;\n\t\trootNode.AddChild(NewTreeComponent(0, &quot;leaf&quot;))\n\t\tnf :&#x3D; NewTreeComponent(1, &quot;nonLeaf&quot;)\n\t\tnf.AddChild(NewTreeComponent(0, &quot;leaf&quot;))\n\t\trootNode.AddChild(nf)\n\t&#125;\n\n\tlog.Println(rootNode.Count())\n&#125;","slug":"golang/dp/理解设计模式之组合模式","date":"2020-10-26T05:37:01.000Z","categories_index":"设计模式","tags_index":"结构型设计模式","author_index":"Rumple"},{"id":"0cc18532576f0420deb16181e5056f24","title":"理解设计模式之代理模式","content":"代理模式用于延迟处理操作或者在进行实际操作前后进行其它处理。\n\n\npackage main\n\nimport &quot;fmt&quot;\n\ntype Work interface &#123;\n\tDo() string\n&#125;\n\ntype RealWork struct&#123;&#125;\n\nfunc (*RealWork) Do() string &#123;\n\treturn &quot;real&quot;\n&#125;\n\ntype Proxy struct &#123;\n\trealWorker Work\n&#125;\n\nfunc (p Proxy) Do() string &#123;\n\tvar res string\n\n\t&#x2F;&#x2F; 在调用真实对象之前的工作，检查缓存，判断权限，实例化真实对象等。。\n\tres +&#x3D; &quot;pre:&quot;\n\n\t&#x2F;&#x2F; 调用真实对象\n\tres +&#x3D; p.realWorker.Do()\n\n\t&#x2F;&#x2F; 调用之后的操作，如缓存结果，对结果进行处理等。。\n\tres +&#x3D; &quot;:after&quot;\n\n\treturn res\n&#125;\n\nfunc NewProxy() *Proxy &#123;\n\treturn &amp;Proxy&#123;realWorker: &amp;RealWork&#123;&#125;&#125;\n&#125;\n\nfunc main() &#123;\n\tfmt.Println(NewProxy().Do())\n&#125;","slug":"golang/dp/理解设计模式之代理模式","date":"2020-10-26T03:26:47.000Z","categories_index":"设计模式","tags_index":"结构型设计模式","author_index":"Rumple"},{"id":"81dbbf6776f0e83a5de64679463cd385","title":"理解设计模式之适配器模式","content":"适配器模式用于转换一种接口适配另一种接口。\n\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; Target 是适配的目标接口\ntype Target interface &#123;\n\tRequest() string\n&#125;\n\n&#x2F;&#x2F; AdapTee 是被适配的目标接口\ntype AdapTee interface &#123;\n\tSpecificRequest() string\n&#125;\n\n&#x2F;&#x2F; NewAdapTee 是被适配接口的工厂函数\nfunc NewAdapTee() AdapTee &#123;\n\treturn &amp;adapTeeImpl&#123;&#125;\n&#125;\n\n&#x2F;&#x2F; adapTeeImpl 是被适配的目标类\ntype adapTeeImpl struct&#123;&#125;\n\n&#x2F;&#x2F; SpecificRequest 是目标类的一个方法\nfunc (*adapTeeImpl) SpecificRequest() string &#123;\n\treturn &quot;adaptee SpecificRequest method&quot;\n&#125;\n\n&#x2F;&#x2F; NewAdapter 是Adapter的工厂函数\nfunc NewAdapter(adp AdapTee) Target &#123;\n\treturn &amp;adapter&#123;\n\t\tAdapTee: adp,\n\t&#125;\n&#125;\n\n&#x2F;&#x2F; Adapter 是转换AdapTee为Target接口的适配器\ntype adapter struct &#123;\n\tAdapTee\n&#125;\n\n&#x2F;&#x2F; Request 实现Target接口\nfunc (a *adapter) Request() string &#123;\n\treturn a.SpecificRequest()\n&#125;\n\nfunc main() &#123;\n\tfmt.Println(NewAdapter(NewAdapTee()).Request())\n&#125;\n\n实际使用中AdapTee一般为接口，并且使用工厂函数生成实例。\n在Adapter中匿名组合AdapTee接口，所以Adapter类也拥有SpecificRequest实例方法又因为Go语言中非入侵式接口特征，其实Adapter也适配AdapTee接口\n","slug":"golang/dp/理解设计模式之适配器模式","date":"2020-10-26T03:20:15.000Z","categories_index":"设计模式","tags_index":"结构型设计模式","author_index":"Rumple"},{"id":"9b3ae101f06841603467d83a4a546e9c","title":"理解设计模式之外观模式","content":"外观模式的主要作用是 减少客户端与系统内部交互的复杂性，对子系统的一系列接口，提供一个一致性的界面，方便调用\n\npackage main\n\nimport &quot;fmt&quot;\n\nfunc NewAPI() FacadeAPI &#123;\n\treturn &amp;apiImpl&#123;\n\t\ta: NewAModuleAPI(),\n\t\tb: NewBModuleAPI(),\n\t&#125;\n&#125;\n\n&#x2F;&#x2F; FacadeAPI is facade interface of facade package\ntype FacadeAPI interface &#123;\n\tTest() string\n&#125;\n\n&#x2F;&#x2F; facade implement\ntype apiImpl struct &#123;\n\ta AModuleAPI\n\tb BModuleAPI\n&#125;\n\nfunc (a *apiImpl) Test() string &#123;\n\taRet :&#x3D; a.a.TestA()\n\tbRet :&#x3D; a.b.TestB()\n\treturn fmt.Sprintf(&quot;%s\\n%s&quot;, aRet, bRet)\n&#125;\n\n&#x2F;&#x2F; NewAModuleAPI return new AModuleAPI\nfunc NewAModuleAPI() AModuleAPI &#123;\n\treturn &amp;aModuleImpl&#123;&#125;\n&#125;\n\n&#x2F;&#x2F; AModuleAPI ...\ntype AModuleAPI interface &#123;\n\tTestA() string\n&#125;\n\ntype aModuleImpl struct&#123;&#125;\n\nfunc (*aModuleImpl) TestA() string &#123;\n\treturn &quot;A module running&quot;\n&#125;\n\n&#x2F;&#x2F; NewBModuleAPI return new BModuleAPI\nfunc NewBModuleAPI() BModuleAPI &#123;\n\treturn &amp;bModuleImpl&#123;&#125;\n&#125;\n\n&#x2F;&#x2F; BModuleAPI ...\ntype BModuleAPI interface &#123;\n\tTestB() string\n&#125;\n\ntype bModuleImpl struct&#123;&#125;\n\nfunc (*bModuleImpl) TestB() string &#123;\n\treturn &quot;B module running&quot;\n&#125;\n\nfunc main() &#123;\n\tfmt.Println(NewAPI().Test())\n&#125;\n","slug":"golang/dp/理解设计模式之外观模式","date":"2020-10-26T02:52:42.000Z","categories_index":"设计模式","tags_index":"结构型设计模式","author_index":"Rumple"},{"id":"ff7986bd3e13e58f395ae3555d928c50","title":"理解设计模式之原型模式","content":"原型模式和其他创建型模式不一样的是，它是复制一个已有对象，而不是创建一个新对象，被复制的对象就叫做原型。原型模式多用于建造复杂或者耗时的对象，这样直接复制会比较高效。原型对象一般会配合原型管理器一起使用\n\n\ngo\npackage main\n\nimport (\n\t&quot;fmt&quot;\n\t&quot;reflect&quot;\n)\n\ntype Cloneable interface &#123;\n\tClone() Cloneable\n&#125;\n\n&#x2F;&#x2F; 原型管理器\ntype ProtoManager struct &#123;\n\tprototypes map[string]Cloneable\n&#125;\n\nfunc NewProtoManager() *ProtoManager &#123;\n\treturn &amp;ProtoManager&#123;prototypes: make(map[string]Cloneable)&#125;\n&#125;\n\nfunc (p *ProtoManager) Get(name string) Cloneable &#123;\n\treturn p.prototypes[name]\n&#125;\nfunc (p *ProtoManager) Set(name string, v Cloneable) &#123;\n\tp.prototypes[name] &#x3D; v\n&#125;\n\ntype Object struct &#123;\n\tname string\n&#125;\n\nfunc (a *Object) Clone() Cloneable &#123;\n\ttc :&#x3D; *a\n\treturn &amp;tc\n&#125;\n\nfunc NewObject(name string) *Object &#123;\n\treturn &amp;Object&#123;name: name&#125;\n&#125;\n\nfunc main() &#123;\n\tmanager :&#x3D; NewProtoManager()\n\ta :&#x3D; NewObject(&quot;rumple&quot;)\n\tmanager.Set(&quot;t1&quot;, a)\n\n\tc :&#x3D; manager.Get(&quot;t1&quot;).Clone()\n\tfmt.Println(c)\n\n\t&#x2F;&#x2F; 判断是否为同一对象\n\tfmt.Println(a &#x3D;&#x3D; c)\n\t&#x2F;&#x2F; 判断是否相等\n\tfmt.Println(reflect.DeepEqual(a, c))\n&#125;\n\npython\nimport abc\n\nimport copy\n\n\nclass ProtoType(metaclass&#x3D;abc.ABCMeta):\n    &quot;&quot;&quot;\n    原型抽象类\n    &quot;&quot;&quot;\n\n    @abc.abstractmethod\n    def clone(self):\n        pass\n\n    @abc.abstractmethod\n    def deep_clone(self):\n        pass\n\n\nclass WorkExperience(object):\n    &quot;&quot;&quot;\n    工作经验类\n    &quot;&quot;&quot;\n\n    def __init__(self):\n        self.work_time &#x3D; None\n        self.company &#x3D; None\n\n    def set_work(self, time, company: str):\n        self.work_time &#x3D; time\n        self.company &#x3D; company\n\n\nclass Resume(ProtoType):\n    &quot;&quot;&quot;\n    简历类\n    &quot;&quot;&quot;\n\n    def __init__(self, name: str):\n        self.name &#x3D; name\n        self.work_experience &#x3D; WorkExperience()\n        self.gender &#x3D; None\n        self.age &#x3D; None\n\n    def set_person_info(self, gender: str, age: int):\n        self.gender &#x3D; gender\n        self.age &#x3D; age\n\n    def set_work_experience(self, time, company: str):\n        self.work_experience.set_work(time, company)\n\n    def display(self):\n        print(self.name, self.gender, self.age)\n        print(f&quot;工作经历 &#123;self.work_experience.company, self.work_experience.work_time&#125;&quot;)\n\n    def clone(self):\n        return copy.copy(self)\n\n    def deep_clone(self):\n        return copy.deepcopy(self)\n\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    a &#x3D; Resume(&quot;rumple&quot;)\n    b &#x3D; a.clone()\n    c &#x3D; a.deep_clone()\n\n    a.set_person_info(&quot;男&quot;, 67)\n    a.set_work_experience(&#39;2018&#39;, &quot;腾讯&quot;)\n\n    b.set_person_info(&quot;女&quot;, 45)\n    b.set_work_experience(&#39;2019&#39;, &quot;阿里&quot;)\n\n    c.set_person_info(&quot;女&quot;, 32)\n    c.set_work_experience(&#39;2020&#39;, &quot;百度&quot;)\n\n    a.display()\n    print(&quot;---------------------------------------&quot;)\n    b.display()\n    print(&quot;-----------------&quot;)\n    c.display()\n\n","slug":"golang/dp/理解设计模式之原型模式","date":"2020-10-23T12:08:31.000Z","categories_index":"设计模式","tags_index":"创建型设计模式","author_index":"Rumple"},{"id":"1602c992a6a28c4ed33dd66720a6bf2e","title":"理解设计模式之单例模式","content":"go语言中的单例模式简单到没啥可说的。\n正常创建一个全局变量就是，单例为了线程安全你可以加锁，这里直接使用sync.once,原理一样。\n\n\ngo\npackage main\n\nimport &quot;sync&quot;\n\ntype Singleton struct&#123;&#125;\n\nvar singleton *Singleton\n\nfunc GetInstance() *Singleton &#123;\n\tonce :&#x3D; sync.Once&#123;&#125;\n\n\tif singleton &#x3D;&#x3D; nil &#123;\n\t\tonce.Do(func() &#123;\n\t\t\tsingleton &#x3D; &amp;Singleton&#123;&#125;\n\t\t&#125;)\n\t&#125;\n\treturn singleton\n&#125;\n\nfunc main() &#123;\n\tGetInstance()\n&#125;\n\npython\nclass Signleton(object):\n\n    def __init__(self):\n        pass\n\n    def __new__(cls, *args, **kwargs):\n        if not hasattr(cls, &#39;_instance&#39;):\n            # cls._instance &#x3D; object.__new__(cls)\n            cls._instance &#x3D; super(Signleton, cls).__new__(cls, *args, **kwargs)\n\n        return cls._instance\n\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    a &#x3D; Signleton()\n    b &#x3D; Signleton()\n\n    print(id(a))\n    print(id(b))\n\n","slug":"golang/dp/理解设计模式之单例模式","date":"2020-10-23T12:05:12.000Z","categories_index":"设计模式","tags_index":"创建型设计模式","author_index":"Rumple"},{"id":"c3aea0285a3783cfb28818d4df287ed0","title":"理解设计模式之建造者模式","content":"建造者模式主要作用是解耦了创建的过程,将一个复杂对象的创建过程分步完成.下面来讲两种风格的建造者模式\n\n\ngopackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 1.传统类型: 由指挥者指挥建造者创建具体的对象\n&#x2F;&#x2F; 创建奥特曼\n&#x2F;&#x2F; 定义建造者接口\ntype Builder interface &#123;\n\tBuildHead()\n\tBuildHand()\n\tBuildLeg()\n\tBuildBody()\n\tShow()\n&#125;\n\n&#x2F;&#x2F; 定义指挥者\ntype Director struct &#123;\n\tbuilder Builder\n&#125;\n\nfunc NewDirector(b Builder) *Director &#123;\n\treturn &amp;Director&#123;builder: b&#125;\n&#125;\n\nfunc (d *Director) Generate() &#123;\n\td.builder.BuildBody()\n\td.builder.BuildHand()\n\td.builder.BuildHead()\n\td.builder.BuildLeg()\n\td.builder.Show()\n&#125;\n\n&#x2F;&#x2F; 定义奥特曼 以及 奥特曼建造者\ntype UltraMan struct &#123;\n\tHead string\n\tHand string\n\tBody string\n\tLeg  string\n&#125;\n\ntype UltraManBuilder struct &#123;\n\tutMan *UltraMan\n&#125;\n\nfunc (b *UltraManBuilder) BuildBody() &#123;\n\tb.utMan.Body &#x3D; &quot;body&quot;\n&#125;\nfunc (b *UltraManBuilder) BuildHand() &#123;\n\tb.utMan.Hand &#x3D; &quot;hand&quot;\n&#125;\nfunc (b *UltraManBuilder) BuildHead() &#123;\n\tb.utMan.Head &#x3D; &quot;head&quot;\n&#125;\nfunc (b *UltraManBuilder) BuildLeg() &#123;\n\tb.utMan.Leg &#x3D; &quot;leg&quot;\n&#125;\n\nfunc (b *UltraManBuilder) Show() &#123;\n\tfmt.Printf(&quot;%+v&quot;, b.utMan)\n&#125;\n\n&#x2F;&#x2F; 2. Golang风格的建造者模式\n&#x2F;&#x2F; 创建一个坦克\ntype Tank struct &#123;\n\tTankLooks string &#x2F;&#x2F; 坦克最终的样子\n\tWheel     bool   &#x2F;&#x2F; 是否有轮子\n\tCannon    bool   &#x2F;&#x2F; 是否有大炮\n\tDriver    bool   &#x2F;&#x2F; 是否有驾驶员\n&#125;\n\nfunc NewTank() *Tank &#123;\n\treturn &amp;Tank&#123;&#125;\n&#125;\n\nfunc (t *Tank) withWheel() *Tank &#123;\n\tt.Wheel &#x3D; true\n\treturn t\n&#125;\n\nfunc (t *Tank) withCannon() *Tank &#123;\n\tt.Cannon &#x3D; true\n\treturn t\n&#125;\nfunc (t *Tank) withDriver() *Tank &#123;\n\tt.Driver &#x3D; true\n\treturn t\n&#125;\n\nfunc (t *Tank) Show() &#123;\n\tif t.Wheel &#123;\n\t\tt.TankLooks +&#x3D; &quot;有轮子,&quot;\n\t&#125; else &#123;\n\t\tt.TankLooks +&#x3D; &quot;没有轮子,&quot;\n\t&#125;\n\n\tif t.Cannon &#123;\n\t\tt.TankLooks +&#x3D; &quot;有大炮,&quot;\n\t&#125; else &#123;\n\t\tt.TankLooks +&#x3D; &quot;没有大炮,&quot;\n\t&#125;\n\n\tif t.Driver &#123;\n\t\tt.TankLooks +&#x3D; &quot;有驾驶员&quot;\n\t&#125; else &#123;\n\t\tt.TankLooks +&#x3D; &quot;无人驾驶&quot;\n\t&#125;\n\n\tfmt.Println(t.TankLooks) &#x2F;&#x2F; or return tank\n&#125;\n\nfunc main() &#123;\n\t&#x2F;&#x2F; director :&#x3D; NewDirector(&amp;UltraManBuilder&#123;&amp;UltraMan&#123;&#125;&#125;)\n\t&#x2F;&#x2F; director.Generate()\n\ttank :&#x3D; NewTank().withCannon().withDriver()\n\ttank.Show()\n&#125;\n\n2.python\nimport abc\n\n\nclass Builder(metaclass&#x3D;abc.ABCMeta):\n\n    @abc.abstractmethod\n    def create_head(self):\n        pass\n\n    @abc.abstractmethod\n    def create_arm(self):\n        pass\n\n    @abc.abstractmethod\n    def create_leg(self):\n        pass\n\n    @abc.abstractmethod\n    def create_dick(self):\n        pass\n\n    @abc.abstractmethod\n    def create_bottom(self):\n        pass\n\n\nclass Dragon(Builder):\n\n    def create_arm(self):\n        print(&quot;建造恐龙手臂&quot;)\n\n    def create_bottom(self):\n        print(&quot;建造恐龙屁股&quot;)\n\n    def create_dick(self):\n        print(&quot;建造恐龙吊&quot;)\n\n    def create_head(self):\n        print(&quot;建造霸王龙头部&quot;)\n\n    def create_leg(self):\n        print(&quot;建造恐龙腿&quot;)\n\n\nclass AUTOMan(Builder):\n\n    def create_leg(self):\n        print(&quot;建造奥特曼腿&quot;)\n\n    def create_head(self):\n        print(&quot;建造奥特曼头&quot;)\n\n    def create_dick(self):\n        print(&quot;建造奥特曼吊&quot;)\n\n    def create_arm(self):\n        print(&quot;建造奥特曼手臂&quot;)\n\n    def create_bottom(self):\n        print(&quot;建造奥特曼屁股&quot;)\n\n\nclass Director(object):\n\n    def __init__(self, someone: Builder):\n        self.someone &#x3D; someone\n\n    def create(self):\n        self.someone.create_leg()\n        self.someone.create_head()\n        self.someone.create_arm()\n        self.someone.create_dick()\n        self.someone.create_bottom()\n\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    dragon &#x3D; Dragon()\n\n    rumple &#x3D; Director(dragon)\n    rumple.create()","slug":"golang/dp/理解设计模式之建造者模式","date":"2020-10-23T11:05:37.000Z","categories_index":"设计模式","tags_index":"创建型设计模式","author_index":"Rumple"},{"id":"c1243241d6dbe40f7f47b73a2a79fbcc","title":"理解设计模式之抽象工厂","content":"抽象工厂 是在工厂方法的基础之上进化而来，其中最大的不同点是：工厂方法模式中的工厂 只创建一种对象，而抽象工厂中的工厂 则是创建多种对象，而往往这些对象是有关联的，一个家族的一系列对象，比如  订单和订单详情\n\n\ngo\n&#x2F;&#x2F; 订单信息接口\ntype Order interface &#123;\n\tSaveOrderInfo()\n&#125;\n\n&#x2F;&#x2F; 订单详情接口\ntype OrderDetail interface &#123;\n\tSaveOrderDetailInfo()\n&#125;\n\n&#x2F;&#x2F; Order 抽象模式工厂接口\ntype OrderFactory interface &#123;\n\tCreateOrder() Order\n\tCreateOrderDetail() OrderDetail\n&#125;\n\n&#x2F;&#x2F; ------------------------------------------------------\n&#x2F;&#x2F; 我们实现分别用数据库存储订单信息 以及 文件存储订单信息\ntype DBOrderSaver struct&#123;&#125;\n\nfunc (*DBOrderSaver) SaveOrderInfo() &#123;\n\tfmt.Println(&quot;保存订单到数据库&quot;)\n&#125;\n\n&#x2F;&#x2F; 订单详情\ntype DBOrderDetailSaver struct&#123;&#125;\n\nfunc (*DBOrderDetailSaver) SaveOrderDetailInfo() &#123;\n\tfmt.Println(&quot;保存订单详情到数据库&quot;)\n&#125;\n\n&#x2F;&#x2F; 创建数据库 订单相关系列对象的工厂\ntype DBOrderFactory struct&#123;&#125;\n\nfunc (*DBOrderFactory) CreateOrder() Order &#123;\n\treturn &amp;DBOrderSaver&#123;&#125;\n&#125;\n\nfunc (*DBOrderFactory) CreateOrderDetail() OrderDetail &#123;\n\treturn &amp;DBOrderDetailSaver&#123;&#125;\n&#125;\n\n&#x2F;&#x2F; file\ntype FileOrderSaver struct&#123;&#125;\n\nfunc (*FileOrderSaver) SaveOrderInfo() &#123;\n\tfmt.Println(&quot;保存订单到文件&quot;)\n&#125;\n\ntype FileOrderDetailSaver struct&#123;&#125;\n\nfunc (*FileOrderDetailSaver) SaveOrderDetailInfo() &#123;\n\tfmt.Println(&quot;保存订单详情到文件&quot;)\n&#125;\n\ntype FileOrderFactory struct&#123;&#125;\n\nfunc (*FileOrderFactory) CreateOrder() Order &#123;\n\treturn &amp;FileOrderSaver&#123;&#125;\n&#125;\n\nfunc (*FileOrderFactory) CreateOrderDetail() OrderDetail &#123;\n\treturn &amp;FileOrderDetailSaver&#123;&#125;\n&#125;\n\nfunc main() &#123;\n\tdbf :&#x3D; &amp;DBOrderFactory&#123;&#125;\n\torder :&#x3D; dbf.CreateOrder()\n\torderDet :&#x3D; dbf.CreateOrderDetail()\n\n\torder.SaveOrderInfo()\n\torderDet.SaveOrderDetailInfo()\n&#125;\n\npython\nimport abc\n\n\nclass SomeThing(object):\n\n    def __init__(self, brand: str):\n        self.brand &#x3D; brand\n\n    @abc.abstractmethod\n    def fly(self):\n        pass\n\n    @abc.abstractmethod\n    def run(self):\n        pass\n\n\nclass Plane(SomeThing):\n\n    def __init__(self, *args, **kwargs):\n        super(Plane, self).__init__(*args, **kwargs)\n\n    def fly(self):\n        print(f&quot;&#123;self.brand&#125; &#123;Plane.__name__&#125; i can fly&quot;)\n\n    def run(self):\n        print(f&quot;&#123;self.brand&#125; &#123;Plane.__name__&#125; i also run&quot;)\n\n\nclass Tank(SomeThing):\n\n    def __init__(self, *args, **kwargs):\n        super(Tank, self).__init__(*args, **kwargs)\n\n    def fly(self):\n        print(f&quot;&#123;self.brand&#125; &#123;Tank.__name__&#125; i can&#39;t fly&quot;)\n\n    def run(self):\n        print(f&quot;&#123;self.brand&#125; &#123;Tank.__name__&#125; i can run&quot;)\n\n\nclass Factory(object):\n    &quot;&quot;&quot;\n    工厂基类\n    &quot;&quot;&quot;\n\n    @abc.abstractmethod\n    def create_plane(self):\n        pass\n\n    @abc.abstractmethod\n    def create_tank(self):\n        pass\n\n\nclass SamsungFactory(Factory):\n    brand &#x3D; &quot;samsung&quot;\n\n    def create_plane(self):\n        return Plane(SamsungFactory.brand)\n\n    def create_tank(self):\n        return Tank(SamsungFactory.brand)\n\n\nclass AppleFactory(Factory):\n    brand &#x3D; &quot;apple&quot;\n\n    def create_plane(self):\n        return Plane(AppleFactory.brand)\n\n    def create_tank(self):\n        return Tank(AppleFactory.brand)\n\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    samsung_factory &#x3D; SamsungFactory()\n    samsung_plane &#x3D; samsung_factory.create_plane()\n    samsung_tank &#x3D; samsung_factory.create_tank()\n\n    samsung_tank.fly()\n    samsung_tank.run()\n\n    samsung_plane.fly()\n    samsung_plane.run()\n\n    apple_factory &#x3D; AppleFactory()\n    # ...\n\n","slug":"golang/dp/理解设计模式之抽象工厂","date":"2020-10-23T10:54:34.000Z","categories_index":"设计模式","tags_index":"创建型设计模式","author_index":"Rumple"},{"id":"ac7a60db5b9b5c38555c42db8dd8bf35","title":"理解设计模式之工厂方法模式","content":"与简单工厂不同，简单工厂 &#x3D; 一个工厂创造所有的 类对象，如果此对象在工厂中没有，就只能修改代码 去新增对象的创造过程而工厂方法 则只是定义了一系列的接口， 定义创建对象的接口，定义工厂的接口，具体的工厂对象，以及 产品 对象 都由外部自己实现。 相当于只是定义了规则\n\n\ngo版本\npackage main\n\nimport &quot;fmt&quot;\n\n&#x2F;&#x2F; 产品接口\ntype Product interface &#123;\n\tPrice() int\n\tBrand() string\n&#125;\n\n&#x2F;&#x2F; 创造产品的工厂接口\ntype ProductFactory interface &#123;\n\tCreate() Product\n&#125;\n\n&#x2F;&#x2F; ---------------------------------\n&#x2F;&#x2F; 定义产品类, 汽车 与 飞机\ntype Car struct &#123;\n\tbrand string\n\tprice int\n&#125;\n\nfunc (c *Car) Price() int &#123;\n\treturn c.price\n&#125;\n\nfunc (c *Car) Brand() string &#123;\n\treturn c.brand\n&#125;\n\ntype Plane struct &#123;\n\tbrand string\n\tprice int\n&#125;\n\nfunc (c *Plane) Price() int &#123;\n\treturn c.price\n&#125;\n\nfunc (c *Plane) Brand() string &#123;\n\treturn c.brand\n&#125;\n\n&#x2F;&#x2F; 定义 创造产品的工厂\ntype PlaneFactory struct &#123;\n&#125;\n\nfunc (c *PlaneFactory) Create() Product &#123;\n\treturn &amp;Plane&#123;\n\t\tbrand: &quot;波音&quot;,\n\t\tprice: 9999999,\n\t&#125;\n&#125;\n\ntype CarFactory struct &#123;\n&#125;\n\nfunc (c *CarFactory) Create() Product &#123;\n\treturn &amp;Car&#123;\n\t\tbrand: &quot;兰博基尼&quot;,\n\t\tprice: 120000,\n\t&#125;\n&#125;\n\nfunc main() &#123;\n\n\tpf :&#x3D; &amp;PlaneFactory&#123;&#125;\n\tplane :&#x3D; pf.Create()\n\tfmt.Println(plane.Price())\n\n\tcf :&#x3D; &amp;CarFactory&#123;&#125;\n\tcar :&#x3D; cf.Create()\n\tfmt.Println(car.Price())\n&#125;\n\npython版本\nclass GoodGuy(object):\n    &quot;&quot;&quot;\n    雷锋\n    &quot;&quot;&quot;\n\n    @staticmethod\n    def sweep():\n        print(&quot;扫地&quot;)\n\n    @staticmethod\n    def wash_clothes():\n        print(&quot;洗衣服&quot;)\n\n    @staticmethod\n    def buy_something():\n        print(&quot;买东西&quot;)\n\n\nclass Student(GoodGuy):\n    &quot;&quot;&quot;\n    学生\n    &quot;&quot;&quot;\n\n    @staticmethod\n    def buy_something():\n        print(&quot;学生买东西&quot;)\n\n\nclass Volunteer(GoodGuy):\n    &quot;&quot;&quot;\n    社区志愿者\n    &quot;&quot;&quot;\n    @staticmethod\n    def buy_something():\n        print(&quot;社区志愿者买东西&quot;)\n\n\nclass GoodManFactory(object):\n\n    def create_goodman(self):\n        pass\n\n\nclass StudentFactory(GoodManFactory):\n\n    def create_goodman(self):\n        return Student()\n\n\nclass VolunteerFactory(GoodManFactory):\n\n    def create_goodman(self):\n        return Volunteer()\n\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    a &#x3D; StudentFactory()\n    b &#x3D; VolunteerFactory()\n    a.create_goodman().buy_something()\n\n","slug":"golang/dp/理解设计模式之工厂方法模式","date":"2020-10-23T09:40:20.000Z","categories_index":"设计模式","tags_index":"创建型设计模式,设计模式","author_index":"Rumple"},{"id":"66121ee3bb53d4eaf9b18fd8c88d13c8","title":"理解设计模式之简单工厂","content":"所谓简单工厂是指 用来封装一个类对象的具体创建细节，去构造一个对象在go语言中没有构造函数一说，所以一般会定义NewXXX函数来初始化相关类。NewXXX 函数返回接口时就是简单工厂模式，也就是说Golang的一般推荐做法就是简单工厂。\n\npackage factory\n\nimport &quot;fmt&quot;\n\ntype Human interface &#123;\n\tSay()\n&#125;\n\nfunc NewHuman(w int) Human &#123;\n\n\tif w &#x3D;&#x3D; 0 &#123;\n\t\treturn &amp;teacher&#123;&#125;\n\t&#125; else &#123;\n\t\treturn &amp;doctor&#123;&#125;\n\t&#125;\n&#125;\n\ntype teacher struct &#123;\n&#125;\n\nfunc (t *teacher) Say() &#123;\n\tfmt.Println(&quot;hallo i&#39;m a teacher&quot;)\n&#125;\n\ntype doctor struct &#123;\n&#125;\n\nfunc (t *doctor) Say() &#123;\n\tfmt.Println(&quot;hallo i&#39;m a doctor&quot;)\n&#125;\n\n\npackage main\n\nfunc main() &#123;\n\th :&#x3D; NewHuman(0)\n\th.Say()\n&#125;","slug":"golang/dp/理解设计模式之简单工厂","date":"2020-10-23T09:27:12.000Z","categories_index":"设计模式","tags_index":"创建型设计模式,设计模式","author_index":"Rumple"},{"id":"9de8279fb9a993c3fcae6823edce7c19","title":"折腾之在CentOS8上安装K8s环境(废弃)","content":"（红帽不想让我们白嫖了，GG）继续centos7，也可以慢慢转向debian了centos8 已经出来一段时间了，在刚出来的时候，尝试过使用一次，貌似相较7变化有些大，就没继续折腾现在有时间了，来尝试一下把K8S的环境搭建在centos8上。\n\n\n\n虚拟机  我用的是Parallels Desktop,装的centos8虚拟机，用的镜像目前版本是 CentOS-8.2.2004-x86_64-minimal.iso\n\nIP  跟之前不一样的是，8装好ifconfig是没有ip的，这就需要我们手动配置一下了。\n\n查看 /etc/sysconfig/network-scripts/目录下并没有eth0网卡，不过有一个ifcfg-xxx，这里应该每个人是不一样的，不过不管他是什么我们都给改为，ifcfg-eth0.\n\n同时还要修改ifcfg-eth0内的几个配置项 NAME和DEVICE 改为 eth0, ONBOOT 改为 yes.\n\n编辑/etc/default/grub 在 GRUBCMDLINELINUX变量 的 crashkernel=auto 后面加上 net.ifnames=0 biosdevname=0\n\n运行命令grub2-mkconfig -o /boot/grub2/grub.cfg来重新生成GRUB配置并更新内核参数.\n\n最后重启，然后就可以看到ip啦，就可以直接ssh进行操作了。\n\nPS：centos8 已经没有newwork.service这个服务了，如果要单纯重启网络可以执行 nmcli c reload。\n\n修改yum源为清华源\n首先备份 sudo cp /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak\n然后编辑 /etc/yum.repos.d/CentOS-Base.repo\n注释 mirrorlist= 这一行\n取消注释 baseurl= 这一行，并将 mirror.centos.org 替换为 mirrors.tuna.tsinghua.edu.cn\n\n\n最后 执行 sudo yum makecache &amp;&amp; sudo yum -y update\n\n\n安装一些工具 yum -y install python3 vim git wget telnet* the_silver_searcher\npip3 install mycli ipython httpie\n\nhtop原来htop安装 直接yum -y install 就可以的，现在需要用dnf\ndnf install https://dl.Fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\ndnf update\ndnf install htop\n\n\n\n\n安装Docker\n安装依赖 sudo yum install -y yum-utils device-mapper-persistent-data lvm2\n配置阿里云仓库 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n由于centos8默认使用podman，所以我们要先手动安装containerd.io，同时如果你的源下载的版本太低，可以手动下载新版本 Download 进行安装\nyum -y install docker-ce\n修改docker配置文件，镜像源加速  cat &lt;&lt;EOF &gt; &#x2F;etc&#x2F;docker&#x2F;daemon.json\n&#123;\n    &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;registry.docker-cn.com&quot;,&quot;http:&#x2F;&#x2F;hub-mirror.c.163.com&quot;],\n&#125;\nEOF\nsystemctl start docker\n\n\n安装K8S\n关闭防火墙   systemctl disable firewalld\nsystemctl stop firewalld\n禁用SELinux\n\n   setenforce 0\n# 或者\nvim &#x2F;etc&#x2F;sysconfig&#x2F;selinux\nSELINUX&#x3D;disabled\nreboot\n\n\n安装kubeadm(用于安装k8s集群的工具)\n   # 修改源\nvim &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo\n   [kubernetes]\nname&#x3D;Kubernetes Repository\nbaseurl&#x3D;http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-x86_64&#x2F;\nenabled&#x3D;1\ngpgcheck&#x3D;0\n   yum -y install kubelet kubeadm kubectl --disableexcludes&#x3D;kubernetes\n   systemctl enable docker &amp;&amp; systemctl start docker\nsystemctl enable kubelet &amp;&amp; systemctl start kubelet\n\nkubeadm config\n   # 初始化配置文件备用\nkubeadm config print init-defaults &gt; init.defaults.yaml\n# 拷贝一份\ncp init.defaults.yaml init.yaml\n   修改 init.yaml 中的如下项\n   localAPIEndpoint:\n  advertiseAddress: 你的ip\n\nimageRepository: docker.io&#x2F;aiotceo # 镜像仓库地址\n\n下载相关镜像\n   kubeadm config images pull --config&#x3D;init.yaml\n\nMaster节点\n\n关闭swap,修改/etc/sysconfig/kubelet的配置项KUBELET_EXTRA_ARGS=--fail-swap-on=false\n\n swapoff -a\nvim &#x2F;etc&#x2F;fstab\n# 注释掉swap的自动挂载\n\n安装 # 这个过程需要一些时间\nkubeadm init --config&#x3D;init-config.yaml\n# 可能会遇到一些错误需要reset kubelet服务\n\n# 修改权限\nmkdir -p $HOME&#x2F;.kube\nsudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config\nsudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config\n 注意记录安装成功后的信息 kubeadm join xxxxxxxx\n\n\nNode节点前面的准备工作都是一样的 只需要在最后生成配置文件后执行kubeadm join --config=join-config.yaml\n\n如果你只想安装单节点的话\n kubectl taint nodes --all node-role.kubernetes.io&#x2F;master-\n\n\n\n","slug":"centos/折腾centos8","date":"2020-10-21T05:29:21.000Z","categories_index":"centos","tags_index":"centos8,k8s","author_index":"Rumple"},{"id":"e58f8fe0572c85b85b5c4eee696e5d39","title":"hexo添加评论系统","content":"\nhexo支持很多评论系统，由于我的blog是部署在github page 上，所以，索性我就直接用gitalk用做评论系统\n配置方法  \n\n首先先在github中创建一个用于存储评论的公有仓库，注意（博客可以部署在私有仓库，评论必须public）\n注册Github APP https://github.com/settings/applications/new\nHomepage URL 与 Authorization callback URL 都填写你的blog地址\n其余随意填写\n\n\n注册完毕我们会得到 ClientID 和Client Secret\n在next主题配置文件中 找到如图的配置项      gitalk:\n  enable: true # 开启\n  github_id: 你的账户\n  repo: 刚刚创建的评论仓库\n  client_id: ClientID\n  client_secret: Client Secret\n  admin_user: 你的账户\n配置好后重新部署即可\n\n\n\n","slug":"config/hexo添加评论系统","date":"2020-10-21T01:54:15.000Z","categories_index":"hexo","tags_index":"hexo","author_index":"Rumple"},{"id":"27852f8dc79cc34a496b7be5ae32dae9","title":"DockerSwarm搭建完整的微服务项目","content":"这是一个容器化快速发展的时代，相信不少朋友都已经体会到了容器的便利性，自从我第一眼看到容器这个东西，就对其深深的爱上了。也确定了我以后的职业发展方向。这也是我喜欢Golang的原因\n\n最近接到一个说大不大说下不小的项目，因为K8S有点太重了，我们人员资源有限，所以这一次我打算用docker自带的集群工具swarm去进行搭建。\n简单描述一下项目的架构，图就不放了涉及到商业机密哈哈哈\n整个项目是近年来比较流行的微服务架构的形式，（PS,人少千万别搞，头发疯狂掉，我这边是不懂技术的leader非要搞这个。醉了，其实单体应用一样可以满足需求），不过好处也是有的，各个service的代码会变得少且清爽。\n技术选型\n\n开发语言：Golang\n开发框架：Gin(web框架) go-micro(一个我用起来比较舒服的微服务框架)\nOTHER：\ngo-fastdfs : 存储静态文件\nMySQL\nRedis\nETCD\nElasticSearch\nlogstash\nkafka\nelastalert (哈哈看到这几个东西你是不是觉得你知道咱们是干什么的啦？没错，但是也错，因为这只是整个项目中的一块功能)\ndocker swarm\n\n\n\n我们准备了五台机器来搭建环境都是32核+48G往上的配置。\n代码是分为了 负责用户交互的 API项目。以及若干不同的后端service, 所有的service通过rpc受API控制与调度。\n\n初始化docker swarm环境。\n\n\n首先选择你要作为主管理节点的机器执行 docker swarm init,执行完毕会生成类似如下信息,其中docker swarm join --token ... 就是你要在其他机器上执行的命令，以让其他节点加入集群。同时我们可以看到swarm集群是默认通过2377端口进行通讯的，注意你的防火墙哦。  Swarm initialized: current node (kszmpm48vw7kzrl3r1erqnhww) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n  docker swarm join --token SWMTKN-1-3fjzlta4vpoj1eq2mo9eqzvxa96lt46hpdfyd6o4pgwtdxnrzo-cbdve6xq1dcah532llqn2jgxr 192.168.65.3:2377\n\nTo add a manager to this swarm, run &#39;docker swarm join-token manager&#39; and follow the instructions.\n在其他节点加入完毕后，在master上执行docker node ls查看是否所有节点都加入进来。\n另外还可以对每个节点 docker node update --label-add xxx=xxx  [node_name]打上一些标签，方便部署规划\n\n\n在开始部署项目之前我们需要解决一个小问题  我们知道docker跨主机网络是可以共享的，那么数据卷是不是可以呢，其实是可以的，只不过官方自己未实现而已，这里就需要一些第三方的插件了，我们这里选用的是 convoy ,这是一个基于nfs的跨主机容器存储插件，安装方式这里就不赘述了。\n\n开始部署。  docker swarm也是支持使用docker-compose.yaml文件去进行部署的，这样比命令行好的原因是方便管理。也更加直观。所以这里我们基本上一个中间件，或者一个服务一个yaml文件\n\nMySQL: 由于我这里暂时数据量还没上来，而且还在开发阶段所以只部署了单节点version: &quot;3.8&quot;\nservices:\n  mysql:\n    image: mysql:5.7\n    command: [ &quot;mysqld&quot;,&quot;--character-set-server&#x3D;utf8mb4&quot;,&quot;--collation-server&#x3D;utf8mb4_unicode_ci&quot; ]\n    ports:\n      - 8306:3306\n    environment:\n      - MYSQL_ROOT_PASSWORD&#x3D;mysql\n    volumes:\n      - mysql-data:&#x2F;var&#x2F;lib&#x2F;mysql\n    networks:\n      - project-network\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.role&#x3D;&#x3D;manager&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\nvolumes:    # 使用convoy创建的数据卷\n  mysql-data:\n    name: mysql-data\n    external: true\n\nnetworks:\n  project-network: # 外部创建用于 项目共享的网络 后面不再赘述\n    name: project-network\n    external: true\n\nredis: redis的集群哨兵模式在docker中只能以host模式去运行（这是要注意的，如果你要搭集群的话）version: &quot;3.8&quot;\n  services:\n    redis:\n      image: project-redis:latest # 这里使用的不是官方镜像，因为我们需要修改一些配置，所以需要自己build\n      networks:\n        - project-network\n      deploy:\n        replicas: 1\n        placement:\n          constraints:\n            - &quot;node.labels.name&#x3D;&#x3D;worker2&quot; # 标签\n        restart_policy:\n          condition: on-failure\n          delay: 5s\n          max_attempts: 3\n          window: 10s\n\n  networks:\n    project-network:\n      name: project-network\n      external: true\n\nfastdfsversion: &quot;3.8&quot;\nservices:\n  fast_dfs:\n    image: sjqzhang&#x2F;go-fastdfs:latest\n    networks:\n      - project-network\n    environment:\n      GO_FASTDFS_DIR: &#x2F;data\n    volumes:\n      - dfs:&#x2F;data\n    deploy:\n      replicas: 1  # 这个也是可以搭建集群的官方有教程可以操作一下\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;worker3&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\nnetworks:\n  project-network:\n    name: project-network\n    external: true\n\nvolumes:\n  dfs:\n    name: fast-dfs\n    external: true\n\nETCD集群version: &quot;3.8&quot;\nservices:\n  etcd:\n    image: quay.io&#x2F;coreos&#x2F;etcd:latest\n    environment:\n      - ETCDCTL_API&#x3D;3\n    networks:\n      - project-network\n    command:\n      &#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcd\n      -name etcd\n      -data-dir &#x2F;etcd-data\n      -initial-advertise-peer-urls http:&#x2F;&#x2F;etcd:2380\n      -advertise-client-urls http:&#x2F;&#x2F;etcd:2379\n      -listen-client-urls http:&#x2F;&#x2F;0.0.0.0:2379\n      -listen-peer-urls http:&#x2F;&#x2F;0.0.0.0:2380\n      -initial-cluster-token etcd-cluster\n      -initial-cluster-state new\n      -initial-cluster &quot;etcd&#x3D;http:&#x2F;&#x2F;etcd:2380,etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380&quot;\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.role&#x3D;&#x3D;manager&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  etcd1:\n    image: quay.io&#x2F;coreos&#x2F;etcd:latest\n    environment:\n      - ETCDCTL_API&#x3D;3\n    networks:\n      - project-network\n    command:\n      &#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcd\n      -name etcd1\n      -data-dir &#x2F;etcd-data\n      -initial-advertise-peer-urls http:&#x2F;&#x2F;etcd1:2380\n      -advertise-client-urls http:&#x2F;&#x2F;etcd1:2379\n      -listen-client-urls http:&#x2F;&#x2F;0.0.0.0:2379\n      -listen-peer-urls http:&#x2F;&#x2F;0.0.0.0:2380\n      -initial-cluster-token etcd-cluster\n      -initial-cluster-state new\n      -initial-cluster &quot;etcd&#x3D;http:&#x2F;&#x2F;etcd:2380,etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380&quot;\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;worker2&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  etcd2:\n    image: quay.io&#x2F;coreos&#x2F;etcd:latest\n    environment:\n      - ETCDCTL_API&#x3D;3\n    networks:\n      - project-network\n    command:\n      &#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcd\n      -name etcd2\n      -data-dir &#x2F;etcd-data\n      -initial-advertise-peer-urls http:&#x2F;&#x2F;etcd2:2380\n      -advertise-client-urls http:&#x2F;&#x2F;etcd2:2379\n      -listen-client-urls http:&#x2F;&#x2F;0.0.0.0:2379\n      -listen-peer-urls http:&#x2F;&#x2F;0.0.0.0:2380\n      -initial-cluster-token etcd-cluster\n      -initial-cluster-state new\n      -initial-cluster &quot;etcd&#x3D;http:&#x2F;&#x2F;etcd:2380,etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380&quot;\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;worker3&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\nnetworks:\n  project-network:\n    name: project-network\n    external: true\n\nES集群version: &quot;3.8&quot;\nservices:\n  es1:\n    image: elasticsearch:7.8.1\n    networks:\n      - project-network\n    volumes:\n      - &#x2F;opt&#x2F;es_docker&#x2F;certs&#x2F;elastic-certificates.p12:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config&#x2F;elastic-certificates.p12\n      - &#x2F;opt&#x2F;es_data:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data\n    environment:\n      - node.name&#x3D;es1\n      - node.master&#x3D;true\n      - node.data&#x3D;true\n      - cluster.name&#x3D;noahsec\n      - node.max_local_storage_nodes&#x3D;9\n      - discovery.zen.ping.unicast.hosts&#x3D;es_es1,es_es2,es_es3\n      - discovery.zen.minimum_master_nodes&#x3D;1\n      - cluster.initial_master_nodes&#x3D;es1\n      - http.cors.enabled&#x3D;true\n      - http.cors.allow-origin&#x3D;&quot;*&quot;\n      - xpack.license.self_generated.type&#x3D;basic\n      - xpack.security.enabled&#x3D;true\n      - xpack.security.transport.ssl.enabled&#x3D;true\n      - xpack.security.transport.ssl.verification_mode&#x3D;certificate\n      - xpack.security.transport.ssl.keystore.path&#x3D;elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path&#x3D;elastic-certificates.p12\n      - xpack.monitoring.enabled&#x3D;true\n      - &quot;ES_JAVA_OPTS&#x3D;-Xms32g -Xmx32g&quot;\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;es&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  es2:\n    image: elasticsearch:7.8.1\n    networks:\n      - project-network\n    volumes:\n      - &#x2F;opt&#x2F;es_docker&#x2F;certs&#x2F;elastic-certificates.p12:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config&#x2F;elastic-certificates.p12\n      - &#x2F;opt&#x2F;es_data:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data\n    environment:\n      - node.name&#x3D;es2\n      - node.master&#x3D;true\n      - node.data&#x3D;true\n      - cluster.name&#x3D;noahsec\n      - node.max_local_storage_nodes&#x3D;9\n      - discovery.zen.ping.unicast.hosts&#x3D;es_es1,es_es2,es_es3\n      - discovery.zen.minimum_master_nodes&#x3D;1\n      - cluster.initial_master_nodes&#x3D;es1\n      - http.cors.enabled&#x3D;true\n      - http.cors.allow-origin&#x3D;&quot;*&quot;\n      - xpack.license.self_generated.type&#x3D;basic\n      - xpack.security.enabled&#x3D;true\n      - xpack.security.transport.ssl.enabled&#x3D;true\n      - xpack.security.transport.ssl.verification_mode&#x3D;certificate\n      - xpack.security.transport.ssl.keystore.path&#x3D;elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path&#x3D;elastic-certificates.p12\n      - xpack.monitoring.enabled&#x3D;true\n      - &quot;ES_JAVA_OPTS&#x3D;-Xms32g -Xmx32g&quot;\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;es&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n  es3:\n    image: elasticsearch:7.8.1\n    networks:\n      - project-network\n    volumes:\n      - &#x2F;opt&#x2F;es_docker&#x2F;certs&#x2F;elastic-certificates.p12:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config&#x2F;elastic-certificates.p12\n      - &#x2F;opt&#x2F;es_data:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data\n    environment:\n      - node.name&#x3D;es3\n      - node.master&#x3D;true\n      - node.data&#x3D;true\n      - cluster.name&#x3D;noahsec\n      - node.max_local_storage_nodes&#x3D;9\n      - discovery.zen.ping.unicast.hosts&#x3D;es_es1,es_es2,es_es3\n      - discovery.zen.minimum_master_nodes&#x3D;1\n      - cluster.initial_master_nodes&#x3D;es1\n      - http.cors.enabled&#x3D;true\n      - http.cors.allow-origin&#x3D;&quot;*&quot;\n      - xpack.license.self_generated.type&#x3D;basic\n      - xpack.security.enabled&#x3D;true\n      - xpack.security.transport.ssl.enabled&#x3D;true\n      - xpack.security.transport.ssl.verification_mode&#x3D;certificate\n      - xpack.security.transport.ssl.keystore.path&#x3D;elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path&#x3D;elastic-certificates.p12\n      - xpack.monitoring.enabled&#x3D;true\n      - &quot;ES_JAVA_OPTS&#x3D;-Xms32g -Xmx32g&quot;\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;es&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  kibana:\n    image: kibana:7.8.1\n    networks:\n      - project-network\n    ports:\n      - 5601:5601\n    environment:\n      ELASTICSEARCH_HOSTS: http:&#x2F;&#x2F;es1:9200\n      ELASTICSEARCH_USERNAME: kibana\n      ELASTICSEARCH_PASSWORD: Zx3TuFXNKgTEv1IVZvFt\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;es&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\n  nginx:  # 这里用ngix是和我们公司的特殊环境有关，需要从外部访问。你可以不用设置\n    image: nginx\n    networks:\n      - project-network\n    ports:\n      - 9200:9200\n    command: |\n      &#x2F;bin&#x2F;bash -c &quot;echo &#39;\n      server &#123;\n        listen 9200;\n        add_header X-Frame-Options &quot;SAMEORIGIN&quot;;\n        location &#x2F; &#123;\n          client_max_body_size 200m;\n          proxy_pass http:&#x2F;&#x2F;es_es1:9200;\n          proxy_http_version 1.1;\n          proxy_set_header Connection keep-alive;\n          proxy_set_header Upgrade $$http_upgrade;\n          proxy_set_header Host $$host;\n          proxy_set_header X-Real-IP $$remote_addr;\n          proxy_cache_bypass $$http_upgrade;\n      &#125;\n      &#125;&#39; | tee &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf &amp;&amp; nginx -g &#39;daemon off;&#39;&quot;\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n          - &quot;node.labels.name&#x3D;&#x3D;esalert&quot;\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 10s\n\nvolumes:\n  es-data:\n    name: es-data\n    external: true\n\nnetworks:\n  project-network:\n    name: project-network\n    external: true\n    external: true  项目代码部分如何部署就不做展示了，都是同理的。\n\n结语  此篇博客其实没什么干货，只是稍微水一下不过我相信聪明的同学即使是在水文中也能获取到一点点知识哈哈。  关于微服务，其实本项目还有很多东西没有做，比如服务注册，服务发现，配置中心等等（目前项目中所有的配置都是使用一个环境变量配置文件去读取），这些都是人手不足无法去做的地方。  所以还是那句话，不要因为什么流行，就去搞什么，还是得调研，实际符合自己的架构才是好的架构。\n\n\n","slug":"golang/DockerSwarm搭建完整的微服务项目","date":"2020-10-20T06:59:52.000Z","categories_index":"docker","tags_index":"docker,swarm,架构,微服务","author_index":"Rumple"},{"id":"5a2cdee73626da8985a23805f627ad4f","title":"用简单的话讲明白MySQL索引","content":"索引的作用顾名思义，索引其实就是字面意思，和我们以前查字典的索引是一样的意思，能够帮助我们快速的查找到相关数据，这就是索引，哈希表的键，人的名字，工号，身份证号，这些都是索引\n\nBTree(B-Tree)  B树和B-树其实是一个意思。它长这个样子  \n\n  它是一颗多路平衡查找树，我们描述一颗B树时需要指定它的阶数，阶数表示一个节点最多有多少个子节点，一般用m表示，当m取2时，就是常见的二叉树。  特性：\n\n节点从左到右递增排序\n每个数据节点后面都会紧跟着一个指针，该指针是指向下一级的内存地址。下一级指的是位于当前指针左右两边数值中间的数据记录所存在内存中的地址。\n叶子节点 的指针为空\n所有索引元素是不重复的。\n每个索引节点都存着当前指向的记录数据或内存地址\n\nB+Tree  B+树是B树的一个变种，它在B树的基础之上做了一些改善，将索引节点所关联的数据记录全部移到了叶子节点上，目的是为了可以存储更多的索引节点，但是却增加了索引节点的冗余，因为叶子节点包含了所有的索引节点。    特性：\n\n叶子节点包含所有的索引节点 \n非叶子节点不存储数据记录 \n叶子节点之间使用指针连接，提高区间访问的便利 \n指针所指向的索引节点的最左边都是大于等于指针所在深度左边的值\n\nMySQL中的B+Tree    MySQL所使用的B+Tree是对于B+Tree更进一步的优化\n\n增加了一个双向的指针 \n首尾节点也通过指针进行关联起来 主要目的是为了更加友好的支持索引内部的范围查找。如果不加双向链表指针，我们每次查找的时候，都要回到根节点查找，增加了磁盘IO，增加查询时间。\n\n聚簇索引与非聚簇索引  聚簇索引：索引文件与数据存放在一起  非聚簇索引：索引文件与数据文件分开存放  我们知道MySQL支持很多存储引擎，InnoDB,MyISAM,Memory等等，我们最常用的也是MySQL默认的就是InnoDB。  虽然InnoDB与MyISAM都是用B+树作为索引的存储结构，但在MyISAM中叶子节点是不存储数据的，而是数据存放的地址，这种就叫做非聚簇索引，而InnoDB叶子节点是存放完整数据的。\n本篇主要讨论的是InnoDB引擎，MyISAM有兴趣可以自己查阅相关资料\b主键索引与非主键索引  在InnoDB中主键索引的叶子节点存储的是当前关联的整条记录，而非主键索引（辅助索引，二级索引）叶子节点存储的是主键值。也就是说当你使用二级索引去搜索数据，其实是要查询两次的，首先查询到对应的主键值，再通过主键值去查询数据，这个操作有个专业词语叫做回行。\n为什么必须要有主键，而且是自增的int型\n为什么Innodb表必须有主键?在innodb存储引擎表中，mysql会给主键添加聚集索引，如果没有主键，mysql则会选举表中设置了唯一索引的字段设置为主键，创建主键索引；如果表中没有字段设置为唯一索引，则mysql会生成一个6字节的row_id，作为主键，创建主键索引。\n为什么mysql推荐使用整形作为主键字段类型？在组建B树的时候，mysql会按照从小到大的顺序进行组建，如果是整形数字的话，mysql则可以直接进行比较，如果是其它类型的话，mysql还得需要将值转换为ascill码，进行比较，会增加创建索引和查询的时间。\n为什么要求是自增类型？在聚集索引中叶子节点存储数据的其实是数据页，也就是多行数据组成一个页，一页通常大小为16K。假设主键是不规则的UUID，当你插入数据时，为了保持B+Tree的平衡，会造成频繁的页分裂和页旋转，大大影响操作效率。而自增的int型时，数据插入只需要不断往右边扩充即可\n\n为什么非主键索引结构叶子节点存储的是主键值\n如果存储的是具体的数据的话，会造成数据不一致的问题，因为主键索引和辅助索引会同时维护数据记录，如果有一方维护失败则会出现不一致性的问题\n都存储具体数据的话，会造成存储空间的浪费，如果只存储主键记录的话，可以存储更多的索引记录，但是需要二次根据主键查找具体数据，以时间换空间\n\n覆盖索引  首先我们创建一张表方便说明    id 为自增主键，有主键索引  username为二级索引。\n\n用不到覆盖索引，需要回行  select * from users where username&#x3D;&quot;zhangsan&quot;;\n覆盖索引，不需要回行  select id from users where username&#x3D;&quot;zhangsan&quot;;\n\n  相信聪明的你，已经知道覆盖索引是什么意思了。简单来说就是我们所需要的数据在索引叶上已经有了，不需要再去查询主键回行进行查询。  如何尽可能的用到覆盖索引呢？这就引出了我们的下一话题，联合索引。\n联合索引  所谓联合索引，就是将多个字段联合为一个索引。好处就是，这样更符合实际需求，减少维护单个索引的成本，如果你只是为每一个字段建立了一个普通的二级索引，那么维护这些索引的成本是巨大的，而且实际的情况也不可能是只用某一个字段作为条件搜索对吧。  同时联合索引的另一个优点就是 一个联合索引 基本可以覆盖很多所需情况  比如说上表 我建立一个 (username,gender,age)的联合索引，当你使用 username ,或者 username,gender,或者username,gender,age都可以使用到这个索引文件，这个描述其实引出了众所周知的 最左前缀原则。\n最左前缀原则  就和我们读书看字一样，数据库根据索引去查找数据也是从左往右读，这就是所谓的最左前缀原则。    如图所示是 (username,age) 的联合索引数据结构  select id from users where username like &quot;张%&quot;;\nselect id from users where username&#x3D;&quot;张三&quot; and age&#x3D;14;  以上这些都是可以使用到索引的。  到这里相信你大概知道你的索引该怎样优化了，以及联合索引该怎样重建，顺序等等。\n  tips:    在老版本的mysql中，索引使用的顺序是要严格按照 索引建立时的顺序去使用的。而现在完全不需要操心这个事情啦。mysql会自动把我们的语句优化成可以使用索引的样子。\n","slug":"mysql/用简单的话讲明白索引","date":"2020-10-20T01:57:21.000Z","categories_index":"MySQL","tags_index":"mysql,数据库索引","author_index":"Rumple"},{"id":"e68c644f0327c9651998fad434541edf","title":"Golang程序Dockerfile最佳实践","content":"众所周知，通过Dockerfile去构建镜像是分层执行的，\b如何使我们的镜像最小化，以及不会泄露源代码等，我总结一个比较通用的Dockerfile.\n\n\nFROM golang:latest as builder\n\nWORKDIR  &#x2F;home&#x2F;works&#x2F;program\n\nADD .. .\nARG GOPROXY&#x3D;https:&#x2F;&#x2F;goproxy.cn\nRUN go build -o bin&#x2F;main src&#x2F;main.go\n\nFROM alpine:latest\n\nRUN echo &quot;http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;alpine&#x2F;latest-stable&#x2F;main&#x2F;&quot; &gt; &#x2F;etc&#x2F;apk&#x2F;repositories \\\n    &amp;&amp; rm -rf &#x2F;var&#x2F;cache&#x2F;apk&#x2F;* \\\n    &amp;&amp; rm -rf &#x2F;tmp&#x2F;* \\\n    &amp;&amp; apk update \\\n    &amp;&amp; apk add --no-cache -U tzdata ca-certificates libc6-compat libgcc libstdc++ \\\n    &amp;&amp; cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime \\\n    &amp;&amp; echo &quot;Asia&#x2F;Shanghai&quot; &gt; &#x2F;etc&#x2F;timezone \\\n    &amp;&amp; apk del tzdata\n\nWORKDIR  &#x2F;home&#x2F;works&#x2F;program\n\nEXPOSE 8000\n\nCOPY --from&#x3D;builder &#x2F;home&#x2F;works&#x2F;program&#x2F;bin&#x2F; .&#x2F;\nCOPY .&#x2F;configs&#x2F;settings.yml .&#x2F;configs&#x2F;settings.yml\n\nCMD .&#x2F;main\n\n说明：\n\n我们使用镜像golang:latest去编译，而实际运行的镜像则是从上层编译环境中copy过来而生产，这样做的好处是，运行的镜像只有编译后的二进制文件，没有各种依赖库，而且源代码也不在其中。是最小的状态。\nDockerfile中RUN一次执行了多条命令，如果我们把多条命令分为多条RUN，那镜像的层数就会大大增加。体积也会变大\n注意 .dockerignore 文件的使用，将不必要的文件及目录写入其中，这样会大大减少docker build过程中 daemon context的大小。\n我喜欢用 CMD 而不是 ENTRYPOINT 的原因是因为，一旦你的程序有问题跑步起来，你想 docker exec 进入容器内部debug时，使用 ENTRYPOINT 是进不去的，而实际使用效果来说两者差别不大。\n不过上述Dockerfile还有个问题就是 每次build都需要重新下载依赖库，公司开了外网，网速快，当然没什么压力，如果没有，还有随着项目越来越大依赖越来越多，构建都是很慢的。  解决办法有两个，1.自己维护一个基础编译镜像，安装好所有的依赖包，这个就是增添了维护的烦恼。2.直接在自己的电脑上交叉编译，将二进制文件直接添加进容器，直接去除实时编译，这种会快不少。\n\n更新:  上面的方式一般本地开发没啥问题,但是集成到cicd流程当中去的时候可能就会有些问题了.  接下来我们要进行优化. 解决以下几个点\n\n解决每次构建都要重新下载pkg的问题\n解决私有仓库的拉取问题\n去除不必要的CGO依赖\n\n先上Dockerfile\n#syntax&#x3D;docker&#x2F;dockerfile:latest\nFROM golang:latest as builder\n\nWORKDIR &#x2F;app\n\nADD . .\n\nENV GOPROXY&#x3D;https:&#x2F;&#x2F;goproxy.cn,direct \\\n    GOINSECURE&#x3D;gitlab.yourdomain.com&#x2F;yourgroup \\\n    GONOPROXY&#x3D;gitlab.yourdomain.com&#x2F;yourgroup \\\n    GONOSUMDB&#x3D;gitlab.yourdomain.com&#x2F;yourgroup \\\n    GOPRIVATE&#x3D;gitlab.yourdomain.com&#x2F;yourgroup \\\n\nRUN echo &quot;machine gitlab.yourdomain.com \\n login gitlab-ci-token \\n password deploytoken&quot; &gt; ~&#x2F;.netrc\n\nRUN --mount&#x3D;type&#x3D;cache,id&#x3D;go_mod,target&#x3D;&#x2F;go&#x2F;pkg&#x2F;mod \\\n    --mount&#x3D;type&#x3D;cache,id&#x3D;odp_go_cache,target&#x3D;&#x2F;root&#x2F;.cache&#x2F;go-build \\\n    CGO_ENABLED&#x3D;0 go build -o bin&#x2F;trans .&#x2F;main.go\n\n\nFROM alpine:latest\n\nRUN echo &quot;http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;alpine&#x2F;latest-stable&#x2F;main&#x2F;&quot; &gt; &#x2F;etc&#x2F;apk&#x2F;repositories \\\n    &amp;&amp; apk update \\\n    &amp;&amp; apk add tzdata \\\n    &amp;&amp; cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime \\\n    &amp;&amp; echo &quot;Asia&#x2F;Shanghai&quot; &gt; &#x2F;etc&#x2F;timezone \\\n    &amp;&amp; apk del tzdata\n\nWORKDIR &#x2F;home&#x2F;works&#x2F;program\n\nARG config&#x3D;config\n\nEXPOSE 8000\n\nENV GIN_MODE&#x3D;release\nCOPY --from&#x3D;builder &#x2F;app&#x2F;bin .&#x2F;\nCOPY .&#x2F;config&#x2F;$&#123;config&#125;.yaml .&#x2F;config&#x2F;config.yaml\nCOPY .&#x2F;static .&#x2F;static\nCMD .&#x2F;trans\n\n\n首先dockerfile语法也是有版本的 也就是BuildKit的版本, 我们开头的 #syntax=docker/dockerfile:latest 就是指定最新的语法, 不然有些功能是无法使用的.\n\n环境变量: 如果你有私有包,比如我这里,是将私有包管理在内网的gitlab,这里就需要配置所需的几个go环境变量\n\n~/.netrc 文件的修改. 是为了配置gitlab的认证. 如果你搜索过相关问题的话,其他人会告诉你需要在 git中配置 git config --global url.&quot;git@mygitlab.com:&quot;.insteadOf &quot;http://mygitlab.com/&quot; 这种方式本地开发可以, 但是在ci流程中就不太好\n\n 这里的主要作用,是为了缓存package,不用每次构建都重新下载package,他会将package给缓存到宿主机上, 之后每次都会先从缓存中读取. 这里构建的时候也将CGO给关闭了, cgo是默认开启的,如果你的代码里没有用到cgo, 而又开启了,那在之后的alpine基础镜像内就需要安装gcc相关依赖 apk add libc6-compat libgcc libstdc++,否则你的程序是无法运行的.\n\n\n","slug":"docker/Golang程序Dockerfile最佳实践","date":"2020-10-16T08:51:49.000Z","categories_index":"docker","tags_index":"go,docker","author_index":"Rumple"},{"id":"26beaec8904420e53dae414f48ef2055","title":"Golang程序实现自动更新","content":"&amp;#160;&amp;#160;&amp;#160;&amp;#160;我们都知道一个正常的golang程序部署流程大致都要经过编译，测试，发布(人工或者自动化) ，在大公司基础设施完善，当然也未必。我现在就身处于一个上市公司，但是基础建设极其惨不忍睹的公司。扯远了。进入正题\n\n假如我们就想实现一个不登录服务器，去通过暴露一个接口让程序自动更新他自己呢？\n\ngo run + 监控文件变动之前有看到一个库是用来监测go源代码变动的，如果有变动则会使变动实时生效，不过这个库是什么我忘了。这种方式比较奇葩。因为这样的话就意味着你的go程序 是没有编译，使用go run的形式跑在服务器的。这种我还不如用python对吧。当然了python程序也可以编译后在运行呢。\n\njpillora&#x2F;overseer这是一个开源的组件，用来实现上述需求。同类型的项目还有https://godoc.org/github.com/cloudflare/tableflip,这里我们暂时不研究他。\n\n原理：通过fork一个子进程去执行main函数中的程序逻辑，所有的请求会通过当前的主进程（也就是 监听进程），通过队列通道下放到子进程（也就是我们自己真正的进程）中取执行 。\n\n废话少说：撸代码。\n package main\n\nimport (\n  &quot;fmt&quot;\n  &quot;github.com&#x2F;gin-gonic&#x2F;gin&quot;\n  &quot;github.com&#x2F;jpillora&#x2F;overseer&quot;\n  &quot;github.com&#x2F;jpillora&#x2F;overseer&#x2F;fetcher&quot;\n  &quot;io&#x2F;ioutil&quot;\n  &quot;net&#x2F;http&quot;\n  &quot;time&quot;\n)\n\nvar (\n  BuildID string &#x3D; &quot;0&quot;\n)\n\nfunc main() &#123;\n  overseer.Run(overseer.Config&#123;\n    Program: program,\n    Address: &quot;:8080&quot;,\n    Fetcher: &amp;fetcher.HTTP&#123;\n      URL:      &quot;http:&#x2F;&#x2F;localhost:4000&#x2F;bin&#x2F;app&quot;,\n      Interval: 3 * time.Second,\n    &#125;,\n    Debug: true,\n  &#125;)\n&#125;\n\nfunc program(state overseer.State) &#123;\n  r :&#x3D; gin.Default()\n  r.GET(&quot;&#x2F;&quot;, func(c *gin.Context) &#123;\n    c.JSON(200, gin.H&#123;&quot;正在运行版本&quot;: BuildID&#125;)\n  &#125;)\n\n  &#x2F;&#x2F; 通过接口上传更新后的版本，触发overseer去自动更新\n  r.Any(&quot;&#x2F;bin&#x2F;app&quot;, func(c *gin.Context) &#123;\n    if b, err :&#x3D; ioutil.ReadFile(&quot;path&#x2F;main&quot;); err !&#x3D; nil &#123;\n      c.JSON(200, gin.H&#123;&quot;msg&quot;: err.Error()&#125;)\n    &#125; else &#123;\n      c.Writer.WriteHeader(http.StatusOK)\n      c.Header(&quot;Content-Disposition&quot;, &quot;attachment; filename&#x3D;main&quot;)\n      c.Header(&quot;Content-Type&quot;, &quot;application&#x2F;octet-stream&quot;)\n      c.Header(&quot;Content-Length&quot;, fmt.Sprintf(&quot;%d&quot;, len(b)))\n\n      if c.Request.Method &#x3D;&#x3D; &quot;HEAD&quot; &#123;\n        c.Header(&quot;ETag&quot;, &quot;v002&quot;)\n        c.Status(200)\n      &#125; else &#123;\n        _, _ &#x3D; c.Writer.Write(b)\n      &#125;\n    &#125;\n  &#125;)\n\n  _ &#x3D; r.RunListener(state.Listener)\n&#125;\n\n注意: 像此类接口，实际开发过程中一定要注意鉴权，以及校验上传文件的哈希值，确保万无一失。哎，见过太多没有安全意识的小盆友了。\n\n缺陷: 监听者自身的配置，还是需要手动更新，无法实现自动更新。\n\n虽然花了一点时间研究，不过在K8S，docker这么好用的今天，这个我也没在实际项目使用，纯当记录吧\n\n\n\n\n","slug":"golang/Golang程序实现自动更新","date":"2020-10-16T08:03:06.000Z","categories_index":"go","tags_index":"go","author_index":"Rumple"},{"id":"a96d6d6139d5419f25b0435643fa218f","title":"ElasticSearch之ScrollAPI","content":"&amp;#160;&amp;#160;&amp;#160;&amp;#160;最近遇到了一个需求，公司集团的所有项目日志都是存在kafka中，通过logstash去不断读取，通过一定的规则将日志切割为我们需要的格式，存入ES。我们要做的就是定期不断的从ES中取获取日志，分析日志。\n\n\n\nScroll的概念 Scroll其实和文件读取中的指针(seek)，传统数据库中的游标非常相似，目的是为了在数据量特别大的时候，去检索数据。因为不可能在一次请求中将所有数据一并处理。\n\n基本使用 ES检索数据所使用的api使用GET,POST方法都是可以的，query scroll 的意思是表明此次会话的有效时长是多久，如果过期的话ES会自动销毁，不过在实际使用过程中，最好还是使用完毕后主动销毁,因为保存会话的存活是有成本的。DSL查询条件则存放于body中\n\n首次查询 POST &#x2F;index&#x2F;_search?scroll&#x3D;1m\n&#123;\n  &quot;size&quot;:1000,\n  &quot;query&quot;:&#123;\n    &quot;range&quot;:&#123;\n      &quot;timestamp&quot;:&#123;\n        &quot;gt&quot;:&quot;xxxxx&quot;,  # 我这里是检索一定时间范围的数据，注意，这里的时间是UTC格式的时间字符串\n        &quot;lt&quot;:&quot;xxxxx&quot;,\n      &#125;\n    &#125;\n  &#125;\n&#125;\n\n在此次请求结果中，除了会得到正常的search response外，还会得到一个 _scroll_id ，而我们后续的请求就会使用这个id去请求scroll api，直到hits中的数据长度为0.\n\n POST &#x2F;_search&#x2F;scroll\n# 注意 scroll 请求url中不能包含 index 和 type，因为初始请求已经包含。（type 在es7以后已经不再推荐使用了）\n&#123;\n  &quot;scroll&quot;: &quot;1m&quot;, # 让此次会话再保存1分钟\n  &quot;scroll_id&quot;: [_scroll_id] # 首次请求所的到的id\n&#125;\n\n销毁会话 可以在query中传入scroll_id 也可以在body中 DELETE &#x2F;_search&#x2F;id1,id2\n&#123;\n  &quot;scroll_id&quot;: &quot;xxxxx&quot;,\n  # 也可以使用数组传递多个\n  &quot;scroll_id&quot;: [\n    &quot;id1&quot;,\n    &quot;id2&quot;\n  ]\n&#125;\n\n# 也可以一次性删除所有\nDELETE &#x2F;_search&#x2F;scroll&#x2F;_all\n\n\n完成需求代码  import (\n  &quot;logs&quot;\n  &quot;context&quot;\n  &quot;fmt&quot;\n  requests &quot;github.com&#x2F;levigross&#x2F;grequests&quot;\n  &quot;time&quot;\n)\n\ntype (\n  searchBody struct &#123;\n    Query _query &#96;json:&quot;query&quot;&#96;\n    Size  int    &#96;json:&quot;size&quot;&#96;\n  &#125;\n\n  _query struct &#123;\n    Range _range &#96;json:&quot;range&quot;&#96;\n  &#125;\n\n  _range struct &#123;\n    Timestamp _timestamp &#96;json:&quot;timestamp&quot;&#96;\n  &#125;\n\n  _timestamp struct &#123;\n    Gte string &#96;json:&quot;gte&quot;&#96;\n    Lte string &#96;json:&quot;lte&quot;&#96;\n  &#125;\n\n  searchResult struct &#123;\n    ScrollId string &#96;json:&quot;_scroll_id&quot;&#96;\n    Hits     _hits  &#96;json:&quot;hits&quot;&#96;\n  &#125;\n\n  _hits struct &#123;\n    Hits []map[string]interface&#123;&#125; &#96;json:&quot;hits&quot;&#96;\n  &#125;\n)\n\nfunc job(ctx context.Context) &#123;\n  var (\n    err   error\n    index string\n    resp  *requests.Response\n  )\n\n  const (\n    utcFormat  &#x3D; &quot;2006-01-02T15:04:05Z&quot;\n    searchSize &#x3D; 1000\n    scroll     &#x3D; &quot;10m&quot;\n  )\n\n  now :&#x3D; time.Now()\n  start :&#x3D; now.Add(-time.Hour)\n\n  gte :&#x3D; start.Format(utcFormat)\n  lte :&#x3D; now.Format(utcFormat)\n\n  body :&#x3D; searchBody&#123;\n    Query: _query&#123;_range&#123;_timestamp&#123;\n      Gte: gte,\n      Lte: lte,\n    &#125;&#125;&#125;,\n    Size: searchSize,\n  &#125;\n\n  defer func() &#123;\n    _ &#x3D; resp.Close()\n  &#125;()\n\n  if resp, err &#x3D; requests.Get(fmt.Sprintf(&quot;http:&#x2F;&#x2F;%s&#x2F;%s&#x2F;_search?scroll&#x3D;%s&quot;, esHost, index, scroll),\n    &amp;requests.RequestOptions&#123;\n      Context: ctx,\n      Auth:    []string&#123;esUser, esPass&#125;,\n      JSON:    body,\n    &#125;); err !&#x3D; nil &#123;\n    logs.Errorf(err.Error())\n    return\n  &#125;\n\n  var (\n    serRes searchResult\n    tmp    []map[string]interface&#123;&#125;\n  )\n\n  if err &#x3D; resp.JSON(&amp;serRes); err !&#x3D; nil &#123;\n    logs.Errorf(&quot;解析json失败:%s&quot;, err.Error())\n    return\n  &#125;\n\n  tmp &#x3D; append(tmp, serRes.Hits.Hits...)\n\n  defer func() &#123;\n    &#x2F;&#x2F; 清除会话\n    if dResp, err :&#x3D; requests.Delete(fmt.Sprintf(&quot;http:&#x2F;&#x2F;%s&#x2F;_search&#x2F;scroll&#x2F;%s&quot;, esHost, serRes.ScrollId),\n      &amp;requests.RequestOptions&#123;Auth: []string&#123;esUser, esPass&#125;&#125;); err !&#x3D; nil &#123;\n      logs.Errorf(&quot;清楚scroll会话失败:%s&quot;, err.Error())\n    &#125; else &#123;\n      _ &#x3D; dResp.Close()\n    &#125;\n  &#125;()\n\n  for &#123;\n    var er searchResult\n    if resp, err &#x3D; requests.Get(fmt.Sprintf(&quot;http:&#x2F;&#x2F;%s&#x2F;_search&#x2F;scroll&quot;, esHost),\n      &amp;requests.RequestOptions&#123;\n        Context: ctx,\n        Auth:    []string&#123;esUser, esPass&#125;,\n        JSON: map[string]interface&#123;&#125;&#123;\n          &quot;scroll&quot;:    scroll,\n          &quot;scroll_id&quot;: serRes.ScrollId,\n        &#125;,\n      &#125;); err !&#x3D; nil &#123;\n      logs.Errorf(&quot;scroll error : %s&quot;, err.Error())\n      return\n    &#125;\n\n    if err &#x3D; resp.JSON(&amp;er); err !&#x3D; nil &#123;\n      logs.Errorf(&quot;scroll json error : %s&quot;, err.Error())\n      return\n    &#125;\n\n    if len(er.Hits.Hits) &#x3D;&#x3D; 0 &#123;\n      break\n    &#125;\n\n    tmp &#x3D; append(tmp, er.Hits.Hits...)\n  &#125;\n\n  logs.Infof(&quot;最终结果:%s&quot;, tmp)\n&#125;\n\n","slug":"es/ElasticSearch之ScrollAPI","date":"2020-10-16T07:07:23.000Z","categories_index":"es","tags_index":"es","author_index":"Rumple"},{"id":"7dfbca418b659e3c01ba70280331af77","title":"工欲善其事,必先利其器","content":"&amp;#160;&amp;#160;&amp;#160;&amp;#160;俗话说的好，工欲善其事必先利其器，作为一名有追求的开发者，当然要将自己吃饭的家伙打造的即好用又美观啦。\n\n\n&amp;#160;&amp;#160;&amp;#160;&amp;#160;接下来我主要会从系统软件与配置,Chrome插件,Terminal 三个方面去推荐好用的软件及配置\n\n系统软件与配置篇\n系统软件\n\n\nname\ndescription\n\n\n\nAlfred4\n提升效率的神器不过多解释了，必装\n\n\n超级右键\n可以增强mac的右键功能，在appstore就可以下载\n\n\nDozer\n免费开源的隐藏图标工具\n\n\niterm2\n终端，开发人员必备\n\n\niStat Menus\n状态栏对于系统资源的监控，很好用且美观\n\n\nFoldery\n可以自定义文件夹的颜色的小工具\n\n\nOpenInTerminial\n在Finder中可以直接打开终端，编辑器\n\n\nSnipaste\n截图贴图的神器，不解释\n\n\nNeatDownloadManager\n替代浏览器自身的下载器，可以最大开启32线程同时下载，很好用\n\n\nTinycal\n一个很简洁的状态栏日历\n\n\nAwesome-mac\n其他mac软件\n\n\n\n系统设置\n通过如下命令，可以让那些包含隐藏窗口的应用程序图标变暗，从而方便我们区分defaults write com.apple.dock showhidden -bool true; killall Dock\n恢复为默认设置defaults delete com.apple.Dock showhidden; Killall Dock \n开启hidpi(当外接2k 4k显示器使用时，可以调整画面更细腻舒适)sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/xzhih/one-key-hidpi/master/hidpi-zh.sh)&quot;\n设置dock隐藏后 弹出响应时间defaults write com.apple.Dock autohide-delay -int 0 &amp;&amp; killall Dockdefaults write com.apple.dock autohide-time-modifier -int 0; killall Dock\n显示与恢复隐藏文件defaults write com.apple.finder AppleShowAllFiles -boolean true ; killall Finderdefaults write com.apple.finder AppleShowAllFiles -boolean false ; killall Finder\n禁止与恢复.DS_store生成defaults write com.apple.desktopservices DSDontWriteNetworkStores -bool TRUEdefaults delete com.apple.desktopservices DSDontWriteNetworkStores\n\n\nother 身为开发人员必装的依赖command-line-tools\n命令行安装方法xcode-select --install\n\n检查是否安装成功xcode-select --print-path\n\n如果命令行安装失败，可以直接去苹果开发者网站下载安装\n\n\n\n\n\nChrome插件篇好用的插件很多，但是在经过我长时间的使用之后留下的只有下面的这些，这里也提供一个谷歌插件英雄榜，可以挑选适合自己的插件\n\n\n\nname\ndescription\n\n\n\nAdguard\n全平台的广告拦截器，也可以只装插件，反正我是把用了许久的adblock换成这个了\n\n\nAPK Downloader\n用来下载google play中的软件\n\n\nFile Icons for GitHub and GitLab\n给github gitlab中的项目文件添加对应的图标\n\n\nNeatDownloadMnagaer\nNDM需要安装对应插件使用\n\n\nOctotree - GitHub code tree\n显示github中的目录文件树，不用点来点去了，直接在侧边栏就可以看\n\n\nSimpleUndoClose\n恢复手贱关掉的网页\n\n\n沙拉查词\n很好用的翻译插件\n\n\n掘金\n查看当下都有哪些流行的项目，和新项目\n\n\nTampermonkey\n不解释 懂的都懂\n\n\n\nTerminal\n\n\nname\ndescription\ninstall\nusage\n\n\n\nbrew\n不解释必装\n&#x2F;bin&#x2F;bash -c “$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot;\nbrew –help\n\n\nohmyzsh\n不解释必装\nsh -c “$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;\n&#x2F;\n\n\ntldr\n有啥命令不会用了就直接用它查看，还有使用示例\nbrew install tldr\ntldr wget\n\n\nmycli\nmysql增强客户端可以自动补全，记录历史，彩色\nbrew install mycli\n同mysql-client\n\n\nlolcat\n炫彩的cat\nbrew install lolcat\n…\n\n\nhttpie\n功能同curl,但是要好用许多\nbrew install httpie\nhttp –help\n\n\ncmatrix\n装逼\nbrew install cmatrix\ncmatrix\n\n\nfd\n增强的find，比find要快很多\nbrew install fd\nfd –help\n\n\nprocs\n比ps更好用\nbrew install procs\nprocs docker\n\n\nhtop\n众所周知的东西了\nbrew install htop\nhtop\n\n\nneofetch\n终端输出美化的电脑配置图\nbrew install neofetch\nneofetch\n\n\ntelnet，tree\nmac 自带没有这些工具\nbrew install\n&#x2F;\n\n\nthe_silver_searcher\n用来搜索文件中字符串的工具\nbrew install\nag –help\n\n\nncdu\n交互式查看文件的工具\nbrew install\nncdu\n\n\nloc\n统计代码行数\nbrew install\nloc .\n\n\nfanyi\n命令翻译工具\nnpm install fanyi -g\nfanyi xxx\n\n\n\n\n","slug":"config/工欲善其事","date":"2020-10-14T08:58:32.000Z","categories_index":"工具配置","tags_index":"mac,config","author_index":"Rumple"},{"id":"215ed200ae4dc1e04195cbe144fde063","title":"Firewalld防火墙操作手册","content":"firewalld的基本使用\n启动: systemctl start firewalld\n关闭: systemctl stop firewalld\n查看状态: systemctl status firewalld\n开机禁用: systemctl disable firewalld\n开机启用: systemctl enable firewalld\n\n\n\n\n启动一个服务：systemctl start firewalld.service\n\n关闭一个服务：systemctl stop firewalld.service\n\n重启一个服务：systemctl restart firewalld.service\n\n显示一个服务的状态：systemctl status firewalld.service\n\n在开机时启用一个服务：systemctl enable firewalld.service\n\n在开机时禁用一个服务：systemctl disable firewalld.service\n\n查看服务是否开机启动：systemctl is-enabled firewalld.service\n\n查看已启动的服务列表：systemctl list-unit-files|grep enabled\n\n查看启动失败的服务列表：systemctl --failed\n\n\n配置firewalld-cmd\n查看版本: firewall-cmd --version\n查看帮助: firewall-cmd --help\n显示状态: firewall-cmd --state\n查看所有打开的端口: firewall-cmd --zone=public --list-ports\n更新防火墙规则: firewall-cmd --reload\n查看区域信息: firewall-cmd --get-active-zones\n查看指定接口所属区域: firewall-cmd --get-zone-of-interface=eth0\n拒绝所有包: firewall-cmd --panic-on\n取消拒绝状态: firewall-cmd --panic-off\n查看是否拒绝: firewall-cmd --query-panic\n\n开启端口\n添加: –permanent永久生效，没有此参数重启后失效  firewall-cmd --zone=public --add-port=80/tcp --permanent\n重新载入:  firewall-cmd --reload\n查看:  firewall-cmd --zone= public --query-port=80/tcp\n删除:  firewall-cmd --zone= public --remove-port=80/tcp --permanent\n\n","slug":"guide/Firewalld防火墙操作手册","date":"2020-10-14T08:30:18.000Z","categories_index":"操作指南","tags_index":"firewalld","author_index":"Rumple"},{"id":"c30c52bb5c9d540be0dfcb4f6b31a9fc","title":"Vim常用命令","content":"&amp;#160;&amp;#160;&amp;#160;&amp;#160;众所周知，vim是程序员的一款利器， 一些大神可以完全抛弃ide只使用vim去构建庞大的项目， 而对于我来说只是一个工具而已，他不应该耗费我的精力去做配置和学习，强行改变自己的编码习惯，所以这里整理了我日常使用比较多的一些命令。\n\n\n第一阶段\ni Insert模式\nx 删当前光标所在的一个字符\n:wq :w后面可以跟文件名表示新建一个文件,q表示退出\ndd 删除当前行\nyy 拷贝当前行\np 在光标后粘贴 P在之前粘贴\n:help &lt;command&gt; 显示命令帮助信息\nu: 撤销一条命令\nCtrl + r: 回退编辑\n\n第二阶段各种插入模式\na 在光标后插入\no 在当前行后插入一个新行\nO 在当前行前插入一个新行\n\n简单移动光标\n0 数字零，到行头\n$ 到本行行尾\n?pattern 在前面的文本搜索 pattern\n/pattern 在后面的文本搜索 pattern 的字符串,如果搜索出多个匹配，n向后查找,N向前查找\n\n打开&#x2F;保存&#x2F;退出&#x2F;改变文件\n:e &lt;path/to/file&gt; 打开一个文件\n:w 存盘 后面跟文件名也可以另存\n:saveas &lt;path/to/file&gt; 另存为 &lt;path&#x2F;to&#x2F;file&gt;\n:x 或 ZZ 或 :wq 保存并退出 :x 表示仅在需要时保存\n:q! 退出不保存 \n:qa! 强行退出所有的正在编辑的文件，就算别的文件有更改。\n:bn &amp;&amp; :bp 你可以同时打开很多文件，使用这两个命令来切换下一个或上一个文件\n\n翻页滚动\nctrl + f 下翻一屏。\nctrl + b 上翻一屏。\nctrl + d 下翻半屏。\nctrl + u 上翻半屏。\nctrl + e 向下滚动一行。\nctrl + y 向上滚动一行。\n\n第三阶段\n. 可以重复上一次的命令\nN &lt;command&gt; 重复某个命令N次 例如：2dd 删除两行\n3G 跳转到第三行,也可以使用 :3\ngg 到第一行 相当于 1G 或者 :1\nG 到最后一行\nw 按单词移动，到下一个单词的开头\ne 按单词移动，到下一个单词的结尾\nv 进入可视化选择\ngU 选中部分变为大写\ngu 选中部分变为小写\n~ 反转光标所在位置大小写\n\n","slug":"guide/Vim常用命令","date":"2020-10-14T05:43:56.000Z","categories_index":"操作指南","tags_index":"vim","author_index":"Rumple"},{"id":"7110b28ed6014c88f6bf2e9ca83fa56d","title":"hexo如何插入图片","content":"\n首先安装插件\n npm install hexo-asset-image --save\n\n\n\n编辑hexo配置文件_config.yml\n post_asset_folder: true\n\n\n修改node_modules/hexo-asset-image/index.js 为如下内容\n use &#39;strict&#39;;\nvar cheerio &#x3D; require(&#39;cheerio&#39;);\n\n&#x2F;&#x2F; http:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;14480345&#x2F;how-to-get-the-nth-occurrence-in-a-string\nfunction getPosition(str, m, i) &#123;\n  return str.split(m, i).join(m).length;\n&#125;\n\nvar version &#x3D; String(hexo.version).split(&#39;.&#39;);\nhexo.extend.filter.register(&#39;after_post_render&#39;, function(data)&#123;\nvar config &#x3D; hexo.config;\nif(config.post_asset_folder)&#123;\n      var link &#x3D; data.permalink;\n  if(version.length &gt; 0 &amp;&amp; Number(version[0]) &#x3D;&#x3D; 3)\n    var beginPos &#x3D; getPosition(link, &#39;&#x2F;&#39;, 1) + 1;\n  else\n    var beginPos &#x3D; getPosition(link, &#39;&#x2F;&#39;, 3) + 1;\n  &#x2F;&#x2F; In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;...&#x2F;about&#x2F;index.html&quot;.\n  var endPos &#x3D; link.lastIndexOf(&#39;&#x2F;&#39;) + 1;\n  link &#x3D; link.substring(beginPos, endPos);\n\n  var toprocess &#x3D; [&#39;excerpt&#39;, &#39;more&#39;, &#39;content&#39;];\n  for(var i &#x3D; 0; i &lt; toprocess.length; i++)&#123;\n    var key &#x3D; toprocess[i];\n\n    var $ &#x3D; cheerio.load(data[key], &#123;\n      ignoreWhitespace: false,\n      xmlMode: false,\n      lowerCaseTags: false,\n      decodeEntities: false\n    &#125;);\n\n    $(&#39;img&#39;).each(function()&#123;\n      if ($(this).attr(&#39;src&#39;))&#123;\n          &#x2F;&#x2F; For windows style path, we replace &#39;\\&#39; to &#39;&#x2F;&#39;.\n          var src &#x3D; $(this).attr(&#39;src&#39;).replace(&#39;\\\\&#39;, &#39;&#x2F;&#39;);\n          if(!&#x2F;http[s]*.*|\\&#x2F;\\&#x2F;.*&#x2F;.test(src) &amp;&amp;\n            !&#x2F;^\\s*\\&#x2F;&#x2F;.test(src)) &#123;\n            &#x2F;&#x2F; For &quot;about&quot; page, the first part of &quot;src&quot; can&#39;t be removed.\n            &#x2F;&#x2F; In addition, to support multi-level local directory.\n            var linkArray &#x3D; link.split(&#39;&#x2F;&#39;).filter(function(elem)&#123;\n              return elem !&#x3D; &#39;&#39;;\n            &#125;);\n            var srcArray &#x3D; src.split(&#39;&#x2F;&#39;).filter(function(elem)&#123;\n              return elem !&#x3D; &#39;&#39; &amp;&amp; elem !&#x3D; &#39;.&#39;;\n            &#125;);\n            if(srcArray.length &gt; 1)\n              srcArray.shift();\n            src &#x3D; srcArray.join(&#39;&#x2F;&#39;);\n            $(this).attr(&#39;src&#39;, config.root + link + src);\n            console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);\n          &#125;\n      &#125;else&#123;\n          console.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;);\n          console.info&amp;&amp;console.info($(this));\n      &#125;\n    &#125;);\n    data[key] &#x3D; $.html();\n  &#125;\n&#125;\n&#125;);\n\n\n然后就可以插入图片了，hexo new [article] 会生成对应文章的文件夹，将图片放入即可。\n\n\n","slug":"config/Hexo如何插入图片","date":"2020-10-14T05:42:20.000Z","categories_index":"hexo","tags_index":"hexo","author_index":"Rumple"},{"id":"99196e093c1a105719cfe8e1edea1c78","title":"Git命令概览","content":"\n\n创建版本库\ngit clone url 克隆远程版本库\ngit init 初始化本地版本库\n\n配置\ngit config --global user.name &#39;chengcp&#39; 配置global级别的用户名\ngit config --global user.email &#39;1326895569@qq.com&#39; 配置global级别的邮箱\ngit config --global -l 查看global级别的配置列表\ngit config --global --unset user.name 删除用户名\ngit config --global alias.last &#39;log -1 HEAD&#39; 配置last别名，使用git last将显示最近的一次提交记录\n\n添加和删除文件\ngit add file1 file2 添加指定文件到暂存区\ngit add dir 添加指定目录到暂存区\ngit add . 添加当前目录的所有文件到暂存区\ngit mv oldname newname 对一个已经追踪过的文件进行改名，同时加入暂存区\ngit rm file1 file2 删除工作区文件，同时将这次删除放入暂存区\ngit rm --cached file 停止追踪指定文件，但该文件会保留在工作区；tracked变成untracked\n\n提交\ngit commit file1 file 2 -m message 提交暂存区指定文件到本地仓库\ngit commit -m message 提交暂存区所有文件到本地仓库\ngit commit -a -m message 自动暂存所有已经追踪过的文件，且提交到本地仓库\ngit commit --amend -m message 使用一次新的提交，替代上次提交\n\n分支\ngit branch 查看所有本地分支\ngit branch –r 查看所有远程分支\ngit branch –a 查看所有远程和本地分支\ngit branch –v 查看本地所有分支最新一次提交信息\ngit branch [branch] 新建分支\ngit checkout –b [branch] 新建一个分支，并且切换过去\ngit branch [branch] [commit] 基于某次提交，建立一个分支\ngit branch --track [branch] [remote-branch] 建立一个分支，并且与远程分支建立追踪关系\ngit branch --set-upstream [branch] [remote-branch] 在现有的本地分支和远程分支之间建立追踪关系\ngit branch –m [old-branch] [new-branch] 重命名分支\ngit merge [branch] 把指定分支合并到当前分支\ngit chery-pick [commit] [commit] 选择提交，合并进当前分支\ngit branch –d [branch] 删除本地分支\ngit push origin –d [branch] 删除远程分支\ngit checkout [branch] 切换分支\ngit checkout - 切换到上一个最近使用过的分支\n\n标签\ngit tag 列出所有标签\ngit show [tag] 查看指定标签信息\ngit tag [tag] 给最近一次提交打一个标签\ngit tag [tag] [commit] 在某次提交上打一个标签\ngit tag –d [tag] 删除本地指定标签\ngit push origin –d tag [tag] 删除远程的标签\ngit push origin [tag] 推送指定标签\ngit push origin --tags 推送所有标签\n\n查看信息\ngit status 查看文件状态\ngit help [command] 获取帮助文档\ngit [command] --help 获取帮助文档\ngit log 查看当前分支的提交记录\ngit log –all 查看所有分支的提交记录\ngit log -5 --oneline --graph 查看最近5次提交记录，以单行、树状图形式显示\ngit reflog 查看本地所有变更记录\ngit diff 查看工作区和暂存区的差异\ngit diff -- file 某个文件在工作区和暂存区的差异\ngit diff HEAD 工作区和最新一次提交的差异\ngit diff --cached 暂存区和HEAD的差异\ngit diff branch_a branch_b – file 某文件在两个分支间的差异\n\n远程操作\ngit remote -v 查看所有远程仓库\ngit ls-remote origin 查看远程仓库引用列表\ngit remote show origin 查看远程仓库信息\ngit fetch origin 拉取远程仓库最新提交\ngit pull origin master 拉取远程master，并且合并到本地当前分支\ngit remote add upstream url 添加一个新的远程仓库，命名为upstream\ngit push origin master 推送到远程origin的master分支\ngit push origin --all 推送所有分支到远程仓库\ngit remote prune origin 删除远程仓库中不存在的分支\ngit push origin --delete tag &quot;tagname&quot; 删除远程tag\n\n撤销\ngit reset --soft HEAD 回滚到指定版本，保留工作区和暂存区\ngit reset --mixed HEAD 回滚到指定版本，保留工作区，清空暂存区；–mixed是默认参数，即等同于git reset HEAD\ngit reset --hard HEAD 回滚到指定版本，清空工作区和暂存区\ngit reset HEAD -- file 清空暂存区中某个文件的修改\ngit checkout -- file 检出暂存区的文件到工作目录\ngit checkout . 检出暂存区的所有文件到工作目录\ngit revert HEAD~ 2 回滚到2个祖先提交的版本，同时产生新的提交记录\ngit revert --continue 冲突解决，且把修改提交到暂存区后执行回滚，生成一个新的提交\ngit revert –abort 取消回滚，回到之前的状态\n\n储藏\ngit stash 将工作区和暂存区的变更保存到储藏堆栈中，同时工作区和暂存区恢复到HEAD一样\ngit stash list 查看储藏列表\ngit stash pop 应用最近的一次储藏，并且从储藏栈中移除该条记录\ngit stash apply stash@&#123;0&#125; 应用最近的一次储藏，不移除记录；等同于 git stash apply\ngit stash pop --index 应用最近一次储藏，–index表示暂存区的变更也会更新，否则只更新工作区变更\ngit stash drop stash@&#123;0&#125; 移除储藏记录\n\n高级\n美化查看分支合并图\n  git log --graph --pretty&#x3D;oneline --abbrev-commit --graph\n强制远程代码覆盖本地\n  git fetch --all\ngit reset --hard origin&#x2F;[branch]\ngit pull\n修改.gitignore文件后使其生效\n  git rm -r --cached .\ngit add .\ngit commit -m &quot;xx&quot;\ngit push\n\n当我们不在master分支时又想要从最新master分支创建一个开发分支可以如下操作，不用切换到master分支\n  git fetch origin&#x2F;master\ngit checkout branch [new branch] origin&#x2F;master\n\n","slug":"guide/Git命令速查表","date":"2020-10-13T03:22:28.000Z","categories_index":"操作指南","tags_index":"git","author_index":"Rumple"},{"id":"bd1810b01d17021ef51e6fe61514d2b5","title":"计算机基础之网络协议","content":"我们都知道OSI把网络分为了一个7层的模型，OSI是Open System Interconnect的缩写，意为开放式系统互联。  主要是：\n\n应用层（Application）\n表示层（Presentation）\n会话层（Session）\n传输层（Transport）\n网络层（Network）\n数据链路层（Data Link）\n物理层（Physical） \n  OSI七层参考模型的各个层次的划分遵循下列原则：\n同一层中的各网络节点都有相同的层次结构，具有同样的功能。\n同一节点内相邻层之间通过接口(可以是逻辑接口)进行通信。\n七层结构中的每一层使用下一层提供的服务，并且向其上层提供服务。\n不同节点的同等层按照协议实现对等层之间的通信\n\n\n\n  \n应用层\n与其它计算机进行通讯的一个应用，它是对应应用程序的通信服务的。例如，一个没有通信功能的字处理程序就不能执行通信的代码，从事字处理工作的程序员也不关心OSI的第7层。但是，如果添加了一个传输文件的选项，那么字处理器的程序员就需要实现OSI的第7层。示例：TELNET，HTTP，FTP，NFS，SMTP等。\n数据单位：报文\n\n表示层\n这一层的主要功能是定义数据格式及加密。例如，FTP允许你选择以二进制或ASCII格式传输。如果选择二进制，那么发送方和接收方不改变文件的内容。如果选择ASCII格式，发送方将把文本从发送方的字符集转换成标准的ASCII后发送数据。在接收方将标准的ASCII转换成接收方计算机的字符集。示例：加密，ASCII等。这一层\n数据单位：报文\n\n会话层\n它定义了如何开始、控制和结束一个会话，包括对多个双向消息的控制和管理，以便在只完成连续消息的一部分时可以通知应用，从而使表示层看到的数据是连续的，在某些情况下，如果表示层收到了所有的数据，则用数据代表表示层。示例：RPC，SQL等。在会话层及以上的高层次中，数据传送的单位不再另外命名，而是统称为报文。\n数据单位：报文\n\n传输层\n这层的功能包括是否选择差错恢复协议还是无差错恢复协议，及在同一主机上对不同应用的数据流的输入进行复用，还包括对收到的顺序不对的数据包的重新排序功能。示例：TCP，UDP，SPX。这一层的数据单元也称作数据包(packets)。但是，当你谈论TCP等具体的协议时又有特殊的叫法，TCP的数据单元称为段 (segments)而UDP协议的数据单元称为“数据报(datagrams)”。\n\n网络层\n这层对端到端的包传输进行定义，它定义了能够标识所有结点的逻辑地址，还定义了路由实现的方式和学习的方式。为了适应最大传输单元长度小于包长度的传输介质，网络层还定义了如何将一个包分解成更小的包的分段方法。示例：IP，IPX等。\n数据的单位：数据包(packet)\n\n数据链路层\n它定义了在单个链路上如何传输数据。这些协议与被讨论的各种介质有关。示例：ATM，FDDI等。\n数据的单位：帧(frame)。\n\n物理层\nOSI的物理层规范是有关传输介质的特这些规范通常也参考了其他组织制定的标准。连接头、帧、帧的使用、电流、编码及光调制等都属于各种物理层规范中的内容。物理层常用多个规范完成对所有细节的定义。示例：Rj45，802.3等。\n数据单位：比特（bit）。\n\n数据传输过程  \n","slug":"basic/计算机基础之网络协议","date":"2020-09-19T09:19:52.000Z","categories_index":"计算机基础","tags_index":"网络协议","author_index":"Rumple"},{"id":"5f7c30e057df77178fa3c740f5edfc89","title":"select poll epoll","content":"今天被问到epoll机制，倒不是不知道，就是长时间不看他就容易忽略一些细节，导致描述不好。好吧那我们就来复习一下吧。（虽然我向来不是一个面向面试编程的人）-.&#x3D;\n\n首先 select,poll,epoll都是I&#x2F;O多路复用的机制。I&#x2F;O多路复用：通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序（也就是响应的进程）进行相应的读写操作。但select，poll，epoll本质上都是同步I&#x2F;O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I&#x2F;O则无需自己负责进行读写，异步I&#x2F;O的实现会负责把数据从内核拷贝到用户空间。\n关于三者的实现原理这里就不赘述了，善用搜索引擎，很多很多。\n总结一下三者的一些特征与区别\n\nselect\n监听的fd（文件描述符）有最大限制 cat /proc/sys/fs/file-max 查看，一般默认32位是1024，64位是2048 \n对socket的扫描是轮训扫描，而且不管其是否活跃都会扫描，效率低下，且浪费cpu时间\n需要维护一个存放fd的数据结构，🙆用户空间与内核空间在传递该结构时复制开销大\n\n\npoll\n与select相比 仅仅是没有最大连接数的限制，因为是基于链表来实现的。\n\n\nepoll\nepoll 没有最大并发连接的显示\n基于事件回调机制，只有活跃的链接才会触发回调，唤醒进程进行处理\n利用mmap()文件映射加速与内核空间的消息传递，减少复制开销\n\n\n\n看完了这些区别是不是epoll就万能了呢，当然不是，任何东西，都有其适用场景，比如当链接比较少，而且都是活跃的情况下，select poll自然比epoll效率高。因为epoll需要很多回调\n但是当今这个时代，确实可用 epoll 一把梭。毕竟感觉好像人人都在追求高并发，大流量。\n","slug":"basic/epoll","date":"2020-08-13T07:27:09.000Z","categories_index":"计算机基础","tags_index":"epoll,poll,select","author_index":"Rumple"}]